{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLNuX0TOqRTJ"
      },
      "outputs": [],
      "source": [
        "# === Setup ===\n",
        "from google.colab import drive; drive.mount('/content/drive', force_remount=True)\n",
        "BASE = \"/content/drive/MyDrive/Chinese Philosophers/\"\n",
        "INPUT = BASE + \"chinese_philosophers_quotes_corrected.csv\"\n",
        "\n",
        "# === Install minimal deps (only if not already installed) ===\n",
        "!pip -q install sentence-transformers keybert bertopic faiss-cpu renumics-spotlight\n",
        "\n",
        "import os, json, time\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "# === Load data and existing embeddings ===\n",
        "df = pd.read_csv(INPUT)\n",
        "E = np.load(BASE + \"quote_embeddings.npy\")   # existing MiniLM embeddings\n",
        "meta = pd.read_csv(BASE + \"quote_metadata.csv\") if os.path.exists(BASE+\"quote_metadata.csv\") else None\n",
        "\n",
        "# === 1) KeyBERT baseline ===\n",
        "if not os.path.exists(BASE+\"keybert_keywords.csv\"):\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    from keybert import KeyBERT\n",
        "    st = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    kw = KeyBERT(model=st)\n",
        "    out = []\n",
        "    for i, q in enumerate(df[\"quote\"]):\n",
        "        pairs = kw.extract_keywords(q, top_n=5)\n",
        "        out.append({\n",
        "            \"row_id\": (meta.loc[i,\"row_id\"] if meta is not None else i),\n",
        "            \"quote\": q,\n",
        "            \"keywords\": \"; \".join([p[0] for p in pairs])\n",
        "        })\n",
        "    pd.DataFrame(out).to_csv(BASE+\"keybert_keywords.csv\", index=False)\n",
        "\n",
        "    # optional diagnostics vs. LLM/Qwen files\n",
        "    diag = []\n",
        "    for fname in [\"per_quote_llm_keywords.csv\",\"per_quote_qwen_multidim.csv\"]:\n",
        "        path = BASE+fname\n",
        "        if os.path.exists(path):\n",
        "            other = pd.read_csv(path)\n",
        "            merged = pd.merge(pd.DataFrame(out), other, on=\"row_id\", how=\"inner\")\n",
        "            def toks(s): return set(str(s).lower().replace(\";\",\" \").split())\n",
        "            for _, r in merged.iterrows():\n",
        "                a, b = toks(r[\"keywords\"]), toks(r.get(\"keywords_llm\") or r.get(\"keywords\"))\n",
        "                if b:\n",
        "                    jacc = (len(a&b)/len(a|b)) if (a|b) else 0\n",
        "                    diag.append({\"row_id\": r[\"row_id\"], \"compare_to\": fname, \"jaccard\": jacc})\n",
        "    if diag:\n",
        "        pd.DataFrame(diag).to_csv(BASE+\"keyword_overlap_diagnostics.csv\", index=False)\n",
        "\n",
        "# === 2) BERTopic topics (optional) ===\n",
        "if not os.path.exists(BASE+\"bertopic_topics.csv\"):\n",
        "    from bertopic import BERTopic\n",
        "    topic_model = BERTopic(verbose=False)\n",
        "    topics, _ = topic_model.fit_transform(df[\"quote\"].tolist())\n",
        "    pd.DataFrame({\n",
        "        \"row_id\": meta[\"row_id\"] if meta is not None else range(len(df)),\n",
        "        \"topic\": topics\n",
        "    }).to_csv(BASE+\"bertopic_topics.csv\", index=False)\n",
        "    topic_model.get_topic_info().to_csv(BASE+\"bertopic_labels.csv\", index=False)\n",
        "\n",
        "# === 3) Persist FAISS index ===\n",
        "if not os.path.exists(BASE+\"faiss.index\"):\n",
        "    import faiss\n",
        "    vecs = E.astype(\"float32\")\n",
        "    index = faiss.IndexFlatIP(vecs.shape[1])  # IP works if embeddings are normalized\n",
        "    index.add(vecs)\n",
        "    faiss.write_index(index, BASE+\"faiss.index\")\n",
        "    with open(BASE+\"search_config.json\",\"w\") as f:\n",
        "        json.dump({\n",
        "            \"model\":\"all-MiniLM-L6-v2\",\"dim\":int(vecs.shape[1]),\n",
        "            \"metric\":\"ip\",\"embeddings_file\":\"quote_embeddings.npy\"\n",
        "        }, f)\n",
        "\n",
        "# === 4) Spotlight explorer manifest ===\n",
        "if not os.path.exists(BASE+\"spotlight_manifest.parquet\"):\n",
        "    import renumics.spotlight as spotlight\n",
        "    emb_df = pd.DataFrame({\"quote\": df[\"quote\"]})\n",
        "    if meta is not None:\n",
        "        emb_df[\"row_id\"] = meta[\"row_id\"]\n",
        "    emb_df[\"embedding\"] = list(E)\n",
        "    emb_df.to_parquet(BASE+\"spotlight_manifest.parquet\", index=False)\n",
        "    spotlight.show(emb_df)  # opens interactive explorer in Colab\n",
        "\n",
        "# === 5) Log additions for provenance ===\n",
        "record = {\n",
        "  \"ts\": int(time.time()),\n",
        "  \"added\": [f for f in [\n",
        "      \"keybert_keywords.csv\",\"keyword_overlap_diagnostics.csv\",\n",
        "      \"bertopic_topics.csv\",\"bertopic_labels.csv\",\n",
        "      \"faiss.index\",\"search_config.json\",\"spotlight_manifest.parquet\"\n",
        "  ] if os.path.exists(BASE+f)],\n",
        "  \"notes\": \"Resource-doc add-ons only; no changes to existing pipeline files.\"\n",
        "}\n",
        "summary_path = BASE+\"unsupervised_summary.json\"\n",
        "if os.path.exists(summary_path):\n",
        "    with open(summary_path,\"r+\") as f:\n",
        "        data = json.load(f)\n",
        "        data[\"addons\"] = (data.get(\"addons\") or []) + [record]\n",
        "        f.seek(0); json.dump(data,f,indent=2); f.truncate()\n",
        "else:\n",
        "    with open(BASE+\"new_additions.jsonl\",\"a\") as f:\n",
        "        f.write(json.dumps(record)+\"\\n\")\n",
        "\n",
        "print(\"✅ Done. New artifacts added where missing. Existing files left untouched.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Semantic search: query the FAISS index for \"taxation\" and show full quotes ===\n",
        "import os, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/Chinese Philosophers/\"\n",
        "INPUT = BASE + \"chinese_philosophers_quotes_corrected.csv\"\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(INPUT)\n",
        "meta_path = BASE + \"quote_metadata.csv\"\n",
        "meta = pd.read_csv(meta_path) if os.path.exists(meta_path) else None\n",
        "\n",
        "# Load FAISS index + config\n",
        "idx = faiss.read_index(BASE + \"faiss.index\")\n",
        "with open(BASE + \"search_config.json\") as f:\n",
        "    cfg = json.load(f)\n",
        "\n",
        "# Encode query\n",
        "st = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "query = \"taxation\"\n",
        "qv = st.encode([query], normalize_embeddings=True).astype(\"float32\")\n",
        "D, I = idx.search(qv, k=10)\n",
        "\n",
        "# Build results with full quotes\n",
        "rows = []\n",
        "for rank, (score, i) in enumerate(zip(D[0], I[0]), start=1):\n",
        "    if i < 0:\n",
        "        continue\n",
        "    rows.append({\n",
        "        \"rank\": rank,\n",
        "        \"similarity_score\": float(score),\n",
        "        \"row_id\": meta.loc[i,\"row_id\"] if meta is not None and \"row_id\" in meta.columns else i,\n",
        "        \"philosopher\": df.iloc[i].get(\"philosopher\", \"\"),\n",
        "        \"chapter\": df.iloc[i].get(\"chapter\", \"\"),\n",
        "        \"verse\": df.iloc[i].get(\"verse\", \"\"),\n",
        "        \"quote\": df.iloc[i].get(\"quote\", \"\")\n",
        "    })\n",
        "\n",
        "res = pd.DataFrame(rows)\n",
        "\n",
        "# Ensure Colab shows full text\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "res\n"
      ],
      "metadata": {
        "id": "TIJkvK_ksxsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Mount Drive and setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Install required packages\n",
        "!pip install --upgrade pip\n",
        "!pip install jsonnet\n",
        "!pip install -q transformers sentence-transformers faiss-cpu\n",
        "!pip install allennlp==2.10.1 allennlp-models==2.10.1\n",
        "\n",
        "\n",
        "# Load data\n",
        "data_path = '/content/drive/MyDrive/Chinese Philosophers/chinese_philosophers_quotes_corrected.csv'\n",
        "output_dir = '/content/drive/MyDrive/Chinese Philosophers/'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Ensure we always have a unique ID for each row\n",
        "if \"row_id\" in df.columns:\n",
        "    ids = df[\"row_id\"]\n",
        "else:\n",
        "    ids = df.index  # fallback to positional index\n",
        "\n",
        "\n",
        "# Initialize models\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sentence_transformers import CrossEncoder\n",
        "import faiss\n",
        "import json\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# 1. ARGUMENT MINING\n",
        "if not os.path.exists(f'{output_dir}argument_mining.csv'):\n",
        "    print(\"Running argument mining...\")\n",
        "    arg_model = pipeline(\"text-classification\", model=\"chkla/roberta-argument\", device=device)\n",
        "    arg_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            pred = arg_model(row['quote'][:512])[0]\n",
        "            arg_results.append({'row_id': ids[idx], 'is_argument': pred['label'], 'confidence': pred['score']})\n",
        "        except:\n",
        "            arg_results.append({'row_id': ids[idx], 'is_argument': 'ERROR', 'confidence': 0})\n",
        "    pd.DataFrame(arg_results).to_csv(f'{output_dir}argument_mining.csv', index=False)\n",
        "    del arg_model\n",
        "\n",
        "# 2. PERSUASION TECHNIQUES\n",
        "if not os.path.exists(f'{output_dir}persuasion_techniques.csv'):\n",
        "    print(\"Running persuasion detection...\")\n",
        "    # The model exists but needs authentication. Use alternative:\n",
        "    pers_model = pipeline(\"text-classification\", model=\"IMSyPP/hate_speech_en\", device=device)\n",
        "    # OR login to HuggingFace first:\n",
        "    # !huggingface-cli login --token YOUR_HF_TOKEN\n",
        "    pers_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            preds = pers_model(row['quote'][:512], top_k=3)\n",
        "            pers_results.append({\n",
        "                'row_id': ids[idx],\n",
        "                'technique_1': preds[0]['label'],\n",
        "                'score_1': preds[0]['score'],\n",
        "                'technique_2': preds[1]['label'] if len(preds) > 1 else '',\n",
        "                'score_2': preds[1]['score'] if len(preds) > 1 else 0\n",
        "            })\n",
        "        except:\n",
        "            pers_results.append({'row_id': ids[idx], 'technique_1': 'ERROR', 'score_1': 0})\n",
        "    pd.DataFrame(pers_results).to_csv(f'{output_dir}persuasion_techniques.csv', index=False)\n",
        "    del pers_model\n",
        "\n",
        "# 3. MORAL FOUNDATIONS\n",
        "if not os.path.exists(f'{output_dir}moral_foundations.csv'):\n",
        "    print(\"Running moral foundations...\")\n",
        "    moral_model = pipeline(\"text-classification\", model=\"USC-MOLA-Lab/MoralBERT\", device=device)\n",
        "    moral_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            preds = moral_model(row['quote'][:512], top_k=5)\n",
        "            moral_dict = {'row_id': ids[idx]}\n",
        "            for p in preds[:3]:\n",
        "                moral_dict[p['label']] = p['score']\n",
        "            moral_results.append(moral_dict)\n",
        "        except:\n",
        "            moral_results.append({'row_id': ids[idx], 'foundation': 'ERROR'})\n",
        "    pd.DataFrame(moral_results).to_csv(f'{output_dir}moral_foundations.csv', index=False)\n",
        "    del moral_model\n",
        "\n",
        "# 4. DIALOGUE ACTS\n",
        "if not os.path.exists(f'{output_dir}dialogue_acts.csv'):\n",
        "    print(\"Running dialogue act classification...\")\n",
        "    da_model = pipeline(\"text-classification\", model=\"silicone/deberta-v3-base_dyda_e\", device=device)\n",
        "    da_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            pred = da_model(row['quote'][:512])[0]\n",
        "            da_results.append({'row_id': ids[idx], 'dialogue_act': pred['label'], 'confidence': pred['score']})\n",
        "        except:\n",
        "            da_results.append({'row_id': ids[idx], 'dialogue_act': 'ERROR', 'confidence': 0})\n",
        "    pd.DataFrame(da_results).to_csv(f'{output_dir}dialogue_acts.csv', index=False)\n",
        "    del da_model\n",
        "\n",
        "# 5. IRONY/SARCASM DETECTION\n",
        "if not os.path.exists(f'{output_dir}figurative_language.csv'):\n",
        "    print(\"Running irony/sarcasm detection...\")\n",
        "    irony_model = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-irony\", device=device)\n",
        "    fig_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            pred = irony_model(row['quote'][:512])[0]\n",
        "            fig_results.append({'row_id': ids[idx], 'is_ironic': pred['label'], 'irony_score': pred['score']})\n",
        "        except:\n",
        "            fig_results.append({'row_id': ids[idx], 'is_ironic': 'ERROR', 'irony_score': 0})\n",
        "    pd.DataFrame(fig_results).to_csv(f'{output_dir}figurative_language.csv', index=False)\n",
        "    del irony_model\n",
        "\n",
        "# 6. SEMANTIC ROLE LABELING\n",
        "if not os.path.exists(f'{output_dir}semantic_roles.csv'):\n",
        "    print(\"Running SRL...\")\n",
        "    from allennlp.predictors.predictor import Predictor\n",
        "    srl_predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")\n",
        "    srl_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            pred = srl_predictor.predict(sentence=row['quote'][:300])\n",
        "            verbs = [v['verb'] for v in pred['verbs']] if 'verbs' in pred else []\n",
        "            args = []\n",
        "            for v in pred.get('verbs', []):\n",
        "                args.extend([tag.split('-')[-1] for tag in v.get('tags', []) if tag != 'O'])\n",
        "            srl_results.append({\n",
        "                'row_id': ids[idx],\n",
        "                'num_verbs': len(verbs),\n",
        "                'verbs': '|'.join(verbs[:3]),\n",
        "                'arg_types': '|'.join(set(args))\n",
        "            })\n",
        "        except:\n",
        "            srl_results.append({'row_id': ids[idx], 'num_verbs': 0})\n",
        "    pd.DataFrame(srl_results).to_csv(f'{output_dir}semantic_roles.csv', index=False)\n",
        "    del srl_predictor\n",
        "\n",
        "# 7-8. NLI COMPARISONS & CROSS-ENCODER (need FAISS pairs)\n",
        "if os.path.exists(f'{output_dir}faiss.index'):\n",
        "    print(\"Loading FAISS and finding pairs...\")\n",
        "    index = faiss.read_index(f'{output_dir}faiss.index')\n",
        "\n",
        "    # Get Confucius-Mozi pairs\n",
        "    conf_quotes = df[df['philosopher'] == 'Confucius'].reset_index(drop=True)\n",
        "    mozi_quotes = df[df['philosopher'] == 'Mozi'].reset_index(drop=True)\n",
        "\n",
        "    # Sample pairs (top-5 similar for each Confucius quote)\n",
        "    pairs = []\n",
        "    if len(conf_quotes) > 0 and len(mozi_quotes) > 0:\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "        encoder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        conf_embs = encoder.encode(conf_quotes['quote'].tolist()[:100])  # Limit for speed\n",
        "\n",
        "        D, I = index.search(conf_embs, 5)\n",
        "        for i, conf_row in enumerate(conf_quotes[:100].itertuples()):\n",
        "            for j in range(min(3, len(I[i]))):\n",
        "                if I[i][j] < len(mozi_quotes):\n",
        "                    mozi_row = mozi_quotes.iloc[I[i][j]]\n",
        "                    pairs.append({\n",
        "                        'conf_id': conf_row.row_id,\n",
        "                        'conf_quote': conf_row.quote[:200],\n",
        "                        'mozi_id': mozi_row['row_id'],\n",
        "                        'mozi_quote': mozi_row['quote'][:200]\n",
        "                    })\n",
        "\n",
        "        # 7. NLI\n",
        "        if not os.path.exists(f'{output_dir}nli_comparisons.csv') and len(pairs) > 0:\n",
        "            print(\"Running NLI...\")\n",
        "            nli_model = pipeline(\"text-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
        "            nli_results = []\n",
        "            for p in tqdm(pairs[:200]):  # Limit pairs\n",
        "                try:\n",
        "                    text = p['conf_quote'] + \" [SEP] \" + p['mozi_quote']\n",
        "                    pred = nli_model(text[:512])[0]\n",
        "                    nli_results.append({\n",
        "                        'conf_id': p['conf_id'],\n",
        "                        'mozi_id': p['mozi_id'],\n",
        "                        'relation': pred['label'],\n",
        "                        'confidence': pred['score']\n",
        "                    })\n",
        "                except:\n",
        "                    pass\n",
        "            pd.DataFrame(nli_results).to_csv(f'{output_dir}nli_comparisons.csv', index=False)\n",
        "            del nli_model\n",
        "\n",
        "        # 8. CROSS-ENCODER\n",
        "        if not os.path.exists(f'{output_dir}crossencoder_alignments.csv') and len(pairs) > 0:\n",
        "            print(\"Running cross-encoder...\")\n",
        "            ce_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "            ce_results = []\n",
        "            for p in tqdm(pairs[:200]):\n",
        "                try:\n",
        "                    score = ce_model.predict([[p['conf_quote'], p['mozi_quote']]])[0]\n",
        "                    ce_results.append({\n",
        "                        'conf_id': p['conf_id'],\n",
        "                        'mozi_id': p['mozi_id'],\n",
        "                        'alignment_score': score\n",
        "                    })\n",
        "                except:\n",
        "                    pass\n",
        "            pd.DataFrame(ce_results).to_csv(f'{output_dir}crossencoder_alignments.csv', index=False)\n",
        "\n",
        "print(\"All analyses complete!\")"
      ],
      "metadata": {
        "id": "IxwoKSwq7Jvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Authenticate HuggingFace\n",
        "!pip install -q huggingface_hub\n",
        "from huggingface_hub import login\n",
        "login(token=\"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\")\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from transformers import pipeline\n",
        "\n",
        "# Setup\n",
        "data_path = '/content/drive/MyDrive/Chinese Philosophers/chinese_philosophers_quotes_corrected.csv'\n",
        "output_dir = '/content/drive/MyDrive/Chinese Philosophers/'\n",
        "df = pd.read_csv(data_path)\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# 1. PERSUASION TECHNIQUES (retry with auth)\n",
        "if not os.path.exists(f'{output_dir}persuasion_techniques.csv'):\n",
        "    print(\"Running persuasion detection...\")\n",
        "    pers_model = pipeline(\"text-classification\", model=\"QCRI/propaganda-techniques-classification\", device=device)\n",
        "    pers_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            preds = pers_model(row['quote'][:512], top_k=3)\n",
        "            pers_results.append({\n",
        "                'row_id': row['row_id'],\n",
        "                'technique_1': preds[0]['label'],\n",
        "                'score_1': preds[0]['score'],\n",
        "                'technique_2': preds[1]['label'] if len(preds) > 1 else '',\n",
        "                'score_2': preds[1]['score'] if len(preds) > 1 else 0\n",
        "            })\n",
        "        except:\n",
        "            pers_results.append({'row_id': row['row_id'], 'technique_1': 'ERROR', 'score_1': 0})\n",
        "    pd.DataFrame(pers_results).to_csv(f'{output_dir}persuasion_techniques.csv', index=False)\n",
        "    del pers_model\n",
        "\n",
        "# 2. STANCE DETECTION\n",
        "if not os.path.exists(f'{output_dir}stance_detection.csv'):\n",
        "    print(\"Running stance detection...\")\n",
        "    stance_model = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-stance-climate\", device=device)\n",
        "    stance_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            pred = stance_model(row['quote'][:512])[0]\n",
        "            stance_results.append({'row_id': row['row_id'], 'stance': pred['label'], 'confidence': pred['score']})\n",
        "        except:\n",
        "            stance_results.append({'row_id': row['row_id'], 'stance': 'ERROR', 'confidence': 0})\n",
        "    pd.DataFrame(stance_results).to_csv(f'{output_dir}stance_detection.csv', index=False)\n",
        "    del stance_model\n",
        "\n",
        "# 3. ADVANCED METAPHOR DETECTION\n",
        "if not os.path.exists(f'{output_dir}metaphor_detection.csv'):\n",
        "    print(\"Running metaphor detection...\")\n",
        "    from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lwachowiak/Metaphor-Detection-XLMR\")\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\"lwachowiak/Metaphor-Detection-XLMR\")\n",
        "    metaphor_pipe = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, device=device, aggregation_strategy=\"simple\")\n",
        "\n",
        "    metaphor_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            pred = metaphor_pipe(row['quote'][:512])\n",
        "            has_metaphor = any(p['entity_group'] == 'LABEL_1' for p in pred)\n",
        "            metaphor_count = sum(1 for p in pred if p['entity_group'] == 'LABEL_1')\n",
        "            metaphor_results.append({'row_id': row['row_id'], 'has_metaphor': has_metaphor, 'metaphor_count': metaphor_count})\n",
        "        except:\n",
        "            metaphor_results.append({'row_id': row['row_id'], 'has_metaphor': False, 'metaphor_count': 0})\n",
        "    pd.DataFrame(metaphor_results).to_csv(f'{output_dir}metaphor_detection.csv', index=False)\n",
        "    del metaphor_pipe, model, tokenizer\n",
        "\n",
        "# 4. FRAME SEMANTICS (simplified version)\n",
        "if not os.path.exists(f'{output_dir}frame_semantics.csv'):\n",
        "    print(\"Running frame analysis...\")\n",
        "    frame_model = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", device=device, top_k=None)\n",
        "    frame_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            preds = frame_model(row['quote'][:512])\n",
        "            top_frames = sorted(preds[0], key=lambda x: x['score'], reverse=True)[:3]\n",
        "            frame_results.append({\n",
        "                'row_id': row['row_id'],\n",
        "                'frame_1': top_frames[0]['label'],\n",
        "                'frame_1_score': top_frames[0]['score'],\n",
        "                'frame_2': top_frames[1]['label'] if len(top_frames) > 1 else '',\n",
        "                'frame_2_score': top_frames[1]['score'] if len(top_frames) > 1 else 0\n",
        "            })\n",
        "        except:\n",
        "            frame_results.append({'row_id': row['row_id'], 'frame_1': 'ERROR', 'frame_1_score': 0})\n",
        "    pd.DataFrame(frame_results).to_csv(f'{output_dir}frame_semantics.csv', index=False)\n",
        "    del frame_model\n",
        "\n",
        "# 5. BOOKNLP (simplified - entity extraction)\n",
        "if not os.path.exists(f'{output_dir}booknlp_entities.csv'):\n",
        "    print(\"Running entity extraction...\")\n",
        "    !pip install -q spacy\n",
        "    !python -m spacy download en_core_web_sm\n",
        "    import spacy\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    entity_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        doc = nlp(row['quote'][:500])\n",
        "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "        persons = [e[0] for e in entities if e[1] == \"PERSON\"]\n",
        "        concepts = [e[0] for e in entities if e[1] in [\"ORG\", \"GPE\", \"NORP\"]]\n",
        "\n",
        "        entity_results.append({\n",
        "            'row_id': row['row_id'],\n",
        "            'num_entities': len(entities),\n",
        "            'persons': '|'.join(persons[:3]),\n",
        "            'concepts': '|'.join(concepts[:3]),\n",
        "            'entity_types': '|'.join(list(set([e[1] for e in entities])))\n",
        "        })\n",
        "    pd.DataFrame(entity_results).to_csv(f'{output_dir}booknlp_entities.csv', index=False)\n",
        "\n",
        "print(\"All missing analyses complete!\")"
      ],
      "metadata": {
        "id": "_4ms7MfROzOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "\n",
        "# Load and inspect the data\n",
        "data_path = '/content/drive/MyDrive/Chinese Philosophers/chinese_philosophers_quotes_corrected.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nColumn names:\", df.columns.tolist())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "eez5JQ-WR1aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from transformers import pipeline\n",
        "\n",
        "# Setup\n",
        "data_path = '/content/drive/MyDrive/Chinese Philosophers/chinese_philosophers_quotes_corrected.csv'\n",
        "output_dir = '/content/drive/MyDrive/Chinese Philosophers/'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# ADD ROW_ID COLUMN\n",
        "df['row_id'] = df.index\n",
        "\n",
        "print(f\"Processing {len(df)} quotes...\")\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# 1. PERSUASION/PROPAGANDA (binary classifier)\n",
        "if not os.path.exists(f'{output_dir}persuasion_techniques.csv'):\n",
        "    print(\"Running persuasion/propaganda detection (binary)...\")\n",
        "    pers_model = pipeline(\"text-classification\", model=\"valurank/distilroberta-propaganda-2class\", device=device)\n",
        "    pers_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            pred = pers_model(row['quote'][:512])[0]\n",
        "            pers_results.append({\n",
        "                'row_id': row['row_id'],\n",
        "                'has_propaganda': pred['label'],\n",
        "                'confidence': pred['score']\n",
        "            })\n",
        "        except:\n",
        "            pers_results.append({'row_id': row['row_id'], 'has_propaganda': 'ERROR', 'confidence': 0})\n",
        "    pd.DataFrame(pers_results).to_csv(f'{output_dir}persuasion_techniques.csv', index=False)\n",
        "    del pers_model\n",
        "\n",
        "# 2. FALLACY DETECTION\n",
        "if not os.path.exists(f'{output_dir}fallacy_detection.csv'):\n",
        "    print(\"Running fallacy detection...\")\n",
        "    fallacy_model = pipeline(\"text-classification\", model=\"q3fer/distilbert-base-fallacy-classification\", device=device)\n",
        "    fallacy_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            pred = fallacy_model(row['quote'][:512])[0]\n",
        "            fallacy_results.append({\n",
        "                'row_id': row['row_id'],\n",
        "                'fallacy_type': pred['label'],\n",
        "                'confidence': pred['score']\n",
        "            })\n",
        "        except:\n",
        "            fallacy_results.append({'row_id': row['row_id'], 'fallacy_type': 'ERROR', 'confidence': 0})\n",
        "    pd.DataFrame(fallacy_results).to_csv(f'{output_dir}fallacy_detection.csv', index=False)\n",
        "    del fallacy_model\n",
        "\n",
        "# 3. STANCE DETECTION\n",
        "if not os.path.exists(f'{output_dir}stance_detection.csv'):\n",
        "    print(\"Running stance detection...\")\n",
        "    stance_model = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-stance-climate\", device=device)\n",
        "    stance_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            pred = stance_model(row['quote'][:512])[0]\n",
        "            stance_results.append({'row_id': row['row_id'], 'stance': pred['label'], 'confidence': pred['score']})\n",
        "        except:\n",
        "            stance_results.append({'row_id': row['row_id'], 'stance': 'ERROR', 'confidence': 0})\n",
        "    pd.DataFrame(stance_results).to_csv(f'{output_dir}stance_detection.csv', index=False)\n",
        "    del stance_model\n",
        "\n",
        "# 4. ADVANCED METAPHOR DETECTION\n",
        "if not os.path.exists(f'{output_dir}metaphor_detection.csv'):\n",
        "    print(\"Running metaphor detection...\")\n",
        "    from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lwachowiak/Metaphor-Detection-XLMR\")\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\"lwachowiak/Metaphor-Detection-XLMR\")\n",
        "    metaphor_pipe = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, device=device, aggregation_strategy=\"simple\")\n",
        "\n",
        "    metaphor_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            pred = metaphor_pipe(row['quote'][:512])\n",
        "            has_metaphor = any(p['entity_group'] == 'LABEL_1' for p in pred)\n",
        "            metaphor_count = sum(1 for p in pred if p['entity_group'] == 'LABEL_1')\n",
        "            metaphor_results.append({'row_id': row['row_id'], 'has_metaphor': has_metaphor, 'metaphor_count': metaphor_count})\n",
        "        except:\n",
        "            metaphor_results.append({'row_id': row['row_id'], 'has_metaphor': False, 'metaphor_count': 0})\n",
        "    pd.DataFrame(metaphor_results).to_csv(f'{output_dir}metaphor_detection.csv', index=False)\n",
        "    del metaphor_pipe, model, tokenizer\n",
        "\n",
        "# 5. EMOTION/FRAME SEMANTICS\n",
        "if not os.path.exists(f'{output_dir}frame_semantics.csv'):\n",
        "    print(\"Running emotion/frame analysis...\")\n",
        "    frame_model = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", device=device, top_k=None)\n",
        "    frame_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            preds = frame_model(row['quote'][:512])\n",
        "            top_frames = sorted(preds[0], key=lambda x: x['score'], reverse=True)[:3]\n",
        "            frame_results.append({\n",
        "                'row_id': row['row_id'],\n",
        "                'emotion_1': top_frames[0]['label'],\n",
        "                'emotion_1_score': top_frames[0]['score'],\n",
        "                'emotion_2': top_frames[1]['label'] if len(top_frames) > 1 else '',\n",
        "                'emotion_2_score': top_frames[1]['score'] if len(top_frames) > 1 else 0\n",
        "            })\n",
        "        except:\n",
        "            frame_results.append({'row_id': row['row_id'], 'emotion_1': 'ERROR', 'emotion_1_score': 0})\n",
        "    pd.DataFrame(frame_results).to_csv(f'{output_dir}frame_semantics.csv', index=False)\n",
        "    del frame_model\n",
        "\n",
        "# 6. ENTITY EXTRACTION\n",
        "if not os.path.exists(f'{output_dir}booknlp_entities.csv'):\n",
        "    print(\"Running entity extraction...\")\n",
        "    !pip install -q spacy\n",
        "    !python -m spacy download en_core_web_sm -q\n",
        "    import spacy\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    entity_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        doc = nlp(row['quote'][:500])\n",
        "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "        persons = [e[0] for e in entities if e[1] == \"PERSON\"]\n",
        "        concepts = [e[0] for e in entities if e[1] in [\"ORG\", \"GPE\", \"NORP\"]]\n",
        "\n",
        "        entity_results.append({\n",
        "            'row_id': row['row_id'],\n",
        "            'num_entities': len(entities),\n",
        "            'persons': '|'.join(persons[:3]),\n",
        "            'concepts': '|'.join(concepts[:3]),\n",
        "            'entity_types': '|'.join(list(set([e[1] for e in entities])))\n",
        "        })\n",
        "    pd.DataFrame(entity_results).to_csv(f'{output_dir}booknlp_entities.csv', index=False)\n",
        "\n",
        "print(\"\\n✅ All analyses complete!\")\n",
        "print(f\"Files saved to: {output_dir}\")"
      ],
      "metadata": {
        "id": "_MgYlv5fRNpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
        "import gc\n",
        "\n",
        "# Setup\n",
        "data_path = '/content/drive/MyDrive/Chinese Philosophers/chinese_philosophers_quotes_corrected.csv'\n",
        "output_dir = '/content/drive/MyDrive/Chinese Philosophers/'\n",
        "df = pd.read_csv(data_path)\n",
        "df['row_id'] = df.index\n",
        "\n",
        "# SIMPLIFIED METAPHOR DETECTION - Use a lighter approach\n",
        "print(\"Running simplified metaphor detection...\")\n",
        "\n",
        "# Option 1: Skip the problematic XLMR model and use a simpler classifier\n",
        "from transformers import pipeline\n",
        "\n",
        "metaphor_model = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", device=-1)\n",
        "\n",
        "metaphor_results = []\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    try:\n",
        "        # Use emotion intensity as proxy for figurative language\n",
        "        pred = metaphor_model(row['quote'][:400])[0]  # Shorter text\n",
        "        # High emotion often correlates with metaphorical language\n",
        "        has_metaphor = pred['score'] > 0.7 and pred['label'] in ['joy', 'anger', 'fear', 'surprise']\n",
        "        metaphor_results.append({\n",
        "            'row_id': row['row_id'],\n",
        "            'has_metaphor': has_metaphor,\n",
        "            'metaphor_proxy': pred['label'],\n",
        "            'score': pred['score']\n",
        "        })\n",
        "    except:\n",
        "        metaphor_results.append({'row_id': row['row_id'], 'has_metaphor': False, 'metaphor_proxy': 'error', 'score': 0})\n",
        "\n",
        "    # Save progress every 200 quotes\n",
        "    if (idx + 1) % 200 == 0:\n",
        "        pd.DataFrame(metaphor_results).to_csv(f'{output_dir}metaphor_detection_temp.csv', index=False)\n",
        "\n",
        "# Save final results\n",
        "pd.DataFrame(metaphor_results).to_csv(f'{output_dir}metaphor_detection.csv', index=False)\n",
        "del metaphor_model\n",
        "gc.collect()\n",
        "print(\"✓ Metaphor detection complete (simplified)\")\n",
        "\n",
        "# 2. FRAME SEMANTICS (if not done)\n",
        "import os\n",
        "if not os.path.exists(f'{output_dir}frame_semantics.csv'):\n",
        "    print(\"Running frame analysis...\")\n",
        "    frame_model = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", device=-1, top_k=None)\n",
        "    frame_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            preds = frame_model(row['quote'][:400])\n",
        "            top_frames = sorted(preds[0], key=lambda x: x['score'], reverse=True)[:3]\n",
        "            frame_results.append({\n",
        "                'row_id': row['row_id'],\n",
        "                'emotion_1': top_frames[0]['label'],\n",
        "                'emotion_1_score': top_frames[0]['score'],\n",
        "                'emotion_2': top_frames[1]['label'] if len(top_frames) > 1 else '',\n",
        "                'emotion_2_score': top_frames[1]['score'] if len(top_frames) > 1 else 0\n",
        "            })\n",
        "        except:\n",
        "            frame_results.append({'row_id': row['row_id'], 'emotion_1': 'ERROR', 'emotion_1_score': 0})\n",
        "    pd.DataFrame(frame_results).to_csv(f'{output_dir}frame_semantics.csv', index=False)\n",
        "    del frame_model\n",
        "\n",
        "# 3. ENTITY EXTRACTION (if not done)\n",
        "if not os.path.exists(f'{output_dir}booknlp_entities.csv'):\n",
        "    print(\"Running entity extraction...\")\n",
        "    !pip install -q spacy\n",
        "    !python -m spacy download en_core_web_sm -q\n",
        "    import spacy\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    entity_results = []\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        doc = nlp(row['quote'][:400])  # Shorter text\n",
        "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "        persons = [e[0] for e in entities if e[1] == \"PERSON\"]\n",
        "        concepts = [e[0] for e in entities if e[1] in [\"ORG\", \"GPE\", \"NORP\"]]\n",
        "\n",
        "        entity_results.append({\n",
        "            'row_id': row['row_id'],\n",
        "            'num_entities': len(entities),\n",
        "            'persons': '|'.join(persons[:3]),\n",
        "            'concepts': '|'.join(concepts[:3]),\n",
        "            'entity_types': '|'.join(list(set([e[1] for e in entities])))\n",
        "        })\n",
        "    pd.DataFrame(entity_results).to_csv(f'{output_dir}booknlp_entities.csv', index=False)\n",
        "\n",
        "print(\"\\n✅ All analyses complete!\")"
      ],
      "metadata": {
        "id": "uiBRu7S4ekJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install transformers torch pandas tqdm huggingface_hub -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Login to Hugging Face\n",
        "login(token=\"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\")\n",
        "\n",
        "# Set device\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "print(f\"Using device: {'GPU' if device == 0 else 'CPU'}\")\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Chinese Philosophers/chinese_philosophers_quotes_corrected.csv')\n",
        "df['row_id'] = df.index\n",
        "print(f\"Loaded {len(df)} quotes\")\n",
        "\n",
        "# Prepare quotes list\n",
        "quotes = df['quote'].tolist()\n",
        "\n",
        "def run_classification_model(model_name, quotes_list, output_filename, task_type=\"text-classification\", batch_size=16):\n",
        "    \"\"\"Run a classification model and save results\"\"\"\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Running: {model_name}\")\n",
        "    print(f\"Output: {output_filename}\")\n",
        "\n",
        "    try:\n",
        "        # Initialize pipeline\n",
        "        classifier = pipeline(task_type, model=model_name, device=device)\n",
        "\n",
        "        # Process in batches\n",
        "        all_results = []\n",
        "        for i in tqdm(range(0, len(quotes_list), batch_size), desc=\"Processing\"):\n",
        "            batch = quotes_list[i:i+batch_size]\n",
        "            # Truncate long texts\n",
        "            batch = [q[:512] if isinstance(q, str) else \"\" for q in batch]\n",
        "\n",
        "            try:\n",
        "                results = classifier(batch)\n",
        "                all_results.extend(results)\n",
        "            except Exception as e:\n",
        "                print(f\"Batch error: {e}\")\n",
        "                # Process individually if batch fails\n",
        "                for text in batch:\n",
        "                    try:\n",
        "                        result = classifier(text)\n",
        "                        all_results.append(result if isinstance(result, dict) else result[0])\n",
        "                    except:\n",
        "                        all_results.append({'label': 'ERROR', 'score': 0.0})\n",
        "\n",
        "        # Convert results to DataFrame\n",
        "        if all_results and isinstance(all_results[0], list):\n",
        "            # Multi-label results\n",
        "            results_df = pd.DataFrame({\n",
        "                'row_id': range(len(all_results)),\n",
        "                'predictions': all_results\n",
        "            })\n",
        "        else:\n",
        "            # Single-label results\n",
        "            results_df = pd.DataFrame({\n",
        "                'row_id': range(len(all_results)),\n",
        "                'label': [r.get('label', 'ERROR') if isinstance(r, dict) else 'ERROR' for r in all_results],\n",
        "                'score': [r.get('score', 0.0) if isinstance(r, dict) else 0.0 for r in all_results]\n",
        "            })\n",
        "\n",
        "        # Save to CSV\n",
        "        output_path = f'/content/drive/MyDrive/Chinese Philosophers/{output_filename}'\n",
        "        results_df.to_csv(output_path, index=False)\n",
        "        print(f\"✅ Saved: {output_filename}\")\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def run_zero_shot_classification(model_name, quotes_list, candidate_labels, output_filename, batch_size=8):\n",
        "    \"\"\"Run zero-shot classification with custom labels\"\"\"\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Running Zero-Shot: {model_name}\")\n",
        "    print(f\"Labels: {candidate_labels}\")\n",
        "\n",
        "    try:\n",
        "        classifier = pipeline(\"zero-shot-classification\", model=model_name, device=device)\n",
        "\n",
        "        all_results = []\n",
        "        for i in tqdm(range(0, len(quotes_list), batch_size), desc=\"Processing\"):\n",
        "            batch = quotes_list[i:i+batch_size]\n",
        "            batch = [q[:512] if isinstance(q, str) else \"\" for q in batch]\n",
        "\n",
        "            for text in batch:\n",
        "                try:\n",
        "                    result = classifier(text, candidate_labels=candidate_labels)\n",
        "                    all_results.append({\n",
        "                        'top_label': result['labels'][0],\n",
        "                        'top_score': result['scores'][0],\n",
        "                        'all_scores': dict(zip(result['labels'], result['scores']))\n",
        "                    })\n",
        "                except:\n",
        "                    all_results.append({\n",
        "                        'top_label': 'ERROR',\n",
        "                        'top_score': 0.0,\n",
        "                        'all_scores': {}\n",
        "                    })\n",
        "\n",
        "        results_df = pd.DataFrame(all_results)\n",
        "        results_df['row_id'] = range(len(results_df))\n",
        "\n",
        "        output_path = f'/content/drive/MyDrive/Chinese Philosophers/{output_filename}'\n",
        "        results_df.to_csv(output_path, index=False)\n",
        "        print(f\"✅ Saved: {output_filename}\")\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# Run all the new models\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STARTING CLASSIFICATION PIPELINE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Evidence Types\n",
        "run_classification_model(\n",
        "    \"marieke93/MiniLM-evidence-types\",\n",
        "    quotes,\n",
        "    \"evidence_types.csv\"\n",
        ")\n",
        "\n",
        "# 2. Virtue Ethics\n",
        "run_classification_model(\n",
        "    \"davidschulte/ESM_metaeval__ethics_virtue\",\n",
        "    quotes,\n",
        "    \"virtue_ethics.csv\"\n",
        ")\n",
        "\n",
        "# 3. 43-Emotion Categories\n",
        "run_classification_model(\n",
        "    \"borisn70/bert-43-multilabel-emotion-detection\",\n",
        "    quotes,\n",
        "    \"emotion_43_categories.csv\"\n",
        ")\n",
        "\n",
        "# 4. Chinese Emotion (if you have Chinese text)\n",
        "# Uncomment if you have Chinese translations\n",
        "# run_classification_model(\n",
        "#     \"Johnson8187/Chinese-Emotion\",\n",
        "#     quotes,  # Use Chinese quotes here\n",
        "#     \"chinese_emotion.csv\"\n",
        "# )\n",
        "\n",
        "# 5. Text Register/Formality\n",
        "run_classification_model(\n",
        "    \"TurkuNLP/web-register-classification-multilingual\",\n",
        "    quotes,\n",
        "    \"text_register.csv\"\n",
        ")\n",
        "\n",
        "# 6. Intent Classification\n",
        "run_classification_model(\n",
        "    \"Falconsai/intent_classification\",\n",
        "    quotes,\n",
        "    \"intent_classification.csv\"\n",
        ")\n",
        "\n",
        "# 7. Question Detection\n",
        "run_classification_model(\n",
        "    \"shahrukhx01/bert-mini-finetune-question-detection\",\n",
        "    quotes,\n",
        "    \"question_detection.csv\"\n",
        ")\n",
        "\n",
        "# 8. Action-Context-Consequence\n",
        "run_classification_model(\n",
        "    \"moralstories/roberta-large_action-context-consequence\",\n",
        "    quotes,\n",
        "    \"action_consequence.csv\"\n",
        ")\n",
        "\n",
        "# 9. Relationship Detection\n",
        "run_classification_model(\n",
        "    \"anushka37/relationship-detector\",\n",
        "    quotes,\n",
        "    \"relationship_detection.csv\"\n",
        ")\n",
        "\n",
        "# 10. Zero-shot for Philosophical Concepts\n",
        "philosophical_concepts = [\n",
        "    \"virtue ethics\",\n",
        "    \"consequentialism\",\n",
        "    \"moral exemplar\",\n",
        "    \"historical precedent\",\n",
        "    \"social harmony\",\n",
        "    \"individual cultivation\",\n",
        "    \"universal love\",\n",
        "    \"pragmatic governance\",\n",
        "    \"ritual propriety\",\n",
        "    \"moral instruction\"\n",
        "]\n",
        "\n",
        "run_zero_shot_classification(\n",
        "    \"facebook/bart-large-mnli\",\n",
        "    quotes,\n",
        "    philosophical_concepts,\n",
        "    \"philosophical_concepts_zeroshot.csv\"\n",
        ")\n",
        "\n",
        "# 11. Zero-shot for Pedagogical Methods\n",
        "pedagogical_methods = [\n",
        "    \"direct instruction\",\n",
        "    \"socratic questioning\",\n",
        "    \"parable or storytelling\",\n",
        "    \"historical example\",\n",
        "    \"moral exemplar\",\n",
        "    \"philosophical argument\",\n",
        "    \"practical advice\",\n",
        "    \"ritual explanation\"\n",
        "]\n",
        "\n",
        "run_zero_shot_classification(\n",
        "    \"facebook/bart-large-mnli\",\n",
        "    quotes,\n",
        "    pedagogical_methods,\n",
        "    \"pedagogical_methods_zeroshot.csv\"\n",
        ")\n",
        "\n",
        "# 12. Enhanced Multilingual Zero-shot\n",
        "chinese_philosophy_schools = [\n",
        "    \"Confucian ethics\",\n",
        "    \"Mohist utilitarianism\",\n",
        "    \"Daoist naturalism\",\n",
        "    \"Legalist pragmatism\",\n",
        "    \"Buddhist compassion\"\n",
        "]\n",
        "\n",
        "run_zero_shot_classification(\n",
        "    \"DAMO-NLP-SG/zero-shot-classify-SSTuning-XLM-R\",\n",
        "    quotes,\n",
        "    chinese_philosophy_schools,\n",
        "    \"philosophy_schools_xlmr.csv\"\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CLASSIFICATION PIPELINE COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nAll results saved to: /content/drive/MyDrive/Chinese Philosophers/\")\n",
        "print(\"\\nCompleted analyses:\")\n",
        "import os\n",
        "output_dir = \"/content/drive/MyDrive/Chinese Philosophers/\"\n",
        "csv_files = [f for f in os.listdir(output_dir) if f.endswith('.csv') and any(x in f for x in [\n",
        "    'evidence_types', 'virtue_ethics', 'emotion_43', 'text_register',\n",
        "    'intent_classification', 'question_detection', 'action_consequence',\n",
        "    'relationship_detection', 'philosophical_concepts', 'pedagogical_methods',\n",
        "    'philosophy_schools'\n",
        "])]\n",
        "for f in sorted(csv_files):\n",
        "    print(f\"  ✅ {f}\")"
      ],
      "metadata": {
        "id": "Ap68wyQvhFpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick analysis of what you ACTUALLY have in your data\n",
        "import pandas as pd\n",
        "\n",
        "# Load your existing keyword extractions\n",
        "keywords = pd.read_csv('/content/drive/MyDrive/Chinese Philosophers/[your_keywords_file].csv')\n",
        "topics = pd.read_csv('/content/drive/MyDrive/Chinese Philosophers/[bertopic_output].csv')\n",
        "\n",
        "# See what themes YOUR DATA actually contains\n",
        "print(\"Actual topics from BERTopic:\")\n",
        "print(topics.head(20))\n",
        "\n",
        "# If you must do zero-shot, use data-derived labels:\n",
        "# 1. Extract top topics from your BERTopic analysis\n",
        "# 2. Use high-frequency meaningful terms from your keyword extraction\n",
        "# 3. Or use known Chinese philosophical concepts that actually appear in the text"
      ],
      "metadata": {
        "id": "AQmwe4mry8ZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# List all CSV files in your Chinese Philosophers directory\n",
        "directory = '/content/drive/MyDrive/Chinese Philosophers/'\n",
        "csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
        "\n",
        "print(\"CSV files in your directory:\")\n",
        "for i, file in enumerate(sorted(csv_files)):\n",
        "    print(f\"{i+1}. {file}\")\n",
        "\n",
        "# Check for keyword/topic related files\n",
        "keyword_files = [f for f in csv_files if 'keyword' in f.lower() or 'topic' in f.lower() or 'bert' in f.lower()]\n",
        "if keyword_files:\n",
        "    print(\"\\nPotential keyword/topic files:\")\n",
        "    for f in keyword_files:\n",
        "        print(f\"  - {f}\")\n",
        "else:\n",
        "    print(\"\\nNo files with 'keyword', 'topic', or 'bert' in the name found.\")\n",
        "\n",
        "# Show all analysis files you've created\n",
        "print(\"\\nYour analysis files:\")\n",
        "analysis_files = ['argument_mining.csv', 'moral_foundations.csv', 'dialogue_acts.csv',\n",
        "                  'figurative_language.csv', 'semantic_roles.csv', 'nli_comparisons.csv',\n",
        "                  'crossencoder_alignments.csv', 'persuasion_techniques.csv',\n",
        "                  'fallacy_detection.csv', 'stance_detection.csv', 'metaphor_detection.csv',\n",
        "                  'frame_semantics.csv', 'booknlp_entities.csv']\n",
        "\n",
        "for file in analysis_files:\n",
        "    path = os.path.join(directory, file)\n",
        "    if os.path.exists(path):\n",
        "        df = pd.read_csv(path)\n",
        "        print(f\"✓ {file}: {len(df)} rows\")"
      ],
      "metadata": {
        "id": "fLpIsvW_0krd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Mount drive if not already mounted\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Navigate to your project directory\n",
        "project_dir = '/content/drive/MyDrive/Chinese Philosophers/'\n",
        "\n",
        "# List all CSV files with details\n",
        "print(\"=== ANALYSIS FILES IN YOUR PROJECT ===\\n\")\n",
        "csv_files = []\n",
        "for file in os.listdir(project_dir):\n",
        "    if file.endswith('.csv'):\n",
        "        filepath = os.path.join(project_dir, file)\n",
        "        size = os.path.getsize(filepath) / 1024  # Size in KB\n",
        "        modified = datetime.fromtimestamp(os.path.getmtime(filepath))\n",
        "        csv_files.append({\n",
        "            'File': file,\n",
        "            'Size (KB)': f\"{size:.1f}\",\n",
        "            'Last Modified': modified.strftime('%Y-%m-%d %H:%M')\n",
        "        })\n",
        "\n",
        "# Display as a sorted table\n",
        "if csv_files:\n",
        "    df_files = pd.DataFrame(csv_files)\n",
        "    df_files = df_files.sort_values('File')\n",
        "    print(df_files.to_string(index=False))\n",
        "    print(f\"\\n✅ Total CSV files found: {len(csv_files)}\")\n",
        "else:\n",
        "    print(\"❌ No CSV files found in the directory\")\n",
        "\n",
        "# Check for the main dataset\n",
        "main_file = '/content/drive/MyDrive/Chinese Philosophers/chinese_philosophers_quotes_corrected.csv'\n",
        "if os.path.exists(main_file):\n",
        "    df = pd.read_csv(main_file)\n",
        "    print(f\"\\n📊 Main dataset: {df.shape[0]} quotes × {df.shape[1]} columns\")\n",
        "    print(f\"   Philosophers: {df['philosopher'].value_counts().to_dict()}\")"
      ],
      "metadata": {
        "id": "YHsm8FSy2p6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the Missing Analyses\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setup\n",
        "base_path = '/content/drive/MyDrive/Chinese Philosophers/'\n",
        "df = pd.read_csv(f'{base_path}chinese_philosophers_quotes_corrected.csv')\n",
        "df['row_id'] = df.index\n",
        "quotes = df['quote'].tolist()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"COMPLETING MISSING ANALYSES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. MORAL FOUNDATIONS - Using keyword-based approach with validation\n",
        "print(\"\\n1. Moral Foundations Analysis...\")\n",
        "moral_foundations = {\n",
        "    'care_harm': ['care', 'harm', 'suffering', 'kindness', 'cruel', 'hurt', 'compassion', 'pain', 'protect', 'safe'],\n",
        "    'fairness_cheating': ['fair', 'equal', 'justice', 'rights', 'cheat', 'honest', 'deserve', 'reciprocal', 'balanced'],\n",
        "    'loyalty_betrayal': ['loyal', 'betray', 'team', 'family', 'group', 'traitor', 'united', 'solidarity', 'patriot'],\n",
        "    'authority_subversion': ['authority', 'respect', 'tradition', 'rebel', 'obey', 'honor', 'law', 'duty', 'hierarchy'],\n",
        "    'sanctity_degradation': ['sacred', 'pure', 'disgusting', 'noble', 'virtue', 'degradation', 'holy', 'contaminate', 'pristine']\n",
        "}\n",
        "\n",
        "moral_results = []\n",
        "for i, quote in enumerate(tqdm(quotes, desc=\"Processing moral foundations\")):\n",
        "    if isinstance(quote, str):\n",
        "        quote_lower = quote.lower()\n",
        "        scores = {}\n",
        "        for foundation, keywords in moral_foundations.items():\n",
        "            # Count weighted keyword presence\n",
        "            score = sum(2 if k in quote_lower.split() else 1 if k in quote_lower else 0\n",
        "                       for k in keywords)\n",
        "            scores[foundation] = score\n",
        "\n",
        "        # Get primary and secondary foundations\n",
        "        sorted_foundations = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        primary = sorted_foundations[0][0] if sorted_foundations[0][1] > 0 else 'none'\n",
        "        secondary = sorted_foundations[1][0] if len(sorted_foundations) > 1 and sorted_foundations[1][1] > 0 else 'none'\n",
        "\n",
        "        moral_results.append({\n",
        "            'row_id': i,\n",
        "            'primary_foundation': primary,\n",
        "            'secondary_foundation': secondary,\n",
        "            **{f'{k}_score': v for k, v in scores.items()}\n",
        "        })\n",
        "    else:\n",
        "        moral_results.append({'row_id': i, 'primary_foundation': 'ERROR'})\n",
        "\n",
        "pd.DataFrame(moral_results).to_csv(f'{base_path}moral_foundations.csv', index=False)\n",
        "print(\"✅ Saved moral_foundations.csv\")\n",
        "\n",
        "# 2. DIALOGUE ACTS\n",
        "print(\"\\n2. Dialogue Acts Classification...\")\n",
        "try:\n",
        "    from transformers import pipeline\n",
        "    dialogue_classifier = pipeline(\n",
        "        \"text-classification\",\n",
        "        model=\"diwank/silicone-deberta-pair\",  # Alternative dialogue act model\n",
        "        device=-1\n",
        "    )\n",
        "\n",
        "    dialogue_results = []\n",
        "    batch_size = 8\n",
        "\n",
        "    for i in tqdm(range(0, len(quotes), batch_size), desc=\"Processing dialogue acts\"):\n",
        "        batch = quotes[i:i+batch_size]\n",
        "        batch = [q[:512] if isinstance(q, str) else \"\" for q in batch]\n",
        "\n",
        "        try:\n",
        "            results = dialogue_classifier(batch)\n",
        "            for j, result in enumerate(results):\n",
        "                dialogue_results.append({\n",
        "                    'row_id': i + j,\n",
        "                    'dialogue_act': result['label'],\n",
        "                    'confidence': result['score']\n",
        "                })\n",
        "        except Exception as e:\n",
        "            for j in range(len(batch)):\n",
        "                dialogue_results.append({\n",
        "                    'row_id': i + j,\n",
        "                    'dialogue_act': 'ERROR',\n",
        "                    'confidence': 0.0\n",
        "                })\n",
        "\n",
        "    pd.DataFrame(dialogue_results).to_csv(f'{base_path}dialogue_acts.csv', index=False)\n",
        "    print(\"✅ Saved dialogue_acts.csv\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Dialogue acts failed: {e}\")\n",
        "\n",
        "# 3. FIGURATIVE LANGUAGE (Irony/Sarcasm)\n",
        "print(\"\\n3. Figurative Language Detection...\")\n",
        "try:\n",
        "    irony_classifier = pipeline(\n",
        "        \"text-classification\",\n",
        "        model=\"cardiffnlp/twitter-roberta-base-irony\",\n",
        "        device=-1\n",
        "    )\n",
        "\n",
        "    figurative_results = []\n",
        "    for i in tqdm(range(len(quotes)), desc=\"Processing figurative language\"):\n",
        "        try:\n",
        "            text = quotes[i][:512] if isinstance(quotes[i], str) else \"\"\n",
        "            result = irony_classifier(text)\n",
        "            figurative_results.append({\n",
        "                'row_id': i,\n",
        "                'is_ironic': result[0]['label'] == 'LABEL_1',  # LABEL_1 is ironic\n",
        "                'irony_confidence': result[0]['score'] if result[0]['label'] == 'LABEL_1' else 1 - result[0]['score']\n",
        "            })\n",
        "        except:\n",
        "            figurative_results.append({'row_id': i, 'is_ironic': False, 'irony_confidence': 0.0})\n",
        "\n",
        "    pd.DataFrame(figurative_results).to_csv(f'{base_path}figurative_language.csv', index=False)\n",
        "    print(\"✅ Saved figurative_language.csv\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Figurative language failed: {e}\")\n",
        "\n",
        "# 4. SEMANTIC ROLES - Simplified version using spaCy\n",
        "print(\"\\n4. Semantic Role Labeling...\")\n",
        "try:\n",
        "    import spacy\n",
        "    # Try to load spacy model, install if needed\n",
        "    try:\n",
        "        nlp = spacy.load(\"en_core_web_sm\")\n",
        "    except:\n",
        "        import subprocess\n",
        "        subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
        "        nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    semantic_results = []\n",
        "    for i in tqdm(range(len(quotes)), desc=\"Processing semantic roles\"):\n",
        "        try:\n",
        "            if isinstance(quotes[i], str):\n",
        "                doc = nlp(quotes[i][:1000])  # Limit length for speed\n",
        "\n",
        "                # Extract basic semantic roles\n",
        "                agents = []\n",
        "                patients = []\n",
        "                actions = []\n",
        "\n",
        "                for token in doc:\n",
        "                    if token.dep_ == \"nsubj\":  # Subject (often agent)\n",
        "                        agents.append(token.text)\n",
        "                    elif token.dep_ == \"dobj\":  # Direct object (often patient)\n",
        "                        patients.append(token.text)\n",
        "                    elif token.pos_ == \"VERB\":  # Actions\n",
        "                        actions.append(token.lemma_)\n",
        "\n",
        "                semantic_results.append({\n",
        "                    'row_id': i,\n",
        "                    'agents': '|'.join(agents) if agents else 'none',\n",
        "                    'patients': '|'.join(patients) if patients else 'none',\n",
        "                    'actions': '|'.join(actions[:5]) if actions else 'none',  # Top 5 actions\n",
        "                    'num_agents': len(agents),\n",
        "                    'num_patients': len(patients),\n",
        "                    'num_actions': len(actions)\n",
        "                })\n",
        "            else:\n",
        "                semantic_results.append({'row_id': i, 'agents': 'ERROR'})\n",
        "\n",
        "        except Exception as e:\n",
        "            semantic_results.append({'row_id': i, 'agents': 'ERROR'})\n",
        "\n",
        "    pd.DataFrame(semantic_results).to_csv(f'{base_path}semantic_roles.csv', index=False)\n",
        "    print(\"✅ Saved semantic_roles.csv\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Semantic roles failed: {e}\")\n",
        "\n",
        "# 5. NLI COMPARISONS (Confucius vs Mozi)\n",
        "print(\"\\n5. NLI Comparisons Between Philosophers...\")\n",
        "try:\n",
        "    from transformers import pipeline\n",
        "    nli_classifier = pipeline(\n",
        "        \"zero-shot-classification\",\n",
        "        model=\"facebook/bart-large-mnli\",\n",
        "        device=-1\n",
        "    )\n",
        "\n",
        "    # Create pairs for comparison (sample for efficiency)\n",
        "    conf_quotes = df[df['philosopher'] == 'Confucius']['quote'].tolist()\n",
        "    mozi_quotes = df[df['philosopher'] == 'Mozi']['quote'].tolist()\n",
        "\n",
        "    # Sample 100 random pairs for feasibility\n",
        "    np.random.seed(42)\n",
        "    num_pairs = min(100, len(conf_quotes), len(mozi_quotes))\n",
        "    conf_sample = np.random.choice(conf_quotes, num_pairs, replace=False)\n",
        "    mozi_sample = np.random.choice(mozi_quotes, num_pairs, replace=False)\n",
        "\n",
        "    nli_results = []\n",
        "    for i in tqdm(range(num_pairs), desc=\"Processing NLI pairs\"):\n",
        "        try:\n",
        "            c_quote = conf_sample[i][:256] if isinstance(conf_sample[i], str) else \"\"\n",
        "            m_quote = mozi_sample[i][:256] if isinstance(mozi_sample[i], str) else \"\"\n",
        "\n",
        "            # Check if Mozi quote entails, contradicts, or is neutral to Confucius quote\n",
        "            result = nli_classifier(\n",
        "                c_quote,\n",
        "                candidate_labels=[m_quote],\n",
        "                hypothesis_template=\"This text means: {}\"\n",
        "            )\n",
        "\n",
        "            # Determine relationship based on score\n",
        "            score = result['scores'][0]\n",
        "            if score > 0.7:\n",
        "                relationship = 'entailment'\n",
        "            elif score < 0.3:\n",
        "                relationship = 'contradiction'\n",
        "            else:\n",
        "                relationship = 'neutral'\n",
        "\n",
        "            nli_results.append({\n",
        "                'pair_id': i,\n",
        "                'confucius_quote': c_quote[:100] + '...' if len(c_quote) > 100 else c_quote,\n",
        "                'mozi_quote': m_quote[:100] + '...' if len(m_quote) > 100 else m_quote,\n",
        "                'relationship': relationship,\n",
        "                'confidence': score\n",
        "            })\n",
        "        except:\n",
        "            nli_results.append({'pair_id': i, 'relationship': 'ERROR', 'confidence': 0.0})\n",
        "\n",
        "    pd.DataFrame(nli_results).to_csv(f'{base_path}nli_comparisons.csv', index=False)\n",
        "    print(f\"✅ Saved nli_comparisons.csv ({num_pairs} pairs)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ NLI comparisons failed: {e}\")\n",
        "\n",
        "# 6. CROSS-ENCODER ALIGNMENTS\n",
        "print(\"\\n6. Cross-Encoder Semantic Similarity...\")\n",
        "try:\n",
        "    from sentence_transformers import CrossEncoder\n",
        "\n",
        "    # Load cross-encoder model\n",
        "    model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "    # Use same samples as NLI for consistency\n",
        "    similarity_results = []\n",
        "\n",
        "    for i in tqdm(range(num_pairs), desc=\"Processing similarity pairs\"):\n",
        "        try:\n",
        "            c_quote = conf_sample[i] if isinstance(conf_sample[i], str) else \"\"\n",
        "            m_quote = mozi_sample[i] if isinstance(mozi_sample[i], str) else \"\"\n",
        "\n",
        "            # Get similarity score\n",
        "            score = model.predict([[c_quote[:512], m_quote[:512]]])[0]\n",
        "\n",
        "            # Normalize score to 0-1 range\n",
        "            normalized_score = (score + 1) / 2 if score < 0 else min(score, 1)\n",
        "\n",
        "            similarity_results.append({\n",
        "                'pair_id': i,\n",
        "                'similarity_score': normalized_score,\n",
        "                'similarity_category': 'high' if normalized_score > 0.7 else 'medium' if normalized_score > 0.4 else 'low'\n",
        "            })\n",
        "        except:\n",
        "            similarity_results.append({'pair_id': i, 'similarity_score': 0.0, 'similarity_category': 'ERROR'})\n",
        "\n",
        "    pd.DataFrame(similarity_results).to_csv(f'{base_path}crossencoder_alignments.csv', index=False)\n",
        "    print(f\"✅ Saved crossencoder_alignments.csv ({num_pairs} pairs)\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"❌ Cross-encoder failed: Install sentence-transformers with: !pip install sentence-transformers\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Cross-encoder failed: {e}\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPLETION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "completed = []\n",
        "for file in ['moral_foundations.csv', 'dialogue_acts.csv', 'figurative_language.csv',\n",
        "             'semantic_roles.csv', 'nli_comparisons.csv', 'crossencoder_alignments.csv']:\n",
        "    if os.path.exists(f'{base_path}{file}'):\n",
        "        size = os.path.getsize(f'{base_path}{file}') / 1024\n",
        "        completed.append(f\"✅ {file} ({size:.1f} KB)\")\n",
        "    else:\n",
        "        completed.append(f\"❌ {file} - Not created\")\n",
        "\n",
        "for item in completed:\n",
        "    print(item)\n",
        "\n",
        "print(\"\\nAll 6 missing analyses have been attempted!\")\n",
        "print(\"Next step: Create master dataset and run comparative analysis\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dYBgFFRn340C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm\n",
        "import os # Import the os module\n",
        "\n",
        "base_path = '/content/drive/MyDrive/Chinese Philosophers/'\n",
        "df = pd.read_csv(f'{base_path}chinese_philosophers_quotes_corrected.csv')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"COMPLETING REMAINING ANALYSES (Lightweight versions)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 5. NLI COMPARISONS - Using TF-IDF similarity as proxy\n",
        "print(\"\\n5. Philosopher Quote Comparisons (TF-IDF method)...\")\n",
        "\n",
        "conf_quotes = df[df['philosopher'] == 'Confucius']\n",
        "mozi_quotes = df[df['philosopher'] == 'Mozi']\n",
        "\n",
        "# Sample 150 quotes from each for comparison\n",
        "np.random.seed(42)\n",
        "n_samples = min(150, len(conf_quotes), len(mozi_quotes))\n",
        "conf_sample = conf_quotes.sample(n=n_samples)\n",
        "mozi_sample = mozi_quotes.sample(n=n_samples)\n",
        "\n",
        "# Vectorize all quotes\n",
        "vectorizer = TfidfVectorizer(max_features=500, stop_words='english')\n",
        "all_quotes = list(conf_sample['quote'].fillna('')) + list(mozi_sample['quote'].fillna(''))\n",
        "tfidf_matrix = vectorizer.fit_transform(all_quotes)\n",
        "\n",
        "# Calculate similarities\n",
        "conf_vectors = tfidf_matrix[:n_samples]\n",
        "mozi_vectors = tfidf_matrix[n_samples:]\n",
        "\n",
        "nli_results = []\n",
        "for i in tqdm(range(n_samples), desc=\"Comparing quotes\"):\n",
        "    # Get similarity score\n",
        "    similarity = cosine_similarity(conf_vectors[i:i+1], mozi_vectors[i:i+1])[0][0]\n",
        "\n",
        "    # Classify relationship based on similarity and keyword overlap\n",
        "    c_text = conf_sample.iloc[i]['quote'] if pd.notna(conf_sample.iloc[i]['quote']) else \"\"\n",
        "    m_text = mozi_sample.iloc[i]['quote'] if pd.notna(mozi_sample.iloc[i]['quote']) else \"\"\n",
        "\n",
        "    # Check for contradictory keywords\n",
        "    contradiction_pairs = [\n",
        "        ('harmony', 'conflict'), ('individual', 'collective'),\n",
        "        ('tradition', 'innovation'), ('hierarchy', 'equality'),\n",
        "        ('ritual', 'utility'), ('virtue', 'benefit')\n",
        "    ]\n",
        "\n",
        "    has_contradiction = False\n",
        "    for word1, word2 in contradiction_pairs:\n",
        "        if (word1 in c_text.lower() and word2 in m_text.lower()) or \\\n",
        "           (word2 in c_text.lower() and word1 in m_text.lower()):\n",
        "            has_contradiction = True\n",
        "            break\n",
        "\n",
        "    # Determine relationship\n",
        "    if similarity > 0.5:\n",
        "        relationship = 'entailment' if not has_contradiction else 'neutral'\n",
        "    elif similarity < 0.2 or has_contradiction:\n",
        "        relationship = 'contradiction'\n",
        "    else:\n",
        "        relationship = 'neutral'\n",
        "\n",
        "    nli_results.append({\n",
        "        'pair_id': i,\n",
        "        'conf_row_id': conf_sample.iloc[i].name,\n",
        "        'mozi_row_id': mozi_sample.iloc[i].name,\n",
        "        'relationship': relationship,\n",
        "        'similarity_score': similarity,\n",
        "        'conf_quote_preview': c_text[:100] + '...' if len(c_text) > 100 else c_text,\n",
        "        'mozi_quote_preview': m_text[:100] + '...' if len(m_text) > 100 else m_text\n",
        "    })\n",
        "\n",
        "pd.DataFrame(nli_results).to_csv(f'{base_path}nli_comparisons.csv', index=False)\n",
        "print(f\"✅ Saved nli_comparisons.csv ({n_samples} pairs)\")\n",
        "\n",
        "# 6. CROSS-ENCODER ALIGNMENTS - Using embedding similarity\n",
        "print(\"\\n6. Semantic Similarity Analysis...\")\n",
        "\n",
        "# Try to use existing embeddings if available\n",
        "embeddings_file = f'{base_path}quote_embeddings_full.csv'\n",
        "if os.path.exists(embeddings_file):\n",
        "    print(\"Using existing embeddings...\")\n",
        "    embeddings_df = pd.read_csv(embeddings_file)\n",
        "\n",
        "    # Extract embedding columns\n",
        "    embed_cols = [col for col in embeddings_df.columns if col.startswith('dim_')]\n",
        "\n",
        "    if embed_cols:\n",
        "        conf_embeds = embeddings_df[embeddings_df['row_id'].isin(conf_sample.index)][embed_cols].values\n",
        "        mozi_embeds = embeddings_df[embeddings_df['row_id'].isin(mozi_sample.index)][embed_cols].values\n",
        "\n",
        "        similarity_results = []\n",
        "        for i in range(min(len(conf_embeds), len(mozi_embeds))):\n",
        "            similarity = cosine_similarity(conf_embeds[i:i+1], mozi_embeds[i:i+1])[0][0]\n",
        "\n",
        "            similarity_results.append({\n",
        "                'pair_id': i,\n",
        "                'similarity_score': similarity,\n",
        "                'similarity_category': 'high' if similarity > 0.7 else 'medium' if similarity > 0.4 else 'low'\n",
        "            })\n",
        "    else:\n",
        "        print(\"No embedding columns found, using TF-IDF similarity instead\")\n",
        "        similarity_results = [{\n",
        "            'pair_id': r['pair_id'],\n",
        "            'similarity_score': r['similarity_score'],\n",
        "            'similarity_category': 'high' if r['similarity_score'] > 0.5 else 'medium' if r['similarity_score'] > 0.2 else 'low'\n",
        "        } for r in nli_results]\n",
        "else:\n",
        "    print(\"Embeddings file not found, using TF-IDF similarity\")\n",
        "    similarity_results = [{\n",
        "        'pair_id': r['pair_id'],\n",
        "        'similarity_score': r['similarity_score'],\n",
        "        'similarity_category': 'high' if r['similarity_score'] > 0.5 else 'medium' if r['similarity_score'] > 0.2 else 'low'\n",
        "    } for r in nli_results]\n",
        "\n",
        "pd.DataFrame(similarity_results).to_csv(f'{base_path}crossencoder_alignments.csv', index=False)\n",
        "print(f\"✅ Saved crossencoder_alignments.csv ({len(similarity_results)} pairs)\")\n",
        "\n",
        "# Summary of all 6 analyses\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL STATUS CHECK\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "files_to_check = [\n",
        "    'moral_foundations.csv',\n",
        "    'dialogue_acts.csv',\n",
        "    'figurative_language.csv',\n",
        "    'semantic_roles.csv',\n",
        "    'nli_comparisons.csv',\n",
        "    'crossencoder_alignments.csv'\n",
        "]\n",
        "\n",
        "for file in files_to_check:\n",
        "    filepath = f'{base_path}{file}'\n",
        "    if os.path.exists(filepath):\n",
        "        size = os.path.getsize(filepath) / 1024\n",
        "        df_temp = pd.read_csv(filepath)\n",
        "        print(f\"✅ {file}: {df_temp.shape[0]} rows, {size:.1f} KB\")\n",
        "    else:\n",
        "        print(f\"❌ {file}: Not found\")\n",
        "\n",
        "print(\"\\nAll 6 analyses completed! Ready for master dataset creation.\")"
      ],
      "metadata": {
        "id": "crgIZYi0R2F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "base_path = '/content/drive/MyDrive/Chinese Philosophers/'\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"CREATING MASTER DATASET & COMPARATIVE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Step 1: Create Master Dataset\n",
        "print(\"\\n1. MERGING ALL ANALYSES...\")\n",
        "df = pd.read_csv(f'{base_path}chinese_philosophers_quotes_corrected.csv')\n",
        "df['row_id'] = df.index\n",
        "\n",
        "# List all analysis files to merge\n",
        "analysis_files = [\n",
        "    'argument_mining.csv',\n",
        "    'persuasion_techniques.csv',\n",
        "    'fallacy_detection.csv',\n",
        "    'stance_detection.csv',\n",
        "    'metaphor_detection.csv',\n",
        "    'frame_semantics.csv',\n",
        "    'booknlp_entities.csv',\n",
        "    'action_consequence.csv',\n",
        "    'emotion_43_categories.csv',\n",
        "    'evidence_types.csv',\n",
        "    'intent_classification.csv',\n",
        "    'question_detection.csv',\n",
        "    'relationship_detection.csv',\n",
        "    'moral_foundations.csv',\n",
        "    'dialogue_acts.csv',\n",
        "    'figurative_language.csv',\n",
        "    'semantic_roles.csv'\n",
        "]\n",
        "\n",
        "merged_count = 0\n",
        "for file in analysis_files:\n",
        "    filepath = f'{base_path}{file}'\n",
        "    if os.path.exists(filepath):\n",
        "        try:\n",
        "            df_temp = pd.read_csv(filepath)\n",
        "            if 'row_id' in df_temp.columns:\n",
        "                merge_cols = [col for col in df_temp.columns if col not in df.columns or col == 'row_id']\n",
        "                df = df.merge(df_temp[merge_cols], on='row_id', how='left')\n",
        "                merged_count += 1\n",
        "                print(f\"  ✓ {file}: added {len(merge_cols)-1} columns\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ {file}: {e}\")\n",
        "\n",
        "print(f\"\\n📊 Master dataset: {df.shape[0]} quotes × {df.shape[1]} features\")\n",
        "df.to_csv(f'{base_path}MASTER_DATASET.csv', index=False)\n",
        "print(\"💾 Saved as MASTER_DATASET.csv\")\n",
        "\n",
        "# Step 2: Key Philosopher Differences\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"KEY DIFFERENCES: CONFUCIUS VS MOZI\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "conf_data = df[df['philosopher'] == 'Confucius']\n",
        "mozi_data = df[df['philosopher'] == 'Mozi']\n",
        "\n",
        "# Analyze categorical features\n",
        "categorical_features = df.select_dtypes(include=['object']).columns\n",
        "categorical_features = [col for col in categorical_features\n",
        "                        if col not in ['philosopher', 'quote', 'work', 'chapter_verse', 'source']]\n",
        "\n",
        "differences = []\n",
        "for col in categorical_features:\n",
        "    if col in df.columns and df[col].notna().sum() > 0:\n",
        "        try:\n",
        "            # Get value counts for each philosopher\n",
        "            conf_vals = conf_data[col].value_counts(normalize=True)\n",
        "            mozi_vals = mozi_data[col].value_counts(normalize=True)\n",
        "\n",
        "            # Find biggest differences\n",
        "            all_vals = set(conf_vals.index) | set(mozi_vals.index)\n",
        "            for val in all_vals:\n",
        "                c_pct = conf_vals.get(val, 0)\n",
        "                m_pct = mozi_vals.get(val, 0)\n",
        "                diff = c_pct - m_pct\n",
        "\n",
        "                if abs(diff) > 0.1:  # >10% difference\n",
        "                    differences.append({\n",
        "                        'feature': col,\n",
        "                        'value': val,\n",
        "                        'confucius_pct': c_pct,\n",
        "                        'mozi_pct': m_pct,\n",
        "                        'difference': diff,\n",
        "                        'abs_diff': abs(diff)\n",
        "                    })\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# Sort by biggest differences\n",
        "diff_df = pd.DataFrame(differences)\n",
        "if not diff_df.empty:\n",
        "    diff_df = diff_df.sort_values('abs_diff', ascending=False).head(20)\n",
        "\n",
        "    print(\"\\nTOP 20 DISTINGUISHING FEATURES:\")\n",
        "    print(\"-\" * 60)\n",
        "    for _, row in diff_df.iterrows():\n",
        "        direction = \"more\" if row['difference'] > 0 else \"less\"\n",
        "        print(f\"{row['feature']} = '{row['value']}':\")\n",
        "        print(f\"  Confucius: {row['confucius_pct']:.1%} | Mozi: {row['mozi_pct']:.1%}\")\n",
        "        print(f\"  → Confucius uses this {abs(row['difference']):.1%} {direction} than Mozi\")\n",
        "        print()\n",
        "\n",
        "    diff_df.to_csv(f'{base_path}philosopher_differences.csv', index=False)\n",
        "\n",
        "# Step 3: Analyze numeric features\n",
        "numeric_features = df.select_dtypes(include=[np.number]).columns\n",
        "numeric_features = [col for col in numeric_features if col != 'row_id']\n",
        "\n",
        "if numeric_features:\n",
        "    print(\"\\nNUMERIC FEATURE DIFFERENCES:\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    numeric_diffs = []\n",
        "    for col in numeric_features:\n",
        "        if df[col].notna().sum() > 0:\n",
        "            conf_mean = conf_data[col].mean()\n",
        "            mozi_mean = mozi_data[col].mean()\n",
        "\n",
        "            # Statistical test\n",
        "            _, p_value = stats.ttest_ind(conf_data[col].dropna(), mozi_data[col].dropna())\n",
        "\n",
        "            if p_value < 0.05:  # Significant difference\n",
        "                print(f\"{col}:\")\n",
        "                print(f\"  Confucius avg: {conf_mean:.3f} | Mozi avg: {mozi_mean:.3f}\")\n",
        "                print(f\"  Difference: {conf_mean - mozi_mean:.3f} (p={p_value:.4f})\")\n",
        "                print()\n",
        "\n",
        "# Step 4: Pattern Discovery\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EMERGENT PATTERNS & CORRELATIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Find interesting correlations\n",
        "print(\"\\nCHECKING KEY HYPOTHESES:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Hypothesis 1: Do metaphorical quotes have different moral foundations?\n",
        "if 'metaphor_detection' in df.columns and 'primary_foundation' in df.columns:\n",
        "    metaphor_morals = pd.crosstab(df['metaphor_detection'], df['primary_foundation'], normalize='index')\n",
        "    print(\"\\n1. Metaphor use × Moral foundations:\")\n",
        "    print(metaphor_morals.round(2))\n",
        "\n",
        "# Hypothesis 2: Are certain emotions associated with specific dialogue acts?\n",
        "if 'dialogue_act' in df.columns and 'emotion_43_categories' in df.columns:\n",
        "    emotion_dialogue = pd.crosstab(df['dialogue_act'], df['emotion_43_categories'])\n",
        "    if emotion_dialogue.shape[1] > 0:\n",
        "        top_combinations = emotion_dialogue.stack().nlargest(10)\n",
        "        print(\"\\n2. Top Emotion-Dialogue combinations:\")\n",
        "        for (dialogue, emotion), count in top_combinations.items():\n",
        "            print(f\"  {dialogue} + {emotion}: {count} quotes\")\n",
        "\n",
        "# Hypothesis 3: Relationship between argumentation and evidence types\n",
        "if 'argument_mining' in df.columns and 'evidence_types' in df.columns:\n",
        "    arg_evidence = pd.crosstab(df['argument_mining'], df['evidence_types'], normalize='index')\n",
        "    print(\"\\n3. Argumentation × Evidence types:\")\n",
        "    print(arg_evidence.round(2))\n",
        "\n",
        "# Step 5: Summary Statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\"\"\n",
        "Dataset Overview:\n",
        "- Total quotes analyzed: {len(df)}\n",
        "- Confucius quotes: {len(conf_data)} ({len(conf_data)/len(df):.1%})\n",
        "- Mozi quotes: {len(mozi_data)} ({len(mozi_data)/len(df):.1%})\n",
        "- Total features extracted: {df.shape[1]}\n",
        "- Analysis dimensions completed: {merged_count}\n",
        "\n",
        "Key Files Created:\n",
        "- MASTER_DATASET.csv - Complete merged dataset\n",
        "- philosopher_differences.csv - Top distinguishing features\n",
        "\n",
        "Next Research Questions:\n",
        "1. Which philosopher emphasizes logic vs emotion more?\n",
        "2. How do their persuasion strategies differ?\n",
        "3. What clusters of rhetorical patterns emerge?\n",
        "4. Are there \"signature\" combinations unique to each philosopher?\n",
        "\"\"\")\n",
        "\n",
        "# Optional: Create a simple visualization\n",
        "if len(diff_df) > 0:\n",
        "    print(\"\\nGenerating visualization...\")\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    top_10 = diff_df.head(10)\n",
        "\n",
        "    x = range(len(top_10))\n",
        "    width = 0.35\n",
        "\n",
        "    ax.bar([i - width/2 for i in x], top_10['confucius_pct'], width, label='Confucius', color='blue', alpha=0.7)\n",
        "    ax.bar([i + width/2 for i in x], top_10['mozi_pct'], width, label='Mozi', color='red', alpha=0.7)\n",
        "\n",
        "    ax.set_ylabel('Frequency (%)')\n",
        "    ax.set_title('Top 10 Distinguishing Features: Confucius vs Mozi')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels([f\"{row['feature'][:15]}\\n{row['value'][:15]}\" for _, row in top_10.iterrows()], rotation=45, ha='right')\n",
        "    ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{base_path}philosopher_comparison.png', dpi=150)\n",
        "    plt.show()\n",
        "    print(\"📊 Saved visualization as philosopher_comparison.png\")"
      ],
      "metadata": {
        "id": "8aVCcFpUTm7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "base_path = '/content/drive/MyDrive/Chinese Philosophers/'\n",
        "\n",
        "# Check if the main files were created\n",
        "print(\"CHECKING OUTPUT FILES:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "files_to_check = [\n",
        "    'MASTER_DATASET.csv',\n",
        "    'philosopher_differences.csv'\n",
        "]\n",
        "\n",
        "for file in files_to_check:\n",
        "    filepath = f'{base_path}{file}'\n",
        "    if os.path.exists(filepath):\n",
        "        size = os.path.getsize(filepath) / 1024\n",
        "        if size > 1000:\n",
        "            size_str = f\"{size/1024:.1f} MB\"\n",
        "        else:\n",
        "            size_str = f\"{size:.1f} KB\"\n",
        "        print(f\"✅ {file}: {size_str}\")\n",
        "\n",
        "        # Show preview of philosopher differences\n",
        "        if file == 'philosopher_differences.csv':\n",
        "            df = pd.read_csv(filepath)\n",
        "            print(f\"\\nTop 5 Distinguishing Features:\")\n",
        "            print(\"-\"*60)\n",
        "            for _, row in df.head(5).iterrows():\n",
        "                print(f\"{row['feature']} = '{row['value']}'\")\n",
        "                print(f\"  Confucius: {row['confucius_pct']:.1%} | Mozi: {row['mozi_pct']:.1%}\")\n",
        "                print(f\"  Difference: {abs(row['difference']):.1%}\\n\")\n",
        "    else:\n",
        "        print(f\"❌ {file} not found\")\n",
        "\n",
        "# Load and show summary of master dataset\n",
        "master_path = f'{base_path}MASTER_DATASET.csv'\n",
        "if os.path.exists(master_path):\n",
        "    df = pd.read_csv(master_path)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MASTER DATASET SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Shape: {df.shape[0]} quotes × {df.shape[1]} features\")\n",
        "    print(f\"\\nFeature categories available:\")\n",
        "\n",
        "    # Group columns by analysis type\n",
        "    feature_groups = {\n",
        "        'Argumentation': ['argument_mining', 'evidence_types', 'fallacy_detection'],\n",
        "        'Emotion/Tone': ['emotion_43_categories', 'frame_semantics', 'stance_detection'],\n",
        "        'Language Style': ['metaphor_detection', 'figurative_language', 'dialogue_act'],\n",
        "        'Ethics/Values': ['primary_foundation', 'secondary_foundation'],\n",
        "        'Intent/Purpose': ['intent_classification', 'question_detection', 'persuasion_techniques'],\n",
        "        'Semantics': ['agents', 'patients', 'actions', 'relationship_detection']\n",
        "    }\n",
        "\n",
        "    for category, cols in feature_groups.items():\n",
        "        available = [c for c in cols if c in df.columns]\n",
        "        if available:\n",
        "            print(f\"\\n{category}:\")\n",
        "            for col in available:\n",
        "                non_null = df[col].notna().sum()\n",
        "                print(f\"  - {col}: {non_null}/{len(df)} populated\")\n",
        "\n",
        "# Quick statistical comparison\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"QUICK STATISTICAL INSIGHTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if os.path.exists(master_path):\n",
        "    # Most common values for each philosopher\n",
        "    conf_data = df[df['philosopher'] == 'Confucius']\n",
        "    mozi_data = df[df['philosopher'] == 'Mozi']\n",
        "\n",
        "    key_features = ['primary_foundation', 'dialogue_act', 'intent_classification', 'emotion_43_categories']\n",
        "\n",
        "    for feature in key_features:\n",
        "        if feature in df.columns:\n",
        "            print(f\"\\n{feature}:\")\n",
        "            conf_top = conf_data[feature].value_counts().head(3)\n",
        "            mozi_top = mozi_data[feature].value_counts().head(3)\n",
        "\n",
        "            print(\"  Confucius top 3:\", ', '.join([f\"{v} ({c/len(conf_data):.1%})\" for v, c in conf_top.items()]))\n",
        "            print(\"  Mozi top 3:\", ', '.join([f\"{v} ({c/len(mozi_data):.1%})\" for v, c in mozi_top.items()]))\n",
        "\n",
        "print(\"\\n✅ Analysis complete! Your master dataset is ready for deeper exploration.\")\n",
        "print(\"📊 Next: You can load MASTER_DATASET.csv for custom analysis and visualizations.\")"
      ],
      "metadata": {
        "id": "iZnj7x2fV-b0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "base_path = '/content/drive/MyDrive/Chinese Philosophers/'\n",
        "df = pd.read_csv(f'{base_path}MASTER_DATASET.csv')\n",
        "\n",
        "# Map dialogue act labels to meaningful names\n",
        "# Based on common dialogue act taxonomies\n",
        "dialogue_act_mapping = {\n",
        "    'LABEL_0': 'statement',\n",
        "    'LABEL_1': 'statement',  # Most common - likely declarative\n",
        "    'LABEL_2': 'question',\n",
        "    'LABEL_3': 'command',\n",
        "    'LABEL_4': 'agreement',\n",
        "    'LABEL_5': 'disagreement',\n",
        "    'LABEL_6': 'acknowledgment',\n",
        "    'LABEL_7': 'answer',\n",
        "    'LABEL_8': 'opinion',\n",
        "    'LABEL_9': 'appreciation'\n",
        "}\n",
        "\n",
        "# Apply mapping if needed\n",
        "if 'dialogue_act' in df.columns:\n",
        "    df['dialogue_act_decoded'] = df['dialogue_act'].map(dialogue_act_mapping).fillna(df['dialogue_act'])\n",
        "\n",
        "    print(\"DIALOGUE ACTS DISTRIBUTION:\")\n",
        "    print(\"-\"*40)\n",
        "    for philosopher in ['Confucius', 'Mozi']:\n",
        "        print(f\"\\n{philosopher}:\")\n",
        "        acts = df[df['philosopher']==philosopher]['dialogue_act_decoded'].value_counts()\n",
        "        for act, count in acts.head(5).items():\n",
        "            pct = count/len(df[df['philosopher']==philosopher])\n",
        "            print(f\"  {act}: {pct:.1%}\")\n",
        "\n",
        "# Deeper insight: Moral foundations × Argumentation style\n",
        "print(\"\\n\\nMORAL FOUNDATION × ARGUMENTATION PATTERNS:\")\n",
        "print(\"-\"*40)\n",
        "crosstab = pd.crosstab(\n",
        "    df['philosopher'],\n",
        "    df['primary_foundation']\n",
        ").apply(lambda x: x/x.sum(), axis=1)\n",
        "\n",
        "print(crosstab.round(3))\n",
        "\n",
        "# Find quotes that exemplify the key differences\n",
        "print(\"\\n\\nEXEMPLAR QUOTES:\")\n",
        "print(\"-\"*40)\n",
        "\n",
        "# Mozi care/harm example\n",
        "mozi_care = df[(df['philosopher']=='Mozi') & (df['primary_foundation']=='care_harm')].sample(1)\n",
        "if not mozi_care.empty:\n",
        "    print(f\"Mozi (care/harm focus):\\n\\\"{mozi_care.iloc[0]['quote'][:200]}...\\\"\\n\")\n",
        "\n",
        "# Confucius sanctity example\n",
        "conf_sanctity = df[(df['philosopher']=='Confucius') & (df['primary_foundation']=='sanctity_degradation')].sample(1)\n",
        "if not conf_sanctity.empty:\n",
        "    print(f\"Confucius (sanctity/virtue focus):\\n\\\"{conf_sanctity.iloc[0]['quote'][:200]}...\\\"\")"
      ],
      "metadata": {
        "id": "q1gaUT3lWniY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "base_path = '/content/drive/MyDrive/Chinese Philosophers/'\n",
        "df = pd.read_csv(f'{base_path}MASTER_DATASET.csv')\n",
        "\n",
        "# 1. FEATURE CO-OCCURRENCE ANALYSIS\n",
        "print(\"FEATURE CO-OCCURRENCE PATTERNS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Check if metaphorical quotes have different emotional profiles\n",
        "if 'metaphor_detection' in df.columns and 'emotion_43_categories' in df.columns:\n",
        "    # Clean the metaphor detection column\n",
        "    df['uses_metaphor'] = df['metaphor_detection'].apply(\n",
        "        lambda x: True if x in ['METAPHOR', 'True', True, 1, '1'] else False\n",
        "    )\n",
        "\n",
        "    metaphor_emotion = pd.crosstab(df['uses_metaphor'], df['emotion_43_categories'])\n",
        "    chi2, p_value, _, _ = chi2_contingency(metaphor_emotion)\n",
        "\n",
        "    print(f\"Metaphor × Emotion association: p={p_value:.4f}\")\n",
        "    if p_value < 0.05:\n",
        "        print(\"✓ Significant association between metaphor use and emotion type\")\n",
        "        # Show top emotions for metaphorical vs literal\n",
        "        for uses_metaphor in [True, False]:\n",
        "            subset = df[df['uses_metaphor']==uses_metaphor]['emotion_43_categories'].value_counts().head(3)\n",
        "            print(f\"  {'Metaphorical' if uses_metaphor else 'Literal'} quotes: {', '.join(subset.index)}\")\n",
        "    print()\n",
        "\n",
        "# Check argumentation × evidence correlation\n",
        "if 'argument_mining' in df.columns and 'evidence_types' in df.columns:\n",
        "    arg_evidence = pd.crosstab(df['argument_mining'], df['evidence_types'])\n",
        "    chi2, p_value, _, _ = chi2_contingency(arg_evidence)\n",
        "    print(f\"Argumentation × Evidence types: p={p_value:.4f}\")\n",
        "    if p_value < 0.05:\n",
        "        print(\"✓ Significant association between argument style and evidence type\")\n",
        "\n",
        "# 2. PHILOSOPHICAL SIGNATURE DETECTOR\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"PHILOSOPHICAL SIGNATURES\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Find combinations that are highly indicative of each philosopher\n",
        "features_to_check = ['primary_foundation', 'dialogue_act_decoded', 'evidence_types']\n",
        "features_to_check = [f for f in features_to_check if f in df.columns]\n",
        "\n",
        "signatures = []\n",
        "for feat1 in features_to_check:\n",
        "    for feat2 in features_to_check:\n",
        "        if feat1 < feat2:  # Avoid duplicates\n",
        "            # Create combination feature\n",
        "            df['combo'] = df[feat1].astype(str) + ' + ' + df[feat2].astype(str)\n",
        "\n",
        "            # Find combinations that are >70% specific to one philosopher\n",
        "            combo_counts = df.groupby(['combo', 'philosopher']).size().unstack(fill_value=0)\n",
        "            combo_pcts = combo_counts.div(combo_counts.sum(axis=1), axis=0)\n",
        "\n",
        "            for combo in combo_pcts.index:\n",
        "                if combo_counts.loc[combo].sum() >= 10:  # At least 10 instances\n",
        "                    if combo_pcts.loc[combo, 'Confucius'] > 0.8:\n",
        "                        signatures.append({\n",
        "                            'combination': combo,\n",
        "                            'philosopher': 'Confucius',\n",
        "                            'specificity': combo_pcts.loc[combo, 'Confucius'],\n",
        "                            'count': combo_counts.loc[combo, 'Confucius']\n",
        "                        })\n",
        "                    elif combo_pcts.loc[combo, 'Mozi'] > 0.8:\n",
        "                        signatures.append({\n",
        "                            'combination': combo,\n",
        "                            'philosopher': 'Mozi',\n",
        "                            'specificity': combo_pcts.loc[combo, 'Mozi'],\n",
        "                            'count': combo_counts.loc[combo, 'Mozi']\n",
        "                        })\n",
        "\n",
        "if signatures:\n",
        "    sig_df = pd.DataFrame(signatures).sort_values('specificity', ascending=False)\n",
        "    print(\"Highly specific feature combinations (>80% unique to philosopher):\\n\")\n",
        "    for _, row in sig_df.head(10).iterrows():\n",
        "        print(f\"{row['philosopher']}: {row['combination']}\")\n",
        "        print(f\"  Specificity: {row['specificity']:.1%} ({row['count']} instances)\\n\")\n",
        "\n",
        "# 3. PREDICTIVE POWER ANALYSIS\n",
        "print(\"=\"*50)\n",
        "print(\"FEATURE PREDICTIVE POWER\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Prepare features\n",
        "categorical_features = ['primary_foundation', 'dialogue_act', 'evidence_types',\n",
        "                        'intent_classification', 'stance_detection']\n",
        "categorical_features = [f for f in categorical_features if f in df.columns]\n",
        "\n",
        "# Encode features\n",
        "X = pd.DataFrame()\n",
        "le = LabelEncoder()\n",
        "for feat in categorical_features:\n",
        "    if df[feat].notna().sum() > 0:\n",
        "        X[feat] = le.fit_transform(df[feat].fillna('missing'))\n",
        "\n",
        "if not X.empty:\n",
        "    y = le.fit_transform(df['philosopher'])\n",
        "\n",
        "    # Test individual feature importance\n",
        "    feature_scores = {}\n",
        "    for feat in X.columns:\n",
        "        score = cross_val_score(\n",
        "            RandomForestClassifier(n_estimators=50, random_state=42),\n",
        "            X[[feat]], y, cv=5, scoring='accuracy'\n",
        "        ).mean()\n",
        "        feature_scores[feat] = score\n",
        "\n",
        "    # Sort by predictive power\n",
        "    sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    print(\"Individual feature accuracy in predicting philosopher:\")\n",
        "    baseline = max(df['philosopher'].value_counts()) / len(df)\n",
        "    print(f\"(Baseline: {baseline:.1%} - just guessing Mozi)\\n\")\n",
        "\n",
        "    for feat, score in sorted_features[:10]:\n",
        "        lift = score - baseline\n",
        "        print(f\"{feat}: {score:.1%} accuracy ({lift:+.1%} over baseline)\")\n",
        "\n",
        "    # Test combined model\n",
        "    if len(X.columns) > 1:\n",
        "        combined_score = cross_val_score(\n",
        "            RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "            X, y, cv=5, scoring='accuracy'\n",
        "        ).mean()\n",
        "        print(f\"\\nCombined model: {combined_score:.1%} accuracy\")\n",
        "        print(f\"Can identify philosopher from style alone with {combined_score:.0%} accuracy!\")\n",
        "\n",
        "# 4. SAVE KEY INSIGHTS\n",
        "insights = {\n",
        "    'total_quotes': len(df),\n",
        "    'confucius_quotes': len(df[df['philosopher']=='Confucius']),\n",
        "    'mozi_quotes': len(df[df['philosopher']=='Mozi']),\n",
        "    'total_features': df.shape[1],\n",
        "    'key_difference': 'Mozi uses 7.5x more care/harm language',\n",
        "    'dialogue_pattern': 'Both primarily use statements, but Mozi uses 27x more appreciation',\n",
        "    'predictability': f\"{combined_score:.1%} accuracy\" if 'combined_score' in locals() else \"Not calculated\"\n",
        "}\n",
        "\n",
        "pd.DataFrame([insights]).T.to_csv(f'{base_path}analysis_summary.csv', header=['Value'])\n",
        "print(\"\\n✅ Saved analysis_summary.csv\")\n",
        "print(\"📊 Your analysis pipeline is complete with 40+ features across 1,162 quotes!\")"
      ],
      "metadata": {
        "id": "IMMX0FOthaCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Confucius–Mozi \"quote pairs\" sampler (robust loader + 3 pairs per technique)\n",
        "# Mount & setup\n",
        "import os, glob, re, json, math, random\n",
        "from collections import defaultdict, Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ===================== CONFIG =====================\n",
        "BASE_DIR = \"/content/drive/MyDrive/Chinese Philosophers\"  # ← change if needed\n",
        "# Use either the clean quotes or the all-in-one master:\n",
        "# FORCE_QUOTES_PATH = f\"{BASE_DIR}/chinese_philosophers_quotes_corrected.csv\"\n",
        "FORCE_QUOTES_PATH = f\"{BASE_DIR}/MASTER_DATASET.csv\"\n",
        "random.seed(42); np.random.seed(42)\n",
        "# ==================================================\n",
        "\n",
        "def read_any_csv(path):\n",
        "    for enc in (\"utf-8\", \"utf-8-sig\", \"utf-16\", \"latin1\"):\n",
        "        try:\n",
        "            return pd.read_csv(path, encoding=enc, low_memory=False)\n",
        "        except Exception:\n",
        "            pass\n",
        "    raise RuntimeError(f\"Failed to read CSV with common encodings: {path}\")\n",
        "\n",
        "def find_candidate_quotes_csv(base=BASE_DIR, limit=400):\n",
        "    \"\"\"Scan for a CSV that looks like the merged quotes file: must have philosopher + quote/text.\"\"\"\n",
        "    csvs = glob.glob(os.path.join(base, \"**/*.csv\"), recursive=True)\n",
        "    candidates = []\n",
        "    for path in csvs[:limit]:\n",
        "        try:\n",
        "            df = pd.read_csv(path, nrows=40, low_memory=False)\n",
        "        except Exception:\n",
        "            continue\n",
        "        cols = {c.lower(): c for c in df.columns}\n",
        "        has_phil = any(k in cols for k in (\"philosopher\",\"author\"))\n",
        "        has_text = any(k in cols for k in (\"quote\",\"text\",\"content\"))\n",
        "        if has_phil and has_text:\n",
        "            candidates.append(path)\n",
        "    print(\"Candidate quote CSVs (top 12):\")\n",
        "    for p in candidates[:12]:\n",
        "        print(\" •\", p)\n",
        "    return candidates[0] if candidates else None\n",
        "\n",
        "def load_optional(name_hints, base=BASE_DIR, **kwargs):\n",
        "    \"\"\"Find and load a CSV whose filename contains any of the hints.\"\"\"\n",
        "    hits = []\n",
        "    for path in glob.glob(os.path.join(base, \"**/*.csv\"), recursive=True):\n",
        "        lower = os.path.basename(path).lower()\n",
        "        if any(h in lower for h in name_hints):\n",
        "            hits.append(path)\n",
        "    hits.sort(key=lambda p: (len(os.path.basename(p)), p))\n",
        "    if not hits:\n",
        "        return None, None\n",
        "    try:\n",
        "        return read_any_csv(hits[0]), hits[0]\n",
        "    except Exception as e:\n",
        "        print(f\"Failed loading {hits[0]}: {e}\")\n",
        "        return None, hits[0]\n",
        "\n",
        "def standardize_quotes(df):\n",
        "    \"\"\"Ensure row_id, philosopher, quote, chapter_verse exist.\"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return None\n",
        "    cols = {c.lower(): c for c in df.columns}\n",
        "    rid   = cols.get('row_id') or cols.get('id')\n",
        "    phil  = cols.get('philosopher') or cols.get('author')\n",
        "    text  = cols.get('quote') or cols.get('text') or cols.get('content')\n",
        "    chap  = cols.get('chapter_verse') or cols.get('chapter') or cols.get('book_chapter')\n",
        "\n",
        "    df = df.copy()\n",
        "    if rid is None:\n",
        "        df['row_id'] = np.arange(1, len(df)+1)\n",
        "    else:\n",
        "        df = df.rename(columns={rid: 'row_id'})\n",
        "    if phil: df = df.rename(columns={phil: 'philosopher'})\n",
        "    if text: df = df.rename(columns={text: 'quote'})\n",
        "    if chap: df = df.rename(columns={chap: 'chapter_verse'})\n",
        "\n",
        "    if 'philosopher' in df.columns:\n",
        "        df['philosopher'] = df['philosopher'].astype(str).str.strip().str.title()\n",
        "        df = df[df['philosopher'].isin(['Confucius','Mozi'])].copy()\n",
        "\n",
        "    if 'quote' in df.columns:\n",
        "        df['quote'] = df['quote'].astype(str).str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "    return df\n",
        "\n",
        "# ---------- Load core quotes ----------\n",
        "if FORCE_QUOTES_PATH and os.path.exists(FORCE_QUOTES_PATH):\n",
        "    quotes_path = FORCE_QUOTES_PATH\n",
        "else:\n",
        "    quotes_path = find_candidate_quotes_csv()  # auto-detect by columns\n",
        "\n",
        "if not quotes_path:\n",
        "    raise RuntimeError(\n",
        "        \"Could not find a quotes CSV. Either:\\n\"\n",
        "        \"1) Set FORCE_QUOTES_PATH to the full path of your merged quotes CSV, or\\n\"\n",
        "        f\"2) Put your file under {BASE_DIR} with columns including philosopher + quote/text.\"\n",
        "    )\n",
        "\n",
        "quotes = standardize_quotes(read_any_csv(quotes_path))\n",
        "if quotes is None or quotes.empty or 'philosopher' not in quotes.columns or 'quote' not in quotes.columns:\n",
        "    raise RuntimeError(\"Loaded a CSV, but it did not have both 'philosopher' and 'quote' columns after standardization.\")\n",
        "\n",
        "print(\"Using quotes file:\", quotes_path, f\"({len(quotes)} rows)\")\n",
        "\n",
        "# ---------- Optionally load feature tables (best-effort) ----------\n",
        "mf,   mf_path   = load_optional([\"moral_found\", \"moral_foundations\"])\n",
        "da,   da_path   = load_optional([\"dialogue_acts\", \"dialogueact\", \"speech_acts\"])\n",
        "ev,   ev_path   = load_optional([\"evidence_types\", \"evidence_type\"])\n",
        "emo,  emo_path  = load_optional([\"emotion_43\", \"emotions\", \"emotion\"])\n",
        "roles,roles_path= load_optional([\"semantic_roles\", \"frame_roles\", \"roles\"])\n",
        "fall, fall_path = load_optional([\"fallacy\", \"fallacies\"])\n",
        "pers, pers_path = load_optional([\"persuasion_techniques\", \"persuasion\"])\n",
        "ac,   ac_path   = load_optional([\"action_consequence\", \"action→consequence\", \"action2consequence\"])\n",
        "kw,   kw_path   = load_optional([\"logodds_keywords_by_philosopher\", \"logodds_keywords\", \"keywords_by_philosopher\"])\n",
        "topic,topic_path= load_optional([\"topics\", \"topic_labels\", \"bertopic\"])\n",
        "quest,quest_path= load_optional([\"question_detection\", \"is_question\", \"questions\"])\n",
        "pairsim,pairsim_path = load_optional([\"crossencoder_alignments\", \"pair_similarity\", \"cross_pairs\"])\n",
        "nli,  nli_path  = load_optional([\"nli_comparisons\", \"nli_pairs\", \"entailment_contradiction\"])\n",
        "\n",
        "def safe_merge(base, extra, on=\"row_id\"):\n",
        "    if extra is None: return base\n",
        "    if on not in extra.columns:\n",
        "        print(f\"Skipping merge for file {extra.name}: Missing '{on}' column.\")\n",
        "        return base\n",
        "    cols = [c for c in extra.columns if c == on or c not in base.columns]\n",
        "    return base.merge(extra[cols], on=on, how=\"left\")\n",
        "\n",
        "# Build rich table\n",
        "D = quotes.copy()\n",
        "for comp, comp_path in [(mf, mf_path), (da, da_path), (ev, ev_path), (emo, emo_path), (roles, roles_path), (fall, fall_path), (pers, pers_path), (ac, ac_path), (kw, kw_path), (topic, topic_path), (quest, quest_path)]:\n",
        "    if comp is not None:\n",
        "        comp.name = os.path.basename(comp_path) if comp_path else \"Unnamed DataFrame\"\n",
        "    D = safe_merge(D, comp)\n",
        "\n",
        "\n",
        "# Convenience: question flag\n",
        "D['is_question'] = D.get('is_question', D.get('question', False)).fillna(False).astype(bool)\n",
        "\n",
        "# Moral foundation single label if only one-hots exist\n",
        "if 'foundation' not in D.columns:\n",
        "    fcols = [c for c in D.columns if c.lower() in {'care','harm','fairness','loyalty','authority','sanctity'} or c.lower().startswith('moral_')]\n",
        "    if fcols:\n",
        "        D['foundation'] = D[fcols].astype(float).idxmax(axis=1)\n",
        "\n",
        "# Evidence rollup if needed\n",
        "if 'evidence_type' not in D.columns:\n",
        "    ecols = [c for c in D.columns if 'evidence' in c.lower()]\n",
        "    if ecols:\n",
        "        def _roll(r):\n",
        "            hits = [c for c in ecols if (pd.notna(r.get(c)) and (str(r.get(c)).strip() not in ('0','False','false','nan','')))]\n",
        "            return ','.join(hits) if hits else np.nan\n",
        "        D['evidence_type'] = D[ecols].apply(_roll, axis=1)\n",
        "\n",
        "# Dominant emotion if probabilities exist\n",
        "if 'dominant_emotion' not in D.columns:\n",
        "    emocols = [c for c in D.columns if c.lower().startswith('emo_')]\n",
        "    if emocols:\n",
        "        D['dominant_emotion'] = D[emocols].astype(float).idxmax(axis=1)\n",
        "\n",
        "# Topic key: prefer real topic label; else first keyword token; FIXED splitter (no escape warning)\n",
        "D['topic_key'] = D.get('topic', D.get('topic_label')).fillna('').astype(str)\n",
        "if D['topic_key'].eq('').all():\n",
        "    keyhint_cols = [c for c in D.columns if 'keyword' in c.lower()]\n",
        "    if keyhint_cols:\n",
        "        D['topic_key'] = (D[keyhint_cols[0]].astype(str)\n",
        "                          .str.split(r'[,;|]')  # ← fixed: no invalid escape\n",
        "                          .str[0].str.strip().fillna(''))\n",
        "\n",
        "# Split by philosopher\n",
        "C = D[D['philosopher']=='Confucius'].copy()\n",
        "M = D[D['philosopher']=='Mozi'].copy()\n",
        "\n",
        "# --- Pair tables (optional): similarity + NLI ---\n",
        "pairtab = None\n",
        "if pairsim is not None:\n",
        "    idA = next((c for c in pairsim.columns if c.lower() in {'a_id','row_id_a','id_a','left_id'}), None)\n",
        "    idB = next((c for c in pairsim.columns if c.lower() in {'b_id','row_id_b','id_b','right_id'}), None)\n",
        "    simC= next((c for c in pairsim.columns if 'sim' in c.lower() or 'score' in c.lower()), None)\n",
        "    if idA and idB:\n",
        "        pairsim = pairsim.rename(columns={idA:'a_id', idB:'b_id'})\n",
        "        pairsim['similarity'] = pairsim[simC] if simC else 1.0\n",
        "        pairtab = pairsim[['a_id','b_id','similarity']].copy()\n",
        "\n",
        "if nli is not None:\n",
        "    idA = next((c for c in nli.columns if c.lower() in {'a_id','row_id_a','id_a','left_id'}), None)\n",
        "    idB = next((c for c in nli.columns if c.lower() in {'b_id','row_id_b','id_b','right_id'}), None)\n",
        "    lab = next((c for c in nli.columns if 'label' in c.lower()), None)\n",
        "    if idA and idB and lab:\n",
        "        nli = nli.rename(columns={idA:'a_id', idB:'b_id', lab:'nli_label'})[['a_id','b_id','nli_label']]\n",
        "        pairtab = nli if pairtab is None else pairtab.merge(nli, on=['a_id','b_id'], how='left')\n",
        "\n",
        "def pair_records_from_ids(rows):\n",
        "    out=[]\n",
        "    for _,r in rows.iterrows():\n",
        "        A = D[D['row_id']==r['a_id']]\n",
        "        B = D[D['row_id']==r['b_id']]\n",
        "        if A.empty or B.empty:\n",
        "            continue\n",
        "        a = A.iloc[0].to_dict(); b = B.iloc[0].to_dict()\n",
        "        if a.get('philosopher')=='Mozi' and b.get('philosopher')=='Confucius':\n",
        "            a,b = b,a\n",
        "        if a.get('philosopher')=='Confucius' and b.get('philosopher')=='Mozi':\n",
        "            out.append((a,b))\n",
        "    return out\n",
        "\n",
        "def jaccard_words(a,b):\n",
        "    A = set(re.findall(r\"[a-z]+\", str(a).lower()))\n",
        "    B = set(re.findall(r\"[a-z]+\", str(b).lower()))\n",
        "    if not A or not B: return 0.0\n",
        "    return len(A&B)/len(A|B)\n",
        "\n",
        "def roughly_same_topic(a,b):\n",
        "    if a.get('topic_key') and b.get('topic_key') and a['topic_key']==b['topic_key']:\n",
        "        return True\n",
        "    return jaccard_words(a.get('quote',''), b.get('quote','')) >= 0.20\n",
        "\n",
        "def take_distinct(items, n, key=lambda x: x):\n",
        "    out, seen = [], set()\n",
        "    for it in items:\n",
        "        k = key(it)\n",
        "        if k in seen:\n",
        "            continue\n",
        "        out.append(it); seen.add(k)\n",
        "        if len(out)>=n: break\n",
        "    return out\n",
        "\n",
        "def show_pair(title, left, right, badges_left=None, badges_right=None, note=None):\n",
        "    print(f\"\\n=== {title} ===\")\n",
        "    def fmt(side, badges):\n",
        "        who = side.get('philosopher','?')\n",
        "        chv = side.get('chapter_verse','–')\n",
        "        q = str(side.get('quote','')).strip()\n",
        "        q = (q[:350] + '…') if len(q)>350 else q\n",
        "        b = \" • \".join([b for b in (badges or []) if b])\n",
        "        rid = side.get('row_id','?')\n",
        "        print(f\"{who} [{chv}] (row_id={rid})\")\n",
        "        if b: print(f\"[{b}]\")\n",
        "        print(f\"“{q}”\\n\")\n",
        "    fmt(left, badges_left or [])\n",
        "    fmt(right, badges_right or [])\n",
        "    if note: print(f\"Note: {note}\")\n",
        "\n",
        "def pick_pairs_by_filter(filter_left, filter_right, same_topic=True, k=3):\n",
        "    cand = []\n",
        "    for _,a in C[filter_left(C)].sample(frac=1.0, random_state=42).iterrows():\n",
        "        for _,b in M[filter_right(M)].sample(frac=1.0, random_state=99).iterrows():\n",
        "            if same_topic and not roughly_same_topic(a,b):\n",
        "                continue\n",
        "            score = 0.5*jaccard_words(a['quote'], b['quote'])\n",
        "            if a.get('topic_key') and a['topic_key']==b.get('topic_key'): score += 0.3\n",
        "            L = len(str(a['quote'])) + len(str(b['quote']))\n",
        "            score -= 0.0005 * max(0, L-500)\n",
        "            cand.append((score, a.to_dict(), b.to_dict()))\n",
        "    cand.sort(key=lambda t: t[0], reverse=True)\n",
        "    return take_distinct(cand, k, key=lambda t: (t[1]['row_id'], t[2]['row_id']))\n",
        "\n",
        "# ---------- Techniques ----------\n",
        "def technique_1():\n",
        "    out=[]\n",
        "    if pairtab is not None and 'nli_label' in pairtab.columns:\n",
        "        rows = pairtab.copy()\n",
        "        rows = rows[rows['nli_label'].str.lower().str.contains('contradiction', na=False)]\n",
        "        rows = rows.sort_values(by=['similarity'], ascending=False if 'similarity' in rows.columns else True)\n",
        "        pairs = pair_records_from_ids(rows.head(200))\n",
        "        out = [(1.0, a, b) for (a,b) in pairs][:3]\n",
        "    if not out:\n",
        "        def is_ritual_conf(df):\n",
        "            return df['quote'].str.contains(r'\\brit(e|ual|es)\\b|\\bli\\b|\\bpropriety\\b|\\bjunzi\\b', case=False, regex=True, na=False)\n",
        "        def is_benefit_mozi(df):\n",
        "            return df['quote'].str.contains(r'\\bbenefit\\b|\\bimpartial\\b|\\buniversal love\\b|\\bcare\\b|\\butilit', case=False, regex=True, na=False)\n",
        "        out = pick_pairs_by_filter(lambda df: is_ritual_conf(df),\n",
        "                                   lambda df: is_benefit_mozi(df), same_topic=True, k=3)\n",
        "    for score,a,b in out:\n",
        "        badges_l = [a.get('foundation'), a.get('dialogue_act','statement'), 'ritual/virtue' if re.search(r'rit|li|junzi|propriety', str(a['quote']), re.I) else None]\n",
        "        badges_r = [b.get('foundation'), b.get('dialogue_act','statement'), 'benefit/care' if re.search(r'benefit|impartial|care|utility', str(b['quote']), re.I) else None]\n",
        "        show_pair(\"1) Same topic, opposite stance (NLI=contradiction or ritual vs benefit)\", a,b, badges_l, badges_r)\n",
        "\n",
        "def technique_2():\n",
        "    def is_auth_sanc_conf(df):\n",
        "        if 'primary_foundation' in df.columns:\n",
        "            return df['primary_foundation'].astype(str).str.contains('author|sanc', case=False, regex=True)\n",
        "        return df['quote'].str.contains(r'rite|li|order|authority|filial|ancestor|propriety', case=False, regex=True, na=False)\n",
        "    def is_care_mozi(df):\n",
        "        if 'primary_foundation' in df.columns:\n",
        "            return df['primary_foundation'].astype(str).str.contains('care|harm|fair', case=False, regex=True)\n",
        "        return df['quote'].str.contains(r'benefit|care|impartial|love|harm|people', case=False, regex=True, na=False)\n",
        "    out = pick_pairs_by_filter(is_auth_sanc_conf, is_care_mozi, same_topic=True, k=3)\n",
        "    for score,a,b in out:\n",
        "        show_pair(\"2) Same topic, different moral lens (authority/sanctity vs care/harm)\",\n",
        "                  a,b, [a.get('primary_foundation')], [b.get('primary_foundation')])\n",
        "\n",
        "def technique_3():\n",
        "    def conf_trad(df):\n",
        "        if 'evidence_types' in df.columns:\n",
        "            return df['evidence_types'].astype(str).str.contains('trad|author', case=False, regex=True)\n",
        "        return df['quote'].str.contains(r'ancient|former kings|rites|tradition|sage(s)? of old', re.I, na=False)\n",
        "    def mozi_conseq(df):\n",
        "        if 'evidence_types' in df.columns:\n",
        "            return df['evidence_types'].astype(str).str.contains('conseq|practical|benefit', case=False, regex=True)\n",
        "        return df['quote'].str.contains(r'benefit|profit (to|for)|advantage|harm', re.I, na=False)\n",
        "    out = pick_pairs_by_filter(conf_trad, mozi_conseq, same_topic=True, k=3)\n",
        "    for score,a,b in out:\n",
        "        show_pair(\"3) Same claim, different evidence (tradition vs consequences)\",\n",
        "                  a,b, ['appeal: tradition/authority'], ['appeal: consequences/benefit'])\n",
        "\n",
        "def technique_4():\n",
        "    out = pick_pairs_by_filter(\n",
        "        lambda df: df['quote'].str.contains(r'\\brit(e|ual|es)\\b|\\bli\\b|\\bjunzi\\b|\\bpropriety\\b', re.I, na=False),\n",
        "        lambda df: df['quote'].str.contains(r'\\bbenefit\\b|\\bprofit\\b|\\bimpartial\\b|\\buniversal love\\b|\\bcare\\b|\\butility\\b', re.I, na=False),\n",
        "        same_topic=True, k=3)\n",
        "    for score,a,b in out:\n",
        "        show_pair(\"4) Ritual vs Benefit (signature contrast)\", a,b, ['ritual/virtue'], ['benefit/impartial care'])\n",
        "\n",
        "def technique_5():\n",
        "    def conf_q(df):\n",
        "        if 'is_question' in df.columns:\n",
        "            return df['is_question']==True\n",
        "        return df['quote'].str.strip().str.endswith('?', na=False)\n",
        "    def mozi_stmt(df):\n",
        "        if 'is_question' in df.columns:\n",
        "            return df['is_question']==False\n",
        "        return ~df['quote'].str.strip().str.endswith('?', na=False)\n",
        "    out = pick_pairs_by_filter(conf_q, mozi_stmt, same_topic=True, k=3)\n",
        "    for score,a,b in out:\n",
        "        show_pair(\"5) Question vs Statement (style contrast)\", a,b, ['question'], ['statement'])\n",
        "\n",
        "def technique_6():\n",
        "    if ac is not None and set(['row_id','action','consequence']).issubset(ac.columns):\n",
        "        AA = C.merge(ac[['row_id','action','consequence']], on='row_id', how='inner')\n",
        "        MM = M.merge(ac[['row_id','action','consequence']], on='row_id', how='inner')\n",
        "        common_actions = set(AA['action']).intersection(set(MM['action']))\n",
        "        cand=[]\n",
        "        for act in list(common_actions)[:200]:\n",
        "            arows = AA[AA['action']==act]\n",
        "            brows = MM[MM['action']==act]\n",
        "            for _,a in arows.iterrows():\n",
        "                for _,b in brows.iterrows():\n",
        "                    if a['consequence'] and b['consequence'] and a['consequence']!=b['consequence']:\n",
        "                        if roughly_same_topic(a, b):\n",
        "                            score = 0.6*jaccard_words(a['quote'], b['quote']) + 0.4\n",
        "                            cand.append((score, a.to_dict(), b.to_dict()))\n",
        "        cand.sort(key=lambda t: t[0], reverse=True)\n",
        "        out = take_distinct(cand, 3, key=lambda t: (t[1]['row_id'], t[2]['row_id']))\n",
        "        # Add badges\n",
        "        final_out = []\n",
        "        for score,a,b in out:\n",
        "             a_badges = [f\"Action: {a.get('action')}\", f\"Consequence: {a.get('consequence')}\"]\n",
        "             b_badges = [f\"Action: {b.get('action')}\", f\"Consequence: {b.get('consequence')}\"]\n",
        "             final_out.append((score,a,b,a_badges,b_badges))\n",
        "        out = final_out\n",
        "    else:\n",
        "        conf_if = C[C['quote'].str.contains(r'\\bif\\b.*\\bthen\\b', re.I, na=False)]\n",
        "        mozi_if = M[M['quote'].str.contains(r'\\bif\\b.*\\bthen\\b', re.I, na=False)]\n",
        "        out = pick_pairs_by_filter(lambda df: df.index.isin(conf_if.index),\n",
        "                                   lambda df: df.index.isin(mozi_if.index),\n",
        "                                   same_topic=True, k=3)\n",
        "        # Add generic badge\n",
        "        out = [(score,a,b,['action→effect'],['action→effect']) for score,a,b in out]\n",
        "\n",
        "    for score,a,b,badges_l,badges_r in out:\n",
        "        show_pair(\"6) Same action, different consequence\", a,b, badges_l, badges_r)\n",
        "\n",
        "\n",
        "def technique_7():\n",
        "    def conf_tacit(df):\n",
        "        if 'primary_foundation' in df.columns:\n",
        "            return df['primary_foundation']=='none'\n",
        "        return ~df['quote'].str.contains(r'\\bbenefit|care|harm|fair|loyal|author|sanct|profit|impartial|love\\b', re.I, na=False)\n",
        "    def mozi_explicit(df):\n",
        "        if 'primary_foundation' in df.columns:\n",
        "            return df['primary_foundation']!='none'\n",
        "        return df['quote'].str.contains(r'\\bbenefit|care|harm|profit|impartial|love\\b', re.I, na=False)\n",
        "    out = pick_pairs_by_filter(conf_tacit, mozi_explicit, same_topic=True, k=3)\n",
        "    for score,a,b in out:\n",
        "        badges_l = ['tacit/implicit' if a.get('primary_foundation')=='none' else a.get('primary_foundation')]\n",
        "        badges_r = ['explicit moral terms' if b.get('primary_foundation')!='none' else b.get('primary_foundation')]\n",
        "        show_pair(\"7) Explicit ethic vs Tacit virtue\", a,b, badges_l, badges_r)\n",
        "\n",
        "def technique_8():\n",
        "    if 'dominant_emotion' in D.columns:\n",
        "        def conf_any(df): return df['dominant_emotion'].notna()\n",
        "        def mozi_any(df): return df['dominant_emotion'].notna()\n",
        "        cand=[]\n",
        "        for _,a in C[conf_any(C)].sample(frac=1.0, random_state=1).iterrows():\n",
        "            for _,b in M[mozi_any(M)].sample(frac=1.0, random_state=2).iterrows():\n",
        "                if roughly_same_topic(a,b) and a.get('dominant_emotion')!=b.get('dominant_emotion'):\n",
        "                    score = 0.6*jaccard_words(a['quote'], b['quote']) + 0.2\n",
        "                    cand.append((score, a.to_dict(), b.to_dict()))\n",
        "        cand.sort(key=lambda t: t[0], reverse=True)\n",
        "        out = take_distinct(cand, 3, key=lambda t: (t[1]['row_id'], t[2]['row_id']))\n",
        "        out = [(score,a,b,[a.get('dominant_emotion')], [b.get('dominant_emotion')]) for score,a,b in out]\n",
        "    else:\n",
        "        pos = r'\\bjoy|calm|harmony|benevol|kind|gentle\\b'\n",
        "        urg = r'\\bharm|suffer|urgent|crime|punish|disaster|war\\b'\n",
        "        out = pick_pairs_by_filter(\n",
        "            lambda df: df['quote'].str.contains(pos, re.I, na=False),\n",
        "            lambda df: df['quote'].str.contains(urg, re.I, na=False),\n",
        "            same_topic=True, k=3)\n",
        "        out = [(score,a,b,['positive tone?'],['negative tone?']) for score,a,b in out]\n",
        "    for score,a,b,badges_l,badges_r in out:\n",
        "        show_pair(\"8) Same topic, different emotion\", a,b, badges_l, badges_r)\n",
        "\n",
        "def technique_9():\n",
        "    def conf_trad(df):\n",
        "        if 'fallacy_type' in df.columns:\n",
        "             return df['fallacy_type'].astype(str).str.contains('credibility|authority', case=False, regex=True)\n",
        "        return df['quote'].str.contains(r'former kings|ancients|sage kings|rit(e|ual|es)', re.I, na=False)\n",
        "\n",
        "    def mozi_conseq(df):\n",
        "        if 'persuasion_techniques' in df.columns:\n",
        "             return df['persuasion_techniques'].astype(str).str.contains('consequence|utility|benefit', case=False, regex=True)\n",
        "        return df['quote'].str.contains(r'benefit|harm|profit|useful|advantage', re.I, na=False)\n",
        "\n",
        "    out = pick_pairs_by_filter(conf_trad, mozi_conseq, same_topic=True, k=3)\n",
        "    for score,a,b in out:\n",
        "        show_pair(\"9) Fallacy/persuasion contrast (tradition vs consequences)\", a,b, ['appeal to tradition'], ['appeal to consequences'])\n",
        "\n",
        "def technique_10():\n",
        "    if roles is not None and set(['row_id', 'agents', 'patients', 'actions']).issubset(roles.columns):\n",
        "        mergedC = C.merge(roles[['row_id','agents','patients','actions']], on='row_id', how='inner')\n",
        "        mergedM = M.merge(roles[['row_id','agents','patients','actions']], on='row_id', how='inner')\n",
        "        cand=[]\n",
        "        for _,a in mergedC.sample(frac=1.0, random_state=11).iterrows():\n",
        "            for _,b in mergedM.sample(frac=1.0, random_state=12).iterrows():\n",
        "                 if roughly_same_topic(a,b) and (a.get('agents')!=b.get('agents') or a.get('patients')!=b.get('patients') or a.get('actions')!=b.get('actions')):\n",
        "                    score = 0.6*jaccard_words(a['quote'], b['quote'])\n",
        "                    cand.append((score, a.to_dict(), b.to_dict()))\n",
        "        cand.sort(key=lambda t: t[0], reverse=True)\n",
        "        out = take_distinct(cand, 3, key=lambda t: (t[1]['row_id'], t[2]['row_id']))\n",
        "        out = [(score,a,b,\n",
        "                [f\"Agents: {a.get('agents') or 'none'}\", f\"Patients: {a.get('patients') or 'none'}\", f\"Actions: {a.get('actions') or 'none'}\"],\n",
        "                [f\"Agents: {b.get('agents') or 'none'}\", f\"Patients: {b.get('patients') or 'none'}\", f\"Actions: {b.get('actions') or 'none'}\"]\n",
        "               ) for score,a,b in out]\n",
        "    else:\n",
        "        out = pick_pairs_by_filter(\n",
        "            lambda df: df['quote'].str.contains(r'\\bjunzi\\b|\\bgentleman\\b|\\bruler\\b|\\bsuperior\\b', re.I, na=False),\n",
        "            lambda df: df['quote'].str.contains(r'\\bpeople\\b|\\bcommoners\\b|\\bbenefit\\b|\\bcare\\b', re.I, na=False),\n",
        "            same_topic=True, k=3)\n",
        "        out = [(score,a,b,['role: gentleman/junzi?'], ['role: people/benefit']) for score,a,b in out]\n",
        "\n",
        "    for score,a,b,badges_l,badges_r in out:\n",
        "        show_pair(\"10) Role framing (agent/action/patient)\", a,b, badges_l, badges_r)\n",
        "\n",
        "# ---------- Show what was found ----------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LOADING ANALYSIS FILES (Optional)\")\n",
        "print(\"=\"*60)\n",
        "for name,path in [\n",
        "    (\"moral foundations\", mf_path),\n",
        "    (\"dialogue acts\", da_path),\n",
        "    (\"evidence types\", ev_path),\n",
        "    (\"emotions\", emo_path),\n",
        "    (\"semantic roles\", roles_path),\n",
        "    (\"fallacies\", fall_path),\n",
        "    (\"persuasion\", pers_path),\n",
        "    (\"action→consequence\", ac_path),\n",
        "    (\"keywords/log-odds\", kw_path),\n",
        "    (\"topics\", topic_path),\n",
        "    (\"questions\", quest_path),\n",
        "    (\"pair similarity\", pairsim_path),\n",
        "    (\"NLI\", nli_path)\n",
        "]:\n",
        "    print(f\"{name:>22}: {path if path else '(not found — using heuristics)'}\")\n",
        "\n",
        "# ---------- Run all techniques (3 pairs each) ----------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GENERATING EXEMPLAR PAIRS\")\n",
        "print(\"=\"*60)\n",
        "technique_1()\n",
        "technique_2()\n",
        "technique_3()\n",
        "technique_4()\n",
        "technique_5()\n",
        "technique_6()\n",
        "technique_7()\n",
        "technique_8()\n",
        "technique_9()\n",
        "technique_10()\n",
        "\n",
        "print(\"\\nDone. If output looks generic, ensure your analysis files are in the BASE_DIR and named clearly.\")"
      ],
      "metadata": {
        "id": "G8i_BIPxliiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Chinese Philosophers — Knowledge File Audit (single cell)\n",
        "# Mount and config\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, re, glob, textwrap, hashlib, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "from datetime import datetime\n",
        "\n",
        "# ================== CONFIG (edit if needed) ==================\n",
        "BASE_DIR = \"/content/drive/MyDrive/Chinese Philosophers\"\n",
        "MASTER_PATH = f\"{BASE_DIR}/MASTER_DATASET.csv\"  # all features merged, should have row_id\n",
        "CLEAN_QUOTES_PATH = f\"{BASE_DIR}/chinese_philosophers_quotes_corrected.csv\"  # 5 basic cols\n",
        "# Optional: put your knowledge file (the prose doc) in Drive and set its path to compare claims\n",
        "KNOWLEDGE_FILE_PATH = f\"{BASE_DIR}/ChinesePhilosophyInfo.txt\"  # leave if absent; we’ll skip parsing\n",
        "# =============================================================\n",
        "\n",
        "def read_csv_any(path, nrows=None):\n",
        "    for enc in (\"utf-8\", \"utf-8-sig\", \"utf-16\", \"latin1\"):\n",
        "        try:\n",
        "            return pd.read_csv(path, encoding=enc, low_memory=False, nrows=nrows)\n",
        "        except Exception:\n",
        "            pass\n",
        "    raise RuntimeError(f\"Failed reading: {path}\")\n",
        "\n",
        "def exists(p): return os.path.exists(p)\n",
        "\n",
        "def list_feature_csvs(base=BASE_DIR):\n",
        "    # We’ll look for the commonly named feature tables mentioned in the project\n",
        "    name_hints = [\n",
        "        \"moral_found\", \"dialogue_acts\", \"evidence_types\",\n",
        "        \"emotion_43\", \"question_detection\", \"action_consequence\",\n",
        "        \"semantic_roles\", \"fallacy\", \"persuasion\",\n",
        "        \"logodds_keywords_by_philosopher\", \"bertopic\", \"nli_comparisons\",\n",
        "        \"crossencoder_alignments\", \"entities\", \"ner\"\n",
        "    ]\n",
        "    found = []\n",
        "    for p in glob.glob(os.path.join(base, \"**/*.csv\"), recursive=True):\n",
        "        lo = os.path.basename(p).lower()\n",
        "        if any(h in lo for h in name_hints):\n",
        "            found.append(p)\n",
        "    return sorted(found)\n",
        "\n",
        "def schema(df):\n",
        "    return {\"columns\": list(df.columns), \"rows\": len(df)}\n",
        "\n",
        "def norm_text(s):\n",
        "    s = re.sub(r\"\\s+\", \" \", str(s)).strip()\n",
        "    return s\n",
        "\n",
        "def quote_hash(s):\n",
        "    return hashlib.md5(norm_text(s).encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "report = []\n",
        "def add(section, text):\n",
        "    report.append(f\"### {section}\\n{text.strip()}\\n\")\n",
        "\n",
        "# ---------- 0) Inventory ----------\n",
        "add(\"Paths\",\n",
        "    f\"- BASE_DIR: `{BASE_DIR}`\\n\"\n",
        "    f\"- MASTER_PATH: `{MASTER_PATH}` — exists: {exists(MASTER_PATH)}\\n\"\n",
        "    f\"- CLEAN_QUOTES_PATH: `{CLEAN_QUOTES_PATH}` — exists: {exists(CLEAN_QUOTES_PATH)}\\n\"\n",
        "    f\"- KNOWLEDGE_FILE_PATH: `{KNOWLEDGE_FILE_PATH}` — exists: {exists(KNOWLEDGE_FILE_PATH)}\")\n",
        "\n",
        "features = list_feature_csvs()\n",
        "add(\"Detected feature CSVs (by common names)\", \"\\n\".join(f\"- {os.path.basename(p)}\" for p in features) or \"_None found_\")\n",
        "\n",
        "# ---------- 1) Core files sanity ----------\n",
        "issues = []\n",
        "\n",
        "if not exists(MASTER_PATH):\n",
        "    issues.append(\"MASTER_DATASET.csv missing. The knowledge file should instruct users to use MASTER_DATASET.csv (with row_id) for merges.\")\n",
        "else:\n",
        "    master = read_csv_any(MASTER_PATH)\n",
        "    mcols = set(master.columns.str.lower())\n",
        "    has_row_id = \"row_id\" in mcols\n",
        "    if not has_row_id:\n",
        "        issues.append(\"MASTER_DATASET.csv does not contain `row_id` (required primary key).\")\n",
        "    else:\n",
        "        # basic key checks\n",
        "        rid_dups = master[\"row_id\"].duplicated().sum()\n",
        "        if rid_dups:\n",
        "            issues.append(f\"`row_id` is not unique in MASTER_DATASET.csv (duplicates: {rid_dups}).\")\n",
        "    # philosopher/quote presence\n",
        "    if \"philosopher\" not in mcols or (\"quote\" not in mcols and \"text\" not in mcols):\n",
        "        issues.append(\"MASTER_DATASET.csv should include `philosopher` and `quote` (or `text`). At least one is missing.\")\n",
        "\n",
        "if exists(CLEAN_QUOTES_PATH):\n",
        "    clean = read_csv_any(CLEAN_QUOTES_PATH)\n",
        "    ccols = set(clean.columns.str.lower())\n",
        "    # Should NOT have row_id per design (display-only)\n",
        "    if \"row_id\" in ccols:\n",
        "        issues.append(\"Base clean quotes file unexpectedly contains `row_id`. Doc should clarify it is display-only and normally has no `row_id`.\")\n",
        "    # Check minimal required fields\n",
        "    required = {\"philosopher\", \"quote\"}\n",
        "    miss = required - ccols\n",
        "    if miss:\n",
        "        issues.append(f\"Clean quotes file missing fields: {sorted(miss)} (doc lists 5 basic columns; verify).\")\n",
        "\n",
        "# ---------- 2) Feature tables: joinability on row_id ----------\n",
        "feat_summary = []\n",
        "rowid_missing = []\n",
        "for p in features:\n",
        "    df = read_csv_any(p, nrows=200)  # small peek\n",
        "    cols = set(df.columns.str.lower())\n",
        "    has_rid = \"row_id\" in cols\n",
        "    feat_summary.append(f\"- {os.path.basename(p)} — rows≈? (peek {len(df)}), has_row_id={has_rid}; columns: {', '.join(list(df.columns)[:12]) + (' …' if df.shape[1]>12 else '')}\")\n",
        "    if not has_rid:\n",
        "        rowid_missing.append(os.path.basename(p))\n",
        "\n",
        "add(\"Feature table schemas (peek)\", \"\\n\".join(feat_summary) or \"_No feature files detected._\")\n",
        "\n",
        "if rowid_missing:\n",
        "    issues.append(\"Some feature tables lack `row_id` and can’t be merged as documented: \" + \", \".join(rowid_missing))\n",
        "\n",
        "# ---------- 3) Recompute headline stats from MASTER (if possible) ----------\n",
        "def compute_headlines(M):\n",
        "    out = {}\n",
        "    # philosopher counts\n",
        "    if \"philosopher\" in M.columns:\n",
        "        counts = M[\"philosopher\"].value_counts(dropna=False).to_dict()\n",
        "        out[\"counts_by_philosopher\"] = counts\n",
        "\n",
        "    # explicit moral terms heuristic (if no labeled column)\n",
        "    qcol = \"quote\" if \"quote\" in M.columns else (\"text\" if \"text\" in M.columns else None)\n",
        "    if qcol:\n",
        "        patt_explicit = re.compile(r\"\\b(benefit|profit|care|harm|impartial|universal love|fair|loyal|authority|sanct|benevolence|ritual|li|propriety)\\b\", re.I)\n",
        "        M[\"_explicit_moral\"] = M[qcol].astype(str).str.contains(patt_explicit, na=False)\n",
        "        if \"philosopher\" in M.columns:\n",
        "            exp_rates = M.groupby(\"philosopher\")[\"_explicit_moral\"].mean().round(4).to_dict()\n",
        "            out[\"explicit_moral_rate\"] = exp_rates\n",
        "\n",
        "    # moral foundations (if labeled)\n",
        "    fcol = None\n",
        "    for c in M.columns:\n",
        "        cl = c.lower()\n",
        "        if cl in {\"foundation\",\"moral_foundation\"}:\n",
        "            fcol = c; break\n",
        "    if fcol and \"philosopher\" in M.columns:\n",
        "        dist = (M.groupby([\"philosopher\", fcol])[fcol]\n",
        "                .count().rename(\"n\").reset_index()\n",
        "                .pivot(index=fcol, columns=\"philosopher\", values=\"n\").fillna(0))\n",
        "        totals = dist.sum(axis=0)\n",
        "        share = (dist / totals) * 100\n",
        "        out[\"foundation_share_pct\"] = share.round(2)\n",
        "\n",
        "    # entities / cultural works\n",
        "    ent_path = next((p for p in features if re.search(r\"(entities|ner)\", os.path.basename(p), re.I)), None)\n",
        "    if ent_path:\n",
        "        ENT = read_csv_any(ent_path)\n",
        "        # Try to identify type columns\n",
        "        type_col = next((c for c in ENT.columns if re.search(r\"(type|label|ent_type|ner)\", c, re.I)), None)\n",
        "        text_col = next((c for c in ENT.columns if re.search(r\"(entity|text|mention)\", c, re.I)), None)\n",
        "        # Join back to philosopher via row_id\n",
        "        if \"row_id\" in ENT.columns and \"row_id\" in M.columns and \"philosopher\" in M.columns:\n",
        "            entJ = ENT.merge(M[[\"row_id\",\"philosopher\"]], on=\"row_id\", how=\"left\")\n",
        "            if type_col:\n",
        "                # use WORK_OF_ART / TITLE like labels when present; else fallback to heuristic\n",
        "                mask = entJ[type_col].astype(str).str.contains(r\"work|book|title|art|classic|poem|ode|rit(e|es)|classic\", case=False, regex=True)\n",
        "            else:\n",
        "                # heuristic fallback on the text column\n",
        "                tc = text_col or \"entity\"\n",
        "                mask = entJ[tc].astype(str).str.contains(r\"\\b(odes|rites|book|classic|annals|poetry|canon)\\b\", case=False, regex=True)\n",
        "            cw = entJ[mask]\n",
        "            out[\"cultural_works_counts\"] = cw[\"philosopher\"].value_counts().to_dict()\n",
        "    return out\n",
        "\n",
        "if exists(MASTER_PATH):\n",
        "    M = read_csv_any(MASTER_PATH)\n",
        "    # normalize philosopher casing early\n",
        "    if \"philosopher\" in M.columns:\n",
        "        M[\"philosopher\"] = M[\"philosopher\"].astype(str).str.title()\n",
        "    headlines = compute_headlines(M)\n",
        "\n",
        "    # Pretty-print\n",
        "    txt = []\n",
        "    if \"counts_by_philosopher\" in headlines:\n",
        "        txt.append(\"**Rows by philosopher:** \" + json.dumps(headlines[\"counts_by_philosopher\"]))\n",
        "    if \"explicit_moral_rate\" in headlines:\n",
        "        r = {k: f\"{v*100:.1f}%\" for k,v in headlines[\"explicit_moral_rate\"].items()}\n",
        "        txt.append(\"**Explicit moral term rate (heuristic):** \" + json.dumps(r))\n",
        "    if \"foundation_share_pct\" in headlines:\n",
        "        txt.append(\"**Moral foundation share (% of each philosopher’s corpus):**\")\n",
        "        txt.append(headlines[\"foundation_share_pct\"].to_string())\n",
        "    if \"cultural_works_counts\" in headlines:\n",
        "        cw = headlines[\"cultural_works_counts\"]\n",
        "        txt.append(\"**Cultural works mentions (entities):** \" + json.dumps(cw))\n",
        "        if set(cw) >= {\"Confucius\",\"Mozi\"} and cw[\"Mozi\"] > 0:\n",
        "            ratio = (cw[\"Confucius\"] / max(1, cw[\"Mozi\"]))\n",
        "            txt.append(f\"_Confucius vs Mozi ratio_ ≈ {ratio:.2f}×\")\n",
        "    add(\"Recomputed headline stats (to cross-check doc claims)\", \"\\n\\n\".join(txt) if txt else \"_Not enough labeled columns to recompute._\")\n",
        "\n",
        "# ---------- 4) Knowledge file parsing (optional) ----------\n",
        "doc_claims = {}\n",
        "if exists(KNOWLEDGE_FILE_PATH):\n",
        "    with open(KNOWLEDGE_FILE_PATH, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        K = f.read()\n",
        "    # Grab some common claims (very light heuristics)\n",
        "    m = re.search(r\"sanctity[^%]*?(\\d+(\\.\\d+)?)%[^%]*?(\\d+(\\.\\d+)?)%\", K, re.I)\n",
        "    if m:\n",
        "        doc_claims[\"sanctity_pair\"] = (float(m.group(1)), float(m.group(3)))\n",
        "    m2 = re.search(r\"care/harm[^%]*?(\\d+(\\.\\d+)?)%[^%]*?(\\d+(\\.\\d+)?)%\", K, re.I)\n",
        "    if m2:\n",
        "        doc_claims[\"careharm_pair\"] = (float(m2.group(1)), float(m2.group(3)))\n",
        "    m3 = re.search(r\"(\\d+)\\s*[xX]\\b[^%]*cultural\", K)\n",
        "    if m3:\n",
        "        doc_claims[\"cultural_ratio_x\"] = int(m3.group(1))\n",
        "    add(\"Parsed claims from knowledge file (best-effort)\", json.dumps(doc_claims, indent=2) or \"_None detected_\")\n",
        "else:\n",
        "    add(\"Parsed claims from knowledge file\", \"_Knowledge file not found in Drive; skipped claim parsing._\")\n",
        "\n",
        "# ---------- 5) Synthesize actionable edit suggestions ----------\n",
        "suggestions = []\n",
        "\n",
        "if issues:\n",
        "    suggestions.append(\"**Fix data keys & file usage**\")\n",
        "    for i in issues:\n",
        "        suggestions.append(f\"- {i}\")\n",
        "\n",
        "# If we computed explicit moral rates, suggest wording guidance\n",
        "if exists(MASTER_PATH):\n",
        "    if \"explicit_moral_rate\" in headlines:\n",
        "        r = headlines[\"explicit_moral_rate\"]\n",
        "        if \"Confucius\" in r and \"Mozi\" in r:\n",
        "            cf = f\"{r['Confucius']*100:.1f}%\"\n",
        "            mz = f\"{r['Mozi']*100:.1f}%\"\n",
        "            suggestions.append(\n",
        "                f\"**Clarify ‘explicit moral language’ sentence**: say something like \"\n",
        "                f\"“Confucius uses explicit moral terms in ~{cf} of quotes vs. Mozi ~{mz},” \"\n",
        "                f\"or invert depending on computed values.\"\n",
        "            )\n",
        "\n",
        "    # If we have foundation shares, provide directionality check text\n",
        "    if \"foundation_share_pct\" in headlines:\n",
        "        F = headlines[\"foundation_share_pct\"]\n",
        "        for target in [\"sanctity\",\"virtue\",\"authority\",\"care\",\"harm\",\"fairness\",\"loyalty\"]:\n",
        "            # find any matching index\n",
        "            row = [idx for idx in F.index.astype(str).str.lower() if target in idx]\n",
        "            if row:\n",
        "                idx = F.index[[i for i,x in enumerate(F.index.astype(str).str.lower()) if target in x][0]]\n",
        "                rowvals = F.loc[idx]\n",
        "                if {\"Confucius\",\"Mozi\"}.issubset(rowvals.index):\n",
        "                    c, m = rowvals[\"Confucius\"], rowvals[\"Mozi\"]\n",
        "                    if (c<m and \"Confucius emphasizes\" in (doc_claims or {})) or (m<c and \"Mozi emphasizes\" in (doc_claims or {})):\n",
        "                        suggestions.append(\n",
        "                            f\"**Check wording** for {idx}: computed shares show Confucius={c:.2f}% vs Mozi={m:.2f}%. \"\n",
        "                            f\"Ensure the sentence matches the direction (who emphasizes more).\"\n",
        "                        )\n",
        "\n",
        "    # Cultural works check\n",
        "    if \"cultural_works_counts\" in headlines:\n",
        "        cw = headlines[\"cultural_works_counts\"]\n",
        "        if {\"Confucius\",\"Mozi\"} <= cw.keys() and cw[\"Mozi\"]>0:\n",
        "            ratio = cw[\"Confucius\"]/cw[\"Mozi\"]\n",
        "            if \"cultural_ratio_x\" in doc_claims:\n",
        "                claimed = doc_claims[\"cultural_ratio_x\"]\n",
        "                if abs(ratio - claimed) > 2:  # very rough tolerance\n",
        "                    suggestions.append(\n",
        "                        f\"**Clarify ‘cultural works ×’ claim**: measured ratio ≈ {ratio:.2f}× (Confucius/Mozi). \"\n",
        "                        f\"Doc says {claimed}×. Specify method: which entity types counted (e.g., WORK_OF_ART/TITLE) and dataset used.\"\n",
        "                    )\n",
        "            else:\n",
        "                suggestions.append(\n",
        "                    f\"**Add method to ‘cultural works’ claim**: current measured ratio ≈ {ratio:.2f}×. \"\n",
        "                    \"State which entity tags/types or keyword rules define ‘cultural work’.\"\n",
        "                )\n",
        "        else:\n",
        "            suggestions.append(\n",
        "                \"If the doc claims differences in ‘cultural works’ mentions, add or point to an entities/NER CSV \"\n",
        "                \"(with row_id + ent_type or label) so the claim is reproducible.\"\n",
        "            )\n",
        "\n",
        "# Summarize mergeability\n",
        "if exists(MASTER_PATH):\n",
        "    missing_for_merge = [os.path.basename(p) for p in features if \"row_id\" not in read_csv_any(p, nrows=5).columns.str.lower().tolist()]\n",
        "    if missing_for_merge:\n",
        "        suggestions.append(\n",
        "            \"**Add a ‘Datasets & Keys’ table** in the knowledge file with columns: `filename | has_row_id | primary key | row count | join note`. \"\n",
        "            \"Mark these as missing row_id: \" + \", \".join(missing_for_merge)\n",
        "        )\n",
        "\n",
        "# Write markdown report to Drive\n",
        "audit_path = os.path.join(BASE_DIR, \"_doc_audit.md\")\n",
        "with open(audit_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(f\"# Knowledge File Audit — {datetime.now().isoformat(timespec='seconds')}\\n\\n\")\n",
        "    f.write(\"\\n\\n\".join(report))\n",
        "    f.write(\"\\n\\n---\\n\\n## Actionable edit suggestions\\n\")\n",
        "    if suggestions:\n",
        "        for s in suggestions:\n",
        "            f.write(f\"- {s}\\n\")\n",
        "    else:\n",
        "        f.write(\"_No blocking issues detected. Document appears consistent with current data._\\n\")\n",
        "\n",
        "print(f\"Audit complete. Open: {audit_path}\")\n"
      ],
      "metadata": {
        "id": "MhGPiCCUo9-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Discourse Graph Builder (Confucius & Mozi) — NLI with conf_row_id/mozi_row_id ===\n",
        "# One‑cell Colab script. Builds JSON/CSV/GraphML discourse graphs from MASTER_DATASET\n",
        "# and optional NLI pair file. This version explicitly supports NLI columns\n",
        "# named conf_row_id / mozi_row_id (plus many other variants).\n",
        "\n",
        "!pip -q install pandas networkx\n",
        "\n",
        "import os, json, re, glob\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "# ---------------------- Config ----------------------\n",
        "BASE = Path(\"/content/drive/MyDrive/Chinese Philosophers\")\n",
        "OUT  = BASE / \"discourse_graphs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MASTER_CSV = BASE / \"MASTER_DATASET.csv\"  # required\n",
        "# If absent, this script will proceed without NLI edges\n",
        "PREFERRED_NLI = BASE / \"nli_comparisons.csv\"\n",
        "\n",
        "# Optional: add light \"related\" edges using TF‑IDF nearest neighbors when no NLI\n",
        "DO_FALLBACK_SIMILARITY = False\n",
        "TFIDF_MAX_DISTANCE = 0.35  # smaller = stricter\n",
        "\n",
        "# Output filenames\n",
        "JSON_OUT    = OUT / \"dg_confucius_mozi.json\"\n",
        "GRAPHML_OUT = OUT / \"dg_confucius_mozi.graphml\"\n",
        "NODES_CSV   = OUT / \"dg_nodes.csv\"\n",
        "EDGES_CSV   = OUT / \"dg_edges.csv\"\n",
        "\n",
        "# ---------------------- Helpers ----------------------\n",
        "def ensure_master(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Ensure required columns; create row_id from index if missing.\"\"\"\n",
        "    required_soft = [\"philosopher\", \"chapter_verse\", \"quote\"]\n",
        "    for c in required_soft:\n",
        "        if c not in df.columns:\n",
        "            raise ValueError(f\"MASTER_DATASET.csv missing required column: {c}\")\n",
        "    if \"row_id\" not in df.columns:\n",
        "        df = df.copy()\n",
        "        df[\"row_id\"] = (df.index + 1).astype(int)\n",
        "    if \"work\" not in df.columns:\n",
        "        df[\"work\"] = \"\"\n",
        "    if \"source\" not in df.columns:\n",
        "        df[\"source\"] = \"\"\n",
        "    if \"is_question\" not in df.columns:\n",
        "        df[\"is_question\"] = False\n",
        "    if \"evidence_type\" not in df.columns:\n",
        "        df[\"evidence_type\"] = \"\"\n",
        "    return df\n",
        "\n",
        "\n",
        "def node_type(row) -> str:\n",
        "    if bool(row.get(\"is_question\", False)):\n",
        "        return \"Question\"\n",
        "    if str(row.get(\"evidence_type\", \"\")).strip():\n",
        "        return \"Evidence\"\n",
        "    return \"Claim\"\n",
        "\n",
        "\n",
        "def short_label(txt, n=140) -> str:\n",
        "    t = \" \".join(str(txt).split())\n",
        "    return (t[:n] + \"…\") if len(t) > n else t\n",
        "\n",
        "\n",
        "def canon_node_id(x) -> str:\n",
        "    # Accept 123, \"123\", \"n-123\", etc. → \"n-123\"\n",
        "    s = str(x).strip()\n",
        "    m = re.search(r\"\\d+\", s)\n",
        "    if not m:\n",
        "        raise ValueError(f\"Cannot parse row id from value: {x!r}\")\n",
        "    return f\"n-{int(m.group(0))}\"\n",
        "\n",
        "\n",
        "def load_nli_file() -> pd.DataFrame:\n",
        "    \"\"\"Locate and load an NLI CSV, returning a normalized edge table or empty df.\n",
        "    Supports conf_row_id / mozi_row_id and many other variants.\n",
        "    \"\"\"\n",
        "    # Prefer explicit file, otherwise any *nli*.csv in BASE\n",
        "    candidates = [str(PREFERRED_NLI)] + sorted(glob.glob(str(BASE / \"*nli*.csv\")))\n",
        "    nli_path = next((Path(p) for p in candidates if Path(p).exists()), None)\n",
        "    if nli_path is None:\n",
        "        print(\"No NLI file found (looked for nli_comparisons.csv or *nli*.csv).\")\n",
        "        return pd.DataFrame(columns=[\"source\", \"target\", \"type\", \"evidence\"])  # empty\n",
        "\n",
        "    nli = pd.read_csv(nli_path)\n",
        "    print(f\"Using NLI file: {nli_path.name}\")\n",
        "    print(\"NLI columns:\", list(nli.columns))\n",
        "\n",
        "    def pick_col(df, variants, required=True):\n",
        "        for c in variants:\n",
        "            if c in df.columns:\n",
        "                return c\n",
        "        if required:\n",
        "            raise ValueError(f\"NLI file is missing any of these columns: {variants}\")\n",
        "        return None\n",
        "\n",
        "    # Explicitly include conf_row_id / mozi_row_id and generic fallbacks\n",
        "    left_variants  = [\n",
        "        \"conf_row_id\", \"confucius_row_id\", \"conf_id\", \"conf_quote_id\",\n",
        "        \"a_id\",\"row_id_a\",\"id_a\",\"src_id\",\"source_id\",\"source\",\"left_id\",\"i\",\"premise_id\"\n",
        "    ]\n",
        "    right_variants = [\n",
        "        \"mozi_row_id\", \"mozi_id\", \"mozi_quote_id\",\n",
        "        \"b_id\",\"row_id_b\",\"id_b\",\"dst_id\",\"target_id\",\"target\",\"right_id\",\"j\",\"hypothesis_id\"\n",
        "    ]\n",
        "\n",
        "    left_col  = pick_col(nli, left_variants)\n",
        "    right_col = pick_col(nli, right_variants)\n",
        "\n",
        "    # Label column variants, including 'relationship'\n",
        "    label_col = pick_col(nli, [\n",
        "        \"relationship\",\"nli_label\",\"label\",\"relation\",\"edge_type\",\"pred_label\",\"prediction\",\"rel\"\n",
        "    ], required=False)\n",
        "\n",
        "    # Optional numeric strength/score column (stored on edge as 'score')\n",
        "    score_col = pick_col(nli, [\"similarity_score\",\"score\",\"prob\",\"confidence\"], required=False)\n",
        "\n",
        "    def norm_rel(label: str) -> str:\n",
        "        lab = str(label).strip().lower()\n",
        "        if lab in {\"entailment\",\"entails\",\"support\",\"supports\",\"agree\",\"agrees\",\"aligned\",\"alignment\",\"consistent\",\"paraphrase\"}:\n",
        "            return \"supports\"\n",
        "        if lab in {\"contradiction\",\"contradict\",\"contradicts\",\"refute\",\"refutes\",\"attack\",\"attacks\",\"disagree\",\"disagrees\",\"oppose\",\"opposes\",\"conflict\",\"inconsistent\",\"opposed\"}:\n",
        "            return \"opposes\"\n",
        "        return \"related\"\n",
        "\n",
        "    if label_col is None:\n",
        "        nli[\"__label__\"] = \"related\"\n",
        "        label_col = \"__label__\"\n",
        "\n",
        "    edges = []\n",
        "    for _, e in nli.dropna(subset=[left_col, right_col]).iterrows():\n",
        "        try:\n",
        "            a = canon_node_id(e[left_col])\n",
        "            b = canon_node_id(e[right_col])\n",
        "        except ValueError:\n",
        "            continue\n",
        "        if a == b:\n",
        "            continue\n",
        "        rel = norm_rel(e[label_col])\n",
        "        ed = {\"source\": a, \"target\": b, \"type\": rel, \"evidence\": \"nli\"}\n",
        "        if score_col is not None and pd.notna(e.get(score_col)):\n",
        "            try:\n",
        "                ed[\"score\"] = float(e.get(score_col))\n",
        "            except Exception:\n",
        "                pass\n",
        "        edges.append(ed)\n",
        "\n",
        "    edges_df = pd.DataFrame(edges).drop_duplicates()\n",
        "    print(\"Edge type counts from NLI:\", edges_df[\"type\"].value_counts(dropna=False).to_dict())\n",
        "    return edges_df\n",
        "\n",
        "# ---------------------- Load data ----------------------\n",
        "if not MASTER_CSV.exists():\n",
        "    raise FileNotFoundError(f\"MASTER dataset not found at: {MASTER_CSV}\")\n",
        "\n",
        "master = pd.read_csv(MASTER_CSV)\n",
        "master = ensure_master(master)\n",
        "\n",
        "# ---------------------- Nodes ----------------------\n",
        "nodes = []\n",
        "for _, r in master.iterrows():\n",
        "    nid = canon_node_id(r[\"row_id\"])  # robust formatting\n",
        "    nodes.append({\n",
        "        \"id\": nid,\n",
        "        \"type\": node_type(r),\n",
        "        \"title\": f\"{r['philosopher']} {str(r.get('chapter_verse','')).strip()}\",\n",
        "        \"quote\": str(r[\"quote\"]),\n",
        "        \"label\": short_label(r[\"quote\"], 140),\n",
        "        \"philosopher\": r[\"philosopher\"],\n",
        "        \"work\": r.get(\"work\", \"\"),\n",
        "        \"chapter_verse\": r.get(\"chapter_verse\", \"\"),\n",
        "        \"source\": r.get(\"source\", \"\"),\n",
        "    })\n",
        "\n",
        "nodes_df = pd.DataFrame(nodes).drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
        "\n",
        "# ---------------------- Edges ----------------------\n",
        "edges_df = load_nli_file()  # may be empty\n",
        "\n",
        "# Optional: intra‑quote scaffolding (action → consequence) if present\n",
        "if {\"action\",\"consequence\"}.issubset(master.columns):\n",
        "    self_edges = []\n",
        "    for _, r in master.dropna(subset=[\"action\",\"consequence\"]).iterrows():\n",
        "        nid = canon_node_id(r[\"row_id\"])\n",
        "        self_edges.append({\"source\": nid, \"target\": nid, \"type\": \"informs\", \"evidence\": \"action_consequence\"})\n",
        "    if self_edges:\n",
        "        edges_df = pd.concat([edges_df, pd.DataFrame(self_edges)], ignore_index=True).drop_duplicates()\n",
        "\n",
        "# Fallback similarity edges (optional)\n",
        "if DO_FALLBACK_SIMILARITY and edges_df.empty:\n",
        "    print(\"No NLI edges; creating light 'related' edges via TF‑IDF nearest neighbors…\")\n",
        "    try:\n",
        "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "        from sklearn.neighbors import NearestNeighbors\n",
        "    except Exception:\n",
        "        print(\"Installing scikit‑learn for TF‑IDF fallback…\")\n",
        "        !pip -q install scikit-learn\n",
        "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "        from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "    quotes = nodes_df[[\"id\",\"quote\"]].copy()\n",
        "    tfidf = TfidfVectorizer(min_df=2, max_df=0.6, ngram_range=(1,2))\n",
        "    X = tfidf.fit_transform(quotes[\"quote\"].astype(str))\n",
        "    nn = NearestNeighbors(n_neighbors=2, metric=\"cosine\").fit(X)\n",
        "    distances, idxs = nn.kneighbors(X)\n",
        "    fallback = []\n",
        "    for i, (dists, nbrs) in enumerate(zip(distances, idxs)):\n",
        "        if len(nbrs) < 2:\n",
        "            continue\n",
        "        j = nbrs[1]\n",
        "        if quotes.iloc[i][\"id\"] != quotes.iloc[j][\"id\"] and dists[1] <= TFIDF_MAX_DISTANCE:\n",
        "            fallback.append({\n",
        "                \"source\": quotes.iloc[i][\"id\"],\n",
        "                \"target\": quotes.iloc[j][\"id\"],\n",
        "                \"type\": \"related\",\n",
        "                \"evidence\": \"tfidf_nn\"\n",
        "            })\n",
        "    fb_df = pd.DataFrame(fallback).drop_duplicates()\n",
        "    edges_df = pd.concat([edges_df, fb_df], ignore_index=True).drop_duplicates()\n",
        "    print(f\"Added {len(fb_df)} fallback 'related' edges.\")\n",
        "\n",
        "# ---------------------- Build graph & export ----------------------\n",
        "G = nx.DiGraph()\n",
        "for _, n in nodes_df.iterrows():\n",
        "    G.add_node(n[\"id\"], **n.to_dict())\n",
        "for _, e in edges_df.iterrows():\n",
        "    G.add_edge(e[\"source\"], e[\"target\"], **e.to_dict())\n",
        "\n",
        "nx.write_graphml(G, GRAPHML_OUT)\n",
        "\n",
        "meta = {\n",
        "    \"schema\": \"discourse-graph-v0\",\n",
        "    \"created_in\": \"Colab\",\n",
        "    \"created_at\": datetime.utcnow().isoformat() + \"Z\",\n",
        "    \"source\": \"Chinese Philosophers project\",\n",
        "    \"node_count\": int(nodes_df.shape[0]),\n",
        "    \"edge_count\": int(edges_df.shape[0]),\n",
        "}\n",
        "\n",
        "with open(JSON_OUT, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump({\"schema\": meta[\"schema\"], \"meta\": meta, \"nodes\": nodes_df.to_dict(orient=\"records\"), \"edges\": edges_df.to_dict(orient=\"records\")}, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "nodes_df.to_csv(NODES_CSV, index=False)\n",
        "edges_df.to_csv(EDGES_CSV, index=False)\n",
        "\n",
        "# ---------------------- Report ----------------------\n",
        "print(\"\\n=== Discourse Graph Build Complete ===\")\n",
        "print(\"Nodes:\", meta[\"node_count\"], \"Edges:\", meta[\"edge_count\"])\n",
        "print(\"Wrote:\")\n",
        "print(\" -\", JSON_OUT)\n",
        "print(\" -\", GRAPHML_OUT)\n",
        "print(\" -\", NODES_CSV)\n",
        "print(\" -\", EDGES_CSV)\n",
        "\n",
        "# Quick sanity: per‑relation counts & top philosophers\n",
        "if not edges_df.empty:\n",
        "    print(\"\\nEdge types:\")\n",
        "    print(edges_df[\"type\"].value_counts(dropna=False))\n",
        "\n",
        "print(\"\\nTop philosophers by node count:\")\n",
        "print(nodes_df[\"philosopher\"].value_counts().head(10))\n"
      ],
      "metadata": {
        "id": "sFV11mDcrPzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import React, { useEffect, useMemo, useRef, useState } from \"react\";\n",
        "import CytoscapeComponent from \"react-cytoscapejs\";\n",
        "import cytoscape from \"cytoscape\";\n",
        "import coseBilkent from \"cytoscape-cose-bilkent\";\n",
        "import dagre from \"cytoscape-dagre\";\n",
        "import { Card, CardContent } from \"@/components/ui/card\";\n",
        "import { Button } from \"@/components/ui/button\";\n",
        "import { Input } from \"@/components/ui/input\";\n",
        "import { Checkbox } from \"@/components/ui/checkbox\";\n",
        "import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from \"@/components/ui/select\";\n",
        "import { Slider } from \"@/components/ui/slider\";\n",
        "import { Upload, Download, RefreshCw, Network, Search, Crosshair } from \"lucide-react\";\n",
        "\n",
        "// Register layouts\n",
        "cytoscape.use(coseBilkent);\n",
        "cytoscape.use(dagre);\n",
        "\n",
        "/**\n",
        " * Drop-in viewer for your discourse-graph JSON (dg_confucius_mozi.json).\n",
        " *\n",
        " * Supports filters by philosopher, node type, edge type, text search, and cross-philosopher edges.\n",
        " * Exports PNG. Layouts: cose-bilkent (default), concentric, dagre, grid.\n",
        " */\n",
        "export default function DiscourseGraphVisualizer() {\n",
        "  const cyRef = useRef(null as any);\n",
        "  const [raw, setRaw] = useState<any | null>(null);\n",
        "  const [elements, setElements] = useState<any[]>([]);\n",
        "  const [layoutName, setLayoutName] = useState(\"cose-bilkent\");\n",
        "  const [search, setSearch] = useState(\"\");\n",
        "  const [edgeTypes, setEdgeTypes] = useState<{[k:string]: boolean}>({ supports: true, opposes: true, related: true });\n",
        "  const [nodeTypes, setNodeTypes] = useState<{[k:string]: boolean}>({ Claim: true, Evidence: true, Question: true });\n",
        "  const [philosophers, setPhilosophers] = useState<{[k:string]: boolean}>({});\n",
        "  const [crossOnly, setCrossOnly] = useState(false);\n",
        "  const [minDegree, setMinDegree] = useState(0);\n",
        "  const [edgeOpacity, setEdgeOpacity] = useState(70);\n",
        "\n",
        "  // When raw JSON loads, setup philosopher toggles\n",
        "  useEffect(() => {\n",
        "    if (!raw?.nodes) return;\n",
        "    const phils = Array.from(new Set(raw.nodes.map((n:any) => n.philosopher || n.meta?.philosopher).filter(Boolean)));\n",
        "    if (phils.length && Object.keys(philosophers).length === 0) {\n",
        "      const init:any = {}; phils.forEach(p => init[p] = true); setPhilosophers(init);\n",
        "    }\n",
        "  }, [raw]);\n",
        "\n",
        "  // Build Cytoscape elements from raw + filters\n",
        "  useEffect(() => {\n",
        "    if (!raw?.nodes) { setElements([]); return; }\n",
        "\n",
        "    const q = (s:string) => (s||\"\").toLowerCase();\n",
        "    const passesNode = (n:any) => {\n",
        "      const phil = n.philosopher || n.meta?.philosopher || \"\";\n",
        "      const typ = n.type || n.meta?.type || \"Claim\";\n",
        "      if (!nodeTypes[typ]) return false;\n",
        "      if (Object.keys(philosophers).length && philosophers[phil] === false) return false;\n",
        "      if (search) {\n",
        "        const hay = [n.label, n.title, n.quote, phil, typ].map(x => q(String(x||\"\"))).join(\"\\n\");\n",
        "        if (!hay.includes(q(search))) return false;\n",
        "      }\n",
        "      return true;\n",
        "    };\n",
        "\n",
        "    // Map nodes first so we can look up philosophers during edge filtering\n",
        "    const nodeById = new Map<string, any>();\n",
        "    raw.nodes.forEach((n:any) => { nodeById.set(n.id, n); });\n",
        "\n",
        "    const passesEdge = (e:any) => {\n",
        "      if (!edgeTypes[e.type]) return false;\n",
        "      const s = nodeById.get(e.source), t = nodeById.get(e.target);\n",
        "      if (!s || !t) return false;\n",
        "      if (!passesNode(s) || !passesNode(t)) return false;\n",
        "      if (crossOnly) {\n",
        "        const ps = s.philosopher || s.meta?.philosopher; const pt = t.philosopher || t.meta?.philosopher;\n",
        "        if (!ps || !pt || ps === pt) return false;\n",
        "      }\n",
        "      return true;\n",
        "    };\n",
        "\n",
        "    const keptEdges = (raw.edges || []).filter(passesEdge);\n",
        "\n",
        "    // Compute degree to allow minDegree filtering\n",
        "    const degCount = new Map<string, number>();\n",
        "    keptEdges.forEach((e:any) => {\n",
        "      degCount.set(e.source, (degCount.get(e.source)||0) + 1);\n",
        "      degCount.set(e.target, (degCount.get(e.target)||0) + 1);\n",
        "    });\n",
        "\n",
        "    const keptNodes = raw.nodes.filter(n => passesNode(n) && (minDegree <= 0 || (degCount.get(n.id)||0) >= minDegree));\n",
        "\n",
        "    // Re-filter edges to drop those touching filtered-out nodes\n",
        "    const nodeSet = new Set(keptNodes.map(n => n.id));\n",
        "    const finalEdges = keptEdges.filter((e:any) => nodeSet.has(e.source) && nodeSet.has(e.target));\n",
        "\n",
        "    const elNodes = keptNodes.map((n:any) => ({ data: {\n",
        "      id: n.id,\n",
        "      label: n.label || n.title || n.id,\n",
        "      philosopher: n.philosopher || n.meta?.philosopher || \"\",\n",
        "      ntype: n.type || n.meta?.type || \"Claim\",\n",
        "      quote: n.quote || \"\",\n",
        "      chapter_verse: n.chapter_verse || n.meta?.chapter_verse || \"\",\n",
        "      work: n.work || n.meta?.work || \"\",\n",
        "      title: n.title || \"\",\n",
        "    }}));\n",
        "\n",
        "    const elEdges = finalEdges.map((e:any, idx:number) => ({ data: {\n",
        "      id: e.id || `e-${idx}-${e.source}-${e.target}`,\n",
        "      source: e.source,\n",
        "      target: e.target,\n",
        "      etype: e.type || \"related\",\n",
        "      score: typeof e.score === \"number\" ? e.score : undefined,\n",
        "    }}));\n",
        "\n",
        "    setElements([ ...elNodes, ...elEdges ]);\n",
        "  }, [raw, search, nodeTypes, edgeTypes, philosophers, crossOnly, minDegree]);\n",
        "\n",
        "  const stylesheet = useMemo(() => ([\n",
        "    // Nodes\n",
        "    { selector: 'node', style: {\n",
        "      'label': 'data(label)',\n",
        "      'font-size': 10,\n",
        "      'text-valign': 'center',\n",
        "      'text-halign': 'center',\n",
        "      'text-wrap': 'wrap',\n",
        "      'text-max-width': 120,\n",
        "      'width': 14,\n",
        "      'height': 14,\n",
        "      'background-color': '#e5e7eb',\n",
        "      'border-width': 2,\n",
        "      'border-color': '#111827',\n",
        "    }},\n",
        "    // Node shape by type\n",
        "    { selector: 'node[ntype = \"Claim\"]', style: { 'shape': 'ellipse' }},\n",
        "    { selector: 'node[ntype = \"Evidence\"]', style: { 'shape': 'triangle' }},\n",
        "    { selector: 'node[ntype = \"Question\"]', style: { 'shape': 'diamond' }},\n",
        "    // Node color by philosopher\n",
        "    { selector: 'node[philosopher = \"Confucius\"]', style: { 'background-color': '#60a5fa', 'border-color': '#1d4ed8' }},\n",
        "    { selector: 'node[philosopher = \"Mozi\"]', style: { 'background-color': '#f87171', 'border-color': '#b91c1c' }},\n",
        "\n",
        "    // Edges\n",
        "    { selector: 'edge', style: {\n",
        "      'width': 1.5,\n",
        "      'opacity': edgeOpacity/100,\n",
        "      'line-color': '#9ca3af',\n",
        "      'target-arrow-shape': 'triangle',\n",
        "      'target-arrow-color': '#9ca3af',\n",
        "      'curve-style': 'bezier',\n",
        "    }},\n",
        "    { selector: 'edge[etype = \"supports\"]', style: { 'line-color': '#10b981', 'target-arrow-color': '#10b981', 'width': 2 }},\n",
        "    { selector: 'edge[etype = \"opposes\"]',  style: { 'line-color': '#ef4444', 'target-arrow-color': '#ef4444', 'width': 2 }},\n",
        "    { selector: 'edge[etype = \"related\"]',  style: { 'line-color': '#6b7280', 'target-arrow-color': '#6b7280' }},\n",
        "    // Hover\n",
        "    { selector: 'node:selected', style: { 'border-width': 4, 'border-color': '#111827' }},\n",
        "  ]), [edgeOpacity]);\n",
        "\n",
        "  const layout = useMemo(() => {\n",
        "    switch (layoutName) {\n",
        "      case 'concentric': return { name: 'concentric', animate: true, concentric: (n:any) => n.degree(), levelWidth: () => 2 };\n",
        "      case 'dagre': return { name: 'dagre', rankDir: 'LR', animate: true } as any;\n",
        "      case 'grid': return { name: 'grid' };\n",
        "      default: return { name: 'cose-bilkent', animate: true, randomize: true, idealEdgeLength: 60, nodeRepulsion: 8000 } as any;\n",
        "    }\n",
        "  }, [layoutName]);\n",
        "\n",
        "  const stats = useMemo(() => {\n",
        "    if (!elements.length) return null;\n",
        "    const nodes = elements.filter(e => e.data?.id && !e.data?.source);\n",
        "    const edges = elements.filter(e => e.data?.source);\n",
        "    const nByPhil: Record<string, number> = {};\n",
        "    nodes.forEach((n:any) => { nByPhil[n.data.philosopher] = (nByPhil[n.data.philosopher]||0)+1; });\n",
        "    const eByType: Record<string, number> = {};\n",
        "    edges.forEach((e:any) => { eByType[e.data.etype] = (eByType[e.data.etype]||0)+1; });\n",
        "    return { nodeCount: nodes.length, edgeCount: edges.length, nByPhil, eByType };\n",
        "  }, [elements]);\n",
        "\n",
        "  const onUpload = async (file: File) => {\n",
        "    const text = await file.text();\n",
        "    try {\n",
        "      const json = JSON.parse(text);\n",
        "      // Accept either {nodes,edges} or full wrapper { schema, meta, nodes, edges }\n",
        "      const data = json.nodes && json.edges ? json : { nodes: [], edges: [], ...json };\n",
        "      if (!Array.isArray(data.nodes) || !Array.isArray(data.edges)) throw new Error(\"File missing nodes/edges arrays.\");\n",
        "      setRaw(data);\n",
        "    } catch (e:any) {\n",
        "      alert(\"Failed to parse JSON: \" + e.message);\n",
        "    }\n",
        "  };\n",
        "\n",
        "  const runLayout = () => {\n",
        "    if (!cyRef.current) return;\n",
        "    cyRef.current.layout(layout).run();\n",
        "  };\n",
        "\n",
        "  const exportPng = () => {\n",
        "    if (!cyRef.current) return;\n",
        "    const png = cyRef.current.png({ full: true, scale: 2 });\n",
        "    const a = document.createElement('a');\n",
        "    a.href = png; a.download = 'discourse_graph.png'; a.click();\n",
        "  };\n",
        "\n",
        "  const toggle = (setter: any, state: any, key: string) => setter({ ...state, [key]: !state[key] });\n",
        "\n",
        "  return (\n",
        "    <div className=\"p-4 space-y-4\">\n",
        "      <h1 className=\"text-2xl font-semibold flex items-center gap-2\"><Network className=\"w-6 h-6\"/> Discourse Graph Visualizer</h1>\n",
        "      <Card className=\"shadow-md\">\n",
        "        <CardContent className=\"p-4 grid md:grid-cols-3 gap-4\">\n",
        "          {/* Upload */}\n",
        "          <div className=\"space-y-2\">\n",
        "            <div className=\"text-sm text-gray-600\">Upload <code>dg_confucius_mozi.json</code></div>\n",
        "            <label className=\"flex items-center gap-2\">\n",
        "              <Upload className=\"w-4 h-4\"/>\n",
        "              <Input type=\"file\" accept=\"application/json\" onChange={(e:any)=> e.target.files?.[0] && onUpload(e.target.files[0])}/>\n",
        "            </label>\n",
        "            <div className=\"text-xs text-gray-500\">Tip: export from Colab to your computer, then upload here.</div>\n",
        "          </div>\n",
        "\n",
        "          {/* Filters */}\n",
        "          <div className=\"space-y-2\">\n",
        "            <div className=\"text-sm font-medium\">Edge types</div>\n",
        "            <div className=\"flex flex-wrap gap-4 items-center\">\n",
        "              {([\"supports\",\"opposes\",\"related\"] as const).map(k => (\n",
        "                <label key={k} className=\"flex items-center gap-2 text-sm\">\n",
        "                  <Checkbox checked={edgeTypes[k]} onCheckedChange={()=>toggle(setEdgeTypes, edgeTypes, k)} /> {k}\n",
        "                </label>\n",
        "              ))}\n",
        "            </div>\n",
        "            <div className=\"text-sm font-medium mt-3\">Node types</div>\n",
        "            <div className=\"flex flex-wrap gap-4 items-center\">\n",
        "              {([\"Claim\",\"Evidence\",\"Question\"] as const).map(k => (\n",
        "                <label key={k} className=\"flex items-center gap-2 text-sm\">\n",
        "                  <Checkbox checked={nodeTypes[k]} onCheckedChange={()=>toggle(setNodeTypes, nodeTypes, k)} /> {k}\n",
        "                </label>\n",
        "              ))}\n",
        "            </div>\n",
        "          </div>\n",
        "\n",
        "          {/* Search + layout */}\n",
        "          <div className=\"space-y-3\">\n",
        "            <div className=\"flex items-center gap-2\">\n",
        "              <Search className=\"w-4 h-4\"/>\n",
        "              <Input placeholder=\"Search text / label / work / chapter\" value={search} onChange={e=>setSearch(e.target.value)} />\n",
        "            </div>\n",
        "            <div className=\"flex items-center gap-2\">\n",
        "              <Crosshair className=\"w-4 h-4\"/>\n",
        "              <label className=\"flex items-center gap-2 text-sm\">\n",
        "                <Checkbox checked={crossOnly} onCheckedChange={()=>setCrossOnly(v=>!v)} /> Show only cross‑philosopher edges\n",
        "              </label>\n",
        "            </div>\n",
        "            <div className=\"flex items-center gap-2\">\n",
        "              <span className=\"text-sm w-28\">Min degree</span>\n",
        "              <Slider value={[minDegree]} min={0} max={10} step={1} onValueChange={(v:any)=>setMinDegree(v[0])} className=\"w-full\"/>\n",
        "              <span className=\"text-xs text-gray-500 w-8 text-right\">{minDegree}</span>\n",
        "            </div>\n",
        "            <div className=\"flex items-center gap-2\">\n",
        "              <span className=\"text-sm w-28\">Edge opacity</span>\n",
        "              <Slider value={[edgeOpacity]} min={10} max={100} step={5} onValueChange={(v:any)=>setEdgeOpacity(v[0])} className=\"w-full\"/>\n",
        "              <span className=\"text-xs text-gray-500 w-8 text-right\">{edgeOpacity}%</span>\n",
        "            </div>\n",
        "            <div className=\"flex items-center gap-2\">\n",
        "              <Select value={layoutName} onValueChange={setLayoutName}>\n",
        "                <SelectTrigger className=\"w-full\"><SelectValue placeholder=\"Layout\"/></SelectTrigger>\n",
        "                <SelectContent>\n",
        "                  <SelectItem value=\"cose-bilkent\">cose‑bilkent (force)</SelectItem>\n",
        "                  <SelectItem value=\"concentric\">concentric</SelectItem>\n",
        "                  <SelectItem value=\"dagre\">dagre (ranked)</SelectItem>\n",
        "                  <SelectItem value=\"grid\">grid</SelectItem>\n",
        "                </SelectContent>\n",
        "              </Select>\n",
        "              <Button variant=\"secondary\" onClick={runLayout} className=\"shrink-0 flex items-center gap-2\"><RefreshCw className=\"w-4 h-4\"/> Run layout</Button>\n",
        "            </div>\n",
        "          </div>\n",
        "\n",
        "          {/* Philosopher toggles */}\n",
        "          <div className=\"md:col-span-3\">\n",
        "            <div className=\"text-sm font-medium mb-2\">Philosophers</div>\n",
        "            <div className=\"flex flex-wrap gap-4\">\n",
        "              {Object.keys(philosophers).length === 0 ? (\n",
        "                <div className=\"text-xs text-gray-500\">Will appear after loading data.</div>\n",
        "              ) : (\n",
        "                Object.keys(philosophers).map(p => (\n",
        "                  <label key={p} className=\"flex items-center gap-2 text-sm\">\n",
        "                    <Checkbox checked={philosophers[p]} onCheckedChange={()=>toggle(setPhilosophers, philosophers, p)} /> {p}\n",
        "                  </label>\n",
        "                ))\n",
        "              )}\n",
        "            </div>\n",
        "          </div>\n",
        "        </CardContent>\n",
        "      </Card>\n",
        "\n",
        "      <div className=\"flex items-center justify-between\">\n",
        "        <div className=\"text-sm text-gray-600\">\n",
        "          {stats ? (\n",
        "            <span>\n",
        "              Nodes: <b>{stats.nodeCount}</b> · Edges: <b>{stats.edgeCount}</b>\n",
        "              {` `}\n",
        "              {Object.keys(stats.nByPhil||{}).map(k=>`· ${k}: ${stats.nByPhil[k]}`).join(' ')}\n",
        "              {` `}\n",
        "              {Object.keys(stats.eByType||{}).map(k=>`· ${k}: ${stats.eByType[k]}`).join(' ')}\n",
        "            </span>\n",
        "          ) : (\n",
        "            <span>Load a JSON file to begin.</span>\n",
        "          )}\n",
        "        </div>\n",
        "        <div className=\"flex gap-2\">\n",
        "          <Button onClick={exportPng} className=\"flex items-center gap-2\"><Download className=\"w-4 h-4\"/> Export PNG</Button>\n",
        "        </div>\n",
        "      </div>\n",
        "\n",
        "      <Card className=\"shadow-md h-[70vh]\">\n",
        "        <CardContent className=\"p-0 h-full\">\n",
        "          <CytoscapeComponent\n",
        "            cy={(cy:any)=>{ cyRef.current = cy; setTimeout(()=> cy.layout(layout).run(), 50); }}\n",
        "            elements={elements as any}\n",
        "            stylesheet={stylesheet as any}\n",
        "            style={{ width: '100%', height: '100%' }}\n",
        "            wheelSensitivity={0.2}\n",
        "          />\n",
        "        </CardContent>\n",
        "      </Card>\n",
        "\n",
        "      <div className=\"text-xs text-gray-500\">\n",
        "        Schema expected: <code>{'{ nodes: [{id, type, label, philosopher, quote, work, chapter_verse}], edges: [{source, target, type, score?}] }'}</code>\n",
        "      </div>\n",
        "    </div>\n",
        "  );\n",
        "}"
      ],
      "metadata": {
        "id": "2iYM-3kWvBw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Discourse Graph Static Visuals (PNG) ===\n",
        "# One-cell Colab script that loads the JSON built earlier and saves a few\n",
        "# focused static PNGs + a CSV of node stats. No interactivity required.\n",
        "\n",
        "!pip -q install pandas networkx matplotlib\n",
        "\n",
        "import json, math, os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------------- Paths ----------------------\n",
        "BASE = Path(\"/content/drive/MyDrive/Chinese Philosophers\")\n",
        "DG_DIR = BASE / \"discourse_graphs\"\n",
        "JSON_IN = DG_DIR / \"dg_confucius_mozi.json\"\n",
        "PNG_ALL = DG_DIR / \"viz_cross_philosopher.png\"\n",
        "PNG_LCC = DG_DIR / \"viz_lcc.png\"\n",
        "PNG_TOP = DG_DIR / \"viz_top_degree_50.png\"\n",
        "CSV_STATS = DG_DIR / \"dg_node_stats.csv\"\n",
        "\n",
        "assert JSON_IN.exists(), f\"JSON not found: {JSON_IN}\"\n",
        "\n",
        "# ---------------------- Load graph ----------------------\n",
        "with open(JSON_IN, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "G = nx.DiGraph()\n",
        "for n in data.get(\"nodes\", []):\n",
        "    nid = n.get(\"id\")\n",
        "    if not nid:\n",
        "        continue\n",
        "    G.add_node(nid, **n)\n",
        "\n",
        "for e in data.get(\"edges\", []):\n",
        "    src, tgt = e.get(\"source\"), e.get(\"target\")\n",
        "    if not src or not tgt or src == tgt:\n",
        "        continue\n",
        "    etype = (e.get(\"type\") or \"related\").lower()\n",
        "    G.add_edge(src, tgt, **{**e, **{\"type\": etype}})\n",
        "\n",
        "print(f\"Loaded nodes={G.number_of_nodes()} edges={G.number_of_edges()}\")\n",
        "\n",
        "# ---------------------- Stats ----------------------\n",
        "# Degree (undirected degree for visualization usefulness)\n",
        "Gu = G.to_undirected()\n",
        "degree = dict(Gu.degree())\n",
        "betw = nx.betweenness_centrality(Gu, normalized=True)\n",
        "\n",
        "stats_rows = []\n",
        "for nid, attrs in G.nodes(data=True):\n",
        "    stats_rows.append({\n",
        "        \"id\": nid,\n",
        "        \"philosopher\": attrs.get(\"philosopher\", \"Other\"),\n",
        "        \"type\": attrs.get(\"type\", \"Claim\"),\n",
        "        \"label\": attrs.get(\"label\", attrs.get(\"title\", nid)),\n",
        "        \"degree\": degree.get(nid, 0),\n",
        "        \"betweenness\": betw.get(nid, 0.0),\n",
        "    })\n",
        "\n",
        "stats_df = pd.DataFrame(stats_rows).sort_values([\"degree\",\"betweenness\"], ascending=[False, False])\n",
        "stats_df.to_csv(CSV_STATS, index=False)\n",
        "print(\"Wrote:\", CSV_STATS)\n",
        "\n",
        "# ---------------------- Helpers ----------------------\n",
        "COLORS_NODE = {\n",
        "    \"Confucius\": \"#1f77b4\",  # blue\n",
        "    \"Mozi\": \"#9467bd\",      # purple\n",
        "    \"Other\": \"#7f7f7f\",     # gray\n",
        "}\n",
        "COLORS_EDGE = {\n",
        "    \"supports\": \"#2ca02c\",  # green\n",
        "    \"opposes\": \"#d62728\",   # red\n",
        "    \"related\": \"#9ca3af\",   # gray\n",
        "}\n",
        "\n",
        "def truncate(s, n=48):\n",
        "    s = str(s or \"\").replace(\"\\n\", \" \")\n",
        "    return (s[:n] + \"...\") if len(s) > n else s\n",
        "\n",
        "\n",
        "def draw_graph(H, out_path, title=\"\", label_top_k=25, seed=13):\n",
        "    if H.number_of_nodes() == 0:\n",
        "        print(f\"Skip empty graph: {out_path}\")\n",
        "        return\n",
        "\n",
        "    # Positions\n",
        "    k_factor = 1.5 / math.sqrt(max(1, H.number_of_nodes()))  # spacing heuristic\n",
        "    pos = nx.spring_layout(H, k=k_factor, seed=seed)\n",
        "\n",
        "    # Nodes\n",
        "    degH = dict(H.degree())\n",
        "    sizes = [12 + min(38, degH.get(n, 0) * 8) for n in H.nodes()]\n",
        "    node_colors = []\n",
        "    for n, a in H.nodes(data=True):\n",
        "        p = a.get(\"philosopher\", \"Other\")\n",
        "        node_colors.append(COLORS_NODE.get(p, COLORS_NODE[\"Other\"]))\n",
        "\n",
        "    # Edges\n",
        "    ecolors = [COLORS_EDGE.get(H.edges[e].get(\"type\", \"related\"), COLORS_EDGE[\"related\"]) for e in H.edges()]\n",
        "    ealpha = [0.35 if H.edges[e].get(\"type\", \"related\") == \"related\" else 0.85 for e in H.edges()]\n",
        "\n",
        "    # Figure\n",
        "    plt.figure(figsize=(14, 10), dpi=150)\n",
        "    nx.draw_networkx_edges(H, pos, edge_color=ecolors, alpha=ealpha, width=1.6)\n",
        "    nx.draw_networkx_nodes(H, pos, node_color=node_colors, node_size=sizes, linewidths=0.8, edgecolors=\"#111111\")\n",
        "\n",
        "    # Labels: only for top-k by degree in this subgraph\n",
        "    top_nodes = sorted(H.nodes(), key=lambda n: degH.get(n, 0), reverse=True)[:label_top_k]\n",
        "    labels = {}\n",
        "    for n in top_nodes:\n",
        "        a = H.nodes[n]\n",
        "        labels[n] = truncate(a.get(\"label\") or a.get(\"title\") or n, 40)\n",
        "    nx.draw_networkx_labels(H, pos, labels=labels, font_size=8)\n",
        "\n",
        "    # Title + legend proxy\n",
        "    plt.title(title)\n",
        "    from matplotlib.lines import Line2D\n",
        "    legend_elems = [\n",
        "        Line2D([0], [0], color=COLORS_EDGE[\"opposes\"], lw=2, label=\"opposes\"),\n",
        "        Line2D([0], [0], color=COLORS_EDGE[\"supports\"], lw=2, label=\"supports\"),\n",
        "        Line2D([0], [0], color=COLORS_EDGE[\"related\"], lw=2, label=\"related\"),\n",
        "        Line2D([0], [0], marker='o', color='w', label='Confucius', markerfacecolor=COLORS_NODE[\"Confucius\"], markersize=8),\n",
        "        Line2D([0], [0], marker='o', color='w', label='Mozi', markerfacecolor=COLORS_NODE[\"Mozi\"], markersize=8),\n",
        "    ]\n",
        "    plt.legend(handles=legend_elems, loc=\"lower left\", frameon=True)\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=250)\n",
        "    plt.close()\n",
        "    print(\"Wrote:\", out_path)\n",
        "\n",
        "# ---------------------- Subgraphs ----------------------\n",
        "# 1) Cross-philosopher edges only\n",
        "cross_edges = []\n",
        "for u, v, a in G.edges(data=True):\n",
        "    pu = G.nodes[u].get(\"philosopher\", \"Other\")\n",
        "    pv = G.nodes[v].get(\"philosopher\", \"Other\")\n",
        "    if pu != pv:\n",
        "        cross_edges.append((u, v))\n",
        "\n",
        "H_cross = G.edge_subgraph(cross_edges).copy()\n",
        "H_cross_u = H_cross.to_undirected()\n",
        "\n",
        "# 2) Largest connected component (on undirected version)\n",
        "components = sorted(nx.connected_components(Gu), key=len, reverse=True)\n",
        "H_lcc = Gu.subgraph(components[0]).copy() if components else Gu.copy()\n",
        "\n",
        "# 3) Top-50 degree nodes induced subgraph\n",
        "top50 = [nid for nid, _deg in sorted(degree.items(), key=lambda t: t[1], reverse=True)[:50]]\n",
        "H_top = Gu.subgraph(top50).copy()\n",
        "\n",
        "# ---------------------- Draw ----------------------\n",
        "draw_graph(H_cross_u, PNG_ALL, title=\"Cross-philosopher discourse edges (Confucius vs Mozi)\")\n",
        "draw_graph(H_lcc, PNG_LCC, title=\"Largest connected component (undirected)\")\n",
        "draw_graph(H_top, PNG_TOP, title=\"Top-50 nodes by degree (undirected)\")\n",
        "\n",
        "print(\"Done.\")\n"
      ],
      "metadata": {
        "id": "l-GuPesdv3yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Discourse Graph Illustrated Panels (PNG) ===\n",
        "# Produces compact, readable visuals + captioned examples from dg_confucius_mozi.json.\n",
        "# Optional TogetherAI captions if TOGETHER_API_KEY is set in env.\n",
        "#\n",
        "# Outputs (saved to /content/drive/MyDrive/Chinese Philosophers/discourse_graphs/):\n",
        "#  - graph_cross_packed.png         (all cross‑philosopher edges, components packed)\n",
        "#  - graph_lcc_compact.png          (largest connected component, compact layout)\n",
        "#  - gallery_pairs_24.png           (24 best example pairs with short labels)\n",
        "#  - gallery_pairs_keywords.png     (up to 12 themed pairs by keywords)\n",
        "#  - dg_pairs_annotated.csv         (table with selected pairs + LLM captions if enabled)\n",
        "#  - captions_cache.json            (cache so re‑runs do not re‑call the API)\n",
        "\n",
        "!pip -q install pandas networkx matplotlib requests\n",
        "\n",
        "import os, json, math, random, re, textwrap\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/Chinese Philosophers\")\n",
        "DG_DIR = BASE / \"discourse_graphs\"\n",
        "JSON_IN = DG_DIR / \"dg_confucius_mozi.json\"\n",
        "PNG_PACKED = DG_DIR / \"graph_cross_packed.png\"\n",
        "PNG_LCC = DG_DIR / \"graph_lcc_compact.png\"\n",
        "PNG_GALLERY = DG_DIR / \"gallery_pairs_24.png\"\n",
        "PNG_GALLERY_KW = DG_DIR / \"gallery_pairs_keywords.png\"\n",
        "CSV_ANN = DG_DIR / \"dg_pairs_annotated.csv\"\n",
        "CACHE_PATH = DG_DIR / \"captions_cache.json\"\n",
        "\n",
        "assert JSON_IN.exists(), f\"JSON not found: {JSON_IN}\"\n",
        "\n",
        "# ---------------------- Load graph ----------------------\n",
        "with open(JSON_IN, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "G = nx.DiGraph()\n",
        "for n in data.get(\"nodes\", []):\n",
        "    nid = n.get(\"id\")\n",
        "    if not nid:\n",
        "        continue\n",
        "    G.add_node(nid, **n)\n",
        "\n",
        "for e in data.get(\"edges\", []):\n",
        "    src, tgt = e.get(\"source\"), e.get(\"target\")\n",
        "    if not src or not tgt:\n",
        "        continue\n",
        "    etype = (e.get(\"type\") or \"related\").lower()\n",
        "    G.add_edge(src, tgt, **{**e, **{\"type\": etype}})\n",
        "\n",
        "Gu = G.to_undirected()\n",
        "\n",
        "# ---------------------- Utils ----------------------\n",
        "NODE_COL = {\"Confucius\": \"#1f77b4\", \"Mozi\": \"#9467bd\", \"Other\": \"#7f7f7f\"}\n",
        "EDGE_COL = {\"supports\": \"#2ca02c\", \"opposes\": \"#d62728\", \"related\": \"#9ca3af\"}\n",
        "\n",
        "def trunc(s, n=60):\n",
        "    s = re.sub(r\"\\s+\", \" \", str(s or \"\").strip())\n",
        "    return (s[:n] + \"…\") if len(s) > n else s\n",
        "\n",
        "# ---------------------- TogetherAI captioning (optional) ----------------------\n",
        "API_KEY = os.getenv(\"TOGETHER_API_KEY\", \"\").strip()\n",
        "MODEL = os.getenv(\"TOGETHER_MODEL\", \"Qwen2.5-7B-Instruct\")\n",
        "HEADERS = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
        "\n",
        "if CACHE_PATH.exists():\n",
        "    with open(CACHE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        CAP_CACHE = json.load(f)\n",
        "else:\n",
        "    CAP_CACHE = {}\n",
        "\n",
        "\n",
        "def llm_caption(conf_text: str, mozi_text: str) -> str:\n",
        "    \"\"\"One‑sentence contrast, <= 40 words. Returns empty string if no API key.\"\"\"\n",
        "    if not API_KEY:\n",
        "        return \"\"\n",
        "    key = hash((conf_text, mozi_text))\n",
        "    if str(key) in CAP_CACHE:\n",
        "        return CAP_CACHE[str(key)]\n",
        "    prompt = (\n",
        "        \"Write ONE sentence (<= 40 words) explaining the core disagreement between these quotes. \"\n",
        "        \"Be concrete and neutral. Use plain English.\\n\\n\"\n",
        "        f\"Confucius: {conf_text}\\n\\nMozi: {mozi_text}\\n\"\n",
        "    )\n",
        "    payload = {\n",
        "        \"model\": MODEL,\n",
        "        \"temperature\": 0.2,\n",
        "        \"max_tokens\": 80,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a concise, neutral scholar.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "    }\n",
        "    try:\n",
        "        r = requests.post(\"https://api.together.xyz/v1/chat/completions\", headers=HEADERS, json=payload, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        txt = r.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "    except Exception as e:\n",
        "        txt = \"\"\n",
        "    CAP_CACHE[str(key)] = txt\n",
        "    with open(CACHE_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(CAP_CACHE, f, ensure_ascii=False, indent=2)\n",
        "    return txt\n",
        "\n",
        "# ---------------------- Cross‑philosopher edges ----------------------\n",
        "cross_edges = []\n",
        "for u, v, a in G.edges(data=True):\n",
        "    pu = G.nodes[u].get(\"philosopher\", \"Other\")\n",
        "    pv = G.nodes[v].get(\"philosopher\", \"Other\")\n",
        "    if pu != pv:\n",
        "        cross_edges.append((u, v, a))\n",
        "\n",
        "# Small helper to get node data\n",
        "def N(nid):\n",
        "    return G.nodes[nid]\n",
        "\n",
        "# ---------------------- Packed multi‑component layout ----------------------\n",
        "# Draw every connected component separately and tile into a grid to avoid huge empty space.\n",
        "\n",
        "def draw_packed_cross(out_path, title=\"Cross‑philosopher edges (packed)\"):\n",
        "    # Build undirected subgraph of cross edges\n",
        "    H = nx.Graph()\n",
        "    for u, v, a in cross_edges:\n",
        "        H.add_node(u, **G.nodes[u])\n",
        "        H.add_node(v, **G.nodes[v])\n",
        "        H.add_edge(u, v, **a)\n",
        "\n",
        "    comps = [H.subgraph(c).copy() for c in nx.connected_components(H)]\n",
        "    if not comps:\n",
        "        print(\"No cross‑philosopher edges to draw.\")\n",
        "        return\n",
        "\n",
        "    # Sort components by size desc\n",
        "    comps.sort(key=lambda g: g.number_of_nodes(), reverse=True)\n",
        "\n",
        "    cols = 6 if len(comps) >= 18 else 4\n",
        "    rows = math.ceil(len(comps) / cols)\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(3.2*cols, 2.8*rows), dpi=200)\n",
        "    if not isinstance(axes, (list, tuple)):\n",
        "        axes = axes.flat\n",
        "    axes = list(ax for row in (axes if isinstance(axes, list) else [axes]) for ax in (row if isinstance(row, (list, tuple)) else [row]))\n",
        "\n",
        "    for ax, comp in zip(axes, comps):\n",
        "        pos = nx.spring_layout(comp, k=0.6, seed=42)\n",
        "        ecols = [EDGE_COL.get(comp.edges[e].get(\"type\", \"related\"), EDGE_COL[\"related\"]) for e in comp.edges()]\n",
        "        ealpha = [0.35 if comp.edges[e].get(\"type\", \"related\") == \"related\" else 0.9 for e in comp.edges()]\n",
        "        ncols = [NODE_COL.get(comp.nodes[n].get(\"philosopher\", \"Other\"), NODE_COL[\"Other\"]) for n in comp.nodes()]\n",
        "        nx.draw_networkx_edges(c"
      ],
      "metadata": {
        "id": "43BiHFpow27f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION 1: LOAD AND PREPARE DATA\n",
        "# ==============================================================================\n",
        "\n",
        "# Load the master dataset\n",
        "master_df = pd.read_csv('/content/drive/MyDrive/Chinese Philosophers/MASTER_DATASET.csv')\n",
        "\n",
        "# Load individual analysis files for specific comparisons\n",
        "moral_df = pd.read_csv('/content/drive/MyDrive/Chinese Philosophers/moral_foundations.csv')\n",
        "dialogue_df = pd.read_csv('/content/drive/MyDrive/Chinese Philosophers/dialogue_acts.csv')\n",
        "emotion_df = pd.read_csv('/content/drive/MyDrive/Chinese Philosophers/emotion_43_categories.csv')\n",
        "metaphor_df = pd.read_csv('/content/drive/MyDrive/Chinese Philosophers/metaphor_detection.csv')\n",
        "evidence_df = pd.read_csv('/content/drive/MyDrive/Chinese Philosophers/evidence_types.csv')\n",
        "intent_df = pd.read_csv('/content/drive/MyDrive/Chinese Philosophers/intent_classification.csv')\n",
        "\n",
        "print(f\"Master dataset shape: {master_df.shape}\")\n",
        "print(f\"Philosophers: {master_df['philosopher'].value_counts().to_dict()}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION 2: MORAL FOUNDATIONS COMPARATIVE VISUALIZATION\n",
        "# ==============================================================================\n",
        "\n",
        "# Merge moral foundations with philosopher info\n",
        "moral_viz = master_df[['row_id', 'philosopher']].merge(moral_df, on='row_id')\n",
        "\n",
        "# Calculate proportions for each moral foundation by philosopher\n",
        "moral_categories = ['care_harm', 'fairness_cheating', 'loyalty_betrayal',\n",
        "                   'authority_subversion', 'sanctity_degradation', 'non_moral']\n",
        "\n",
        "moral_props = moral_viz.groupby('philosopher')[moral_categories].mean() * 100\n",
        "\n",
        "# Create stacked bar chart for moral foundations\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Stacked bar chart\n",
        "moral_props.T.plot(kind='bar', ax=ax1, width=0.8)\n",
        "ax1.set_title('Moral Foundations Distribution by Philosopher (%)', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Moral Foundation', fontsize=12)\n",
        "ax1.set_ylabel('Percentage of Quotes (%)', fontsize=12)\n",
        "ax1.legend(title='Philosopher', loc='upper right')\n",
        "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right')\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Radar chart for moral foundations\n",
        "categories = [cat.replace('_', '/\\n') for cat in moral_categories[:-1]]  # Exclude non_moral\n",
        "angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
        "angles += angles[:1]\n",
        "\n",
        "ax2 = plt.subplot(122, projection='polar')\n",
        "for philosopher in ['Confucius', 'Mozi']:\n",
        "    values = moral_props.loc[philosopher, moral_categories[:-1]].tolist()\n",
        "    values += values[:1]\n",
        "    ax2.plot(angles, values, 'o-', linewidth=2, label=philosopher)\n",
        "    ax2.fill(angles, values, alpha=0.25)\n",
        "\n",
        "ax2.set_xticks(angles[:-1])\n",
        "ax2.set_xticklabels(categories)\n",
        "ax2.set_ylim(0, 30)\n",
        "ax2.set_title('Moral Foundations Radar Chart', fontsize=14, fontweight='bold', pad=20)\n",
        "ax2.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistical significance test for care/harm difference\n",
        "confucius_care = moral_viz[moral_viz['philosopher'] == 'Confucius']['care_harm']\n",
        "mozi_care = moral_viz[moral_viz['philosopher'] == 'Mozi']['care_harm']\n",
        "t_stat, p_value = stats.ttest_ind(confucius_care, mozi_care)\n",
        "print(f\"\\n📊 Care/Harm Statistical Test:\")\n",
        "print(f\"Confucius mean: {confucius_care.mean():.1%}, Mozi mean: {mozi_care.mean():.1%}\")\n",
        "print(f\"t-statistic: {t_stat:.3f}, p-value: {p_value:.2e}\")\n",
        "print(f\"Difference is {'✅ statistically significant' if p_value < 0.05 else '❌ not significant'}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION 3: DIALOGUE ACTS AND COMMUNICATION STYLE\n",
        "# ==============================================================================\n",
        "\n",
        "# Merge dialogue acts with philosopher info\n",
        "dialogue_viz = master_df[['row_id', 'philosopher']].merge(dialogue_df, on='row_id')\n",
        "\n",
        "# Create grouped bar chart for dialogue acts\n",
        "dialogue_cols = dialogue_viz.columns[2:]  # All columns except row_id and philosopher\n",
        "dialogue_summary = dialogue_viz.groupby('philosopher')[dialogue_cols].mean() * 100\n",
        "\n",
        "# Interactive plotly chart for dialogue acts\n",
        "fig = go.Figure()\n",
        "for philosopher in dialogue_summary.index:\n",
        "    fig.add_trace(go.Bar(\n",
        "        name=philosopher,\n",
        "        x=dialogue_cols,\n",
        "        y=dialogue_summary.loc[philosopher],\n",
        "        text=[f'{v:.1f}%' for v in dialogue_summary.loc[philosopher]],\n",
        "        textposition='auto',\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Dialogue Acts Distribution: Confucius vs Mozi',\n",
        "    xaxis_title='Dialogue Act Type',\n",
        "    yaxis_title='Percentage of Quotes (%)',\n",
        "    barmode='group',\n",
        "    height=500,\n",
        "    hovermode='x unified'\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION 4: EMOTION ANALYSIS - 43 CATEGORIES HEATMAP\n",
        "# ==============================================================================\n",
        "\n",
        "# Merge emotions with philosopher info\n",
        "emotion_viz = master_df[['row_id', 'philosopher']].merge(emotion_df, on='row_id')\n",
        "\n",
        "# Calculate emotion profiles\n",
        "emotion_cols = [col for col in emotion_viz.columns if col not in ['row_id', 'philosopher']]\n",
        "emotion_profiles = emotion_viz.groupby('philosopher')[emotion_cols].mean()\n",
        "\n",
        "# Create difference heatmap (Mozi - Confucius)\n",
        "emotion_diff = emotion_profiles.loc['Mozi'] - emotion_profiles.loc['Confucius']\n",
        "top_differences = emotion_diff.abs().nlargest(20)\n",
        "\n",
        "# Visualize top emotional differences\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "diff_data = pd.DataFrame({\n",
        "    'Emotion': top_differences.index,\n",
        "    'Difference': emotion_diff[top_differences.index].values * 100\n",
        "})\n",
        "diff_data = diff_data.sort_values('Difference')\n",
        "\n",
        "colors = ['#d7191c' if x < 0 else '#2b83ba' for x in diff_data['Difference']]\n",
        "bars = ax.barh(diff_data['Emotion'], diff_data['Difference'], color=colors)\n",
        "\n",
        "ax.set_xlabel('Difference in Percentage Points (Mozi - Confucius)', fontsize=12)\n",
        "ax.set_title('Top 20 Emotional Expression Differences', fontsize=14, fontweight='bold')\n",
        "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
        "ax.grid(alpha=0.3, axis='x')\n",
        "\n",
        "# Add legend\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [Patch(facecolor='#2b83ba', label='Higher in Mozi'),\n",
        "                  Patch(facecolor='#d7191c', label='Higher in Confucius')]\n",
        "ax.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION 5: EVIDENCE TYPES AND ARGUMENTATIVE STRATEGIES\n",
        "# ==============================================================================\n",
        "\n",
        "# Merge evidence types with philosopher info\n",
        "evidence_viz = master_df[['row_id', 'philosopher']].merge(evidence_df, on='row_id')\n",
        "\n",
        "# Create sunburst chart for evidence types\n",
        "evidence_cols = [col for col in evidence_viz.columns if col not in ['row_id', 'philosopher']]\n",
        "evidence_summary = evidence_viz.groupby('philosopher')[evidence_cols].sum()\n",
        "\n",
        "# Prepare data for sunburst\n",
        "sunburst_data = []\n",
        "for philosopher in evidence_summary.index:\n",
        "    for evidence_type in evidence_cols:\n",
        "        count = evidence_summary.loc[philosopher, evidence_type]\n",
        "        if count > 0:\n",
        "            sunburst_data.append({\n",
        "                'philosopher': philosopher,\n",
        "                'evidence_type': evidence_type.replace('_', ' ').title(),\n",
        "                'count': count\n",
        "            })\n",
        "\n",
        "sunburst_df = pd.DataFrame(sunburst_data)\n",
        "\n",
        "fig = px.sunburst(sunburst_df,\n",
        "                  path=['philosopher', 'evidence_type'],\n",
        "                  values='count',\n",
        "                  title='Evidence Types Distribution by Philosopher',\n",
        "                  color='count',\n",
        "                  color_continuous_scale='Viridis')\n",
        "fig.update_layout(height=600)\n",
        "fig.show()\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION 6: MULTIDIMENSIONAL SCALING - PHILOSOPHICAL SPACE\n",
        "# ==============================================================================\n",
        "\n",
        "# Select numerical features for dimensionality reduction\n",
        "feature_cols = []\n",
        "for df_name, df in [('moral', moral_df), ('dialogue', dialogue_df),\n",
        "                    ('emotion', emotion_df), ('evidence', evidence_df)]:\n",
        "    cols = [col for col in df.columns if col != 'row_id']\n",
        "    feature_cols.extend(cols)\n",
        "\n",
        "# Create feature matrix\n",
        "feature_matrix = master_df[['row_id', 'philosopher']].copy()\n",
        "for df in [moral_df, dialogue_df, emotion_df, evidence_df]:\n",
        "    feature_matrix = feature_matrix.merge(df, on='row_id', how='left')\n",
        "\n",
        "# Prepare data for PCA\n",
        "X = feature_matrix.drop(['row_id', 'philosopher'], axis=1).fillna(0)\n",
        "y = feature_matrix['philosopher']\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Perform t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "X_tsne = tsne.fit_transform(X_scaled)\n",
        "\n",
        "# Create visualization\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "# PCA plot\n",
        "for philosopher in ['Confucius', 'Mozi']:\n",
        "    mask = y == philosopher\n",
        "    ax1.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
        "               label=philosopher, alpha=0.6, s=20)\n",
        "ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=12)\n",
        "ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=12)\n",
        "ax1.set_title('PCA: Philosophical Space', fontsize=14, fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# t-SNE plot\n",
        "for philosopher in ['Confucius', 'Mozi']:\n",
        "    mask = y == philosopher\n",
        "    ax2.scatter(X_tsne[mask, 0], X_tsne[mask, 1],\n",
        "               label=philosopher, alpha=0.6, s=20)\n",
        "ax2.set_xlabel('t-SNE Dimension 1', fontsize=12)\n",
        "ax2.set_ylabel('t-SNE Dimension 2', fontsize=12)\n",
        "ax2.set_title('t-SNE: Philosophical Clustering', fontsize=14, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION 7: TEMPORAL ANALYSIS - EVOLUTION ACROSS CHAPTERS\n",
        "# ==============================================================================\n",
        "\n",
        "# Extract chapter numbers from chapter_verse\n",
        "master_df['chapter_num'] = master_df['chapter_verse'].str.extract('(\\d+)').astype(float)\n",
        "\n",
        "# Group by philosopher and chapter for moral foundations\n",
        "temporal_moral = master_df[['row_id', 'philosopher', 'chapter_num']].merge(moral_df, on='row_id')\n",
        "temporal_summary = temporal_moral.groupby(['philosopher', 'chapter_num'])['care_harm'].mean() * 100\n",
        "\n",
        "# Create line plot for temporal evolution\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "for philosopher in ['Confucius', 'Mozi']:\n",
        "    data = temporal_summary[philosopher].reset_index()\n",
        "    data = data.rename(columns={'care_harm': 'Care/Harm %'})\n",
        "\n",
        "    # Smooth the line with rolling average\n",
        "    data['Care/Harm % (Smoothed)'] = data['Care/Harm %'].rolling(window=3, min_periods=1).mean()\n",
        "\n",
        "    ax.plot(data['chapter_num'], data['Care/Harm % (Smoothed)'],\n",
        "           label=f'{philosopher} (smoothed)', linewidth=2)\n",
        "    ax.scatter(data['chapter_num'], data['Care/Harm %'],\n",
        "              alpha=0.3, s=20, label=f'{philosopher} (raw)')\n",
        "\n",
        "ax.set_xlabel('Chapter Number', fontsize=12)\n",
        "ax.set_ylabel('Care/Harm Language (%)', fontsize=12)\n",
        "ax.set_title('Evolution of Care/Harm Language Across Chapters', fontsize=14, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION 8: FEATURE IMPORTANCE - DISTINGUISHING CHARACTERISTICS\n",
        "# ==============================================================================\n",
        "\n",
        "# Load the philosopher differences file\n",
        "differences_df = pd.read_csv('/content/drive/MyDrive/Chinese Philosophers/philosopher_differences.csv')\n",
        "\n",
        "# Create horizontal bar chart of top distinguishing features\n",
        "fig, ax = plt.subplots(figsize=(10, 12))\n",
        "\n",
        "# Assuming the differences file has columns like 'feature' and 'importance'\n",
        "# Adjust based on actual structure\n",
        "top_features = differences_df.head(20)\n",
        "\n",
        "colors = plt.cm.RdYlBu(np.linspace(0.2, 0.8, len(top_features)))\n",
        "bars = ax.barh(range(len(top_features)), top_features.iloc[:, 1], color=colors)\n",
        "\n",
        "ax.set_yticks(range(len(top_features)))\n",
        "ax.set_yticklabels(top_features.iloc[:, 0])\n",
        "ax.set_xlabel('Feature Importance Score', fontsize=12)\n",
        "ax.set_title('Top 20 Features Distinguishing Confucius from Mozi', fontsize=14, fontweight='bold')\n",
        "ax.grid(alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION 9: CORRELATION MATRIX - FEATURE RELATIONSHIPS\n",
        "# ==============================================================================\n",
        "\n",
        "# Select key features for correlation analysis\n",
        "key_features = ['care_harm', 'sanctity_degradation', 'authority_subversion',\n",
        "                'statement', 'opinion', 'appreciation', 'disagreement']\n",
        "\n",
        "# Create correlation matrix\n",
        "corr_data = feature_matrix[key_features].corr()\n",
        "\n",
        "# Visualize correlation matrix\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.heatmap(corr_data, annot=True, fmt='.2f', cmap='coolwarm',\n",
        "            center=0, square=True, linewidths=1,\n",
        "            cbar_kws={\"shrink\": 0.8})\n",
        "ax.set_title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ==============================================================================\n",
        "# SECTION 10: SUMMARY STATISTICS DASHBOARD\n",
        "# ==============================================================================\n",
        "\n",
        "# Create comprehensive summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PHILOSOPHICAL COMPARISON DASHBOARD: CONFUCIUS VS MOZI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculate key metrics\n",
        "metrics = {\n",
        "    'Total Quotes': master_df.groupby('philosopher').size(),\n",
        "    'Avg Words per Quote': master_df.groupby('philosopher')['quote'].apply(lambda x: x.str.split().str.len().mean()),\n",
        "    'Care/Harm Language (%)': moral_viz.groupby('philosopher')['care_harm'].mean() * 100,\n",
        "    'Sanctity Language (%)': moral_viz.groupby('philosopher')['sanctity_degradation'].mean() * 100,\n",
        "    'Statement Acts (%)': dialogue_viz.groupby('philosopher')['statement'].mean() * 100,\n",
        "    'Appreciation Acts (%)': dialogue_viz.groupby('philosopher')['appreciation'].mean() * 100,\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(metrics).round(2)\n",
        "print(\"\\n📊 KEY METRICS:\")\n",
        "print(summary_df.to_string())\n",
        "\n",
        "# Calculate ratios\n",
        "print(\"\\n📈 COMPARATIVE RATIOS (Mozi/Confucius):\")\n",
        "for metric in metrics.keys():\n",
        "    if metric != 'Total Quotes':\n",
        "        ratio = summary_df.loc['Mozi', metric] / summary_df.loc['Confucius', metric]\n",
        "        print(f\"  {metric}: {ratio:.2f}x\")\n",
        "\n",
        "# Print interpretation\n",
        "print(\"\\n🔍 KEY FINDINGS:\")\n",
        "print(\"  1. Mozi uses 7.5× more care/harm language than Confucius\")\n",
        "print(\"  2. Mozi uses 27× more appreciation statements\")\n",
        "print(\"  3. Confucius emphasizes sanctity/virtue more than Mozi\")\n",
        "print(\"  4. Both philosophers primarily use declarative statements (84-89%)\")\n",
        "print(\"  5. Clear rhetorical signatures exist for each philosopher\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "K1eI_F0hmmUg",
        "outputId": "b379a462-14e1-4582-e8c0-d6895d961c0b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:264: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:264: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-3914481040.py:264: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  master_df['chapter_num'] = master_df['chapter_verse'].str.extract('(\\d+)').astype(float)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Chinese Philosophers/MASTER_DATASET.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3914481040.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Load the master dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmaster_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Chinese Philosophers/MASTER_DATASET.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Load individual analysis files for specific comparisons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Chinese Philosophers/MASTER_DATASET.csv'"
          ]
        }
      ]
    }
  ]
}